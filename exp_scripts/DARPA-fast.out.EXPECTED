Using gpu device 0: GeForce GTX 285
		----  Encoding  layer #1 ----
			**** DenseLayer.__init__ ****
			tag =  enc1
			inp =  inp
			n_inp =  5000
			n_out =  1000
			act =  tanh
			noise =  binomial_NLP
			out =  outenc1
			params (gradients) =  [Wenc1, benc1]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  None
			allocW, allocb, allocmask =  True True ones
		----  Encoding  layer #2 ----
			**** DenseLayer.__init__ ****
			tag =  enc2
			inp =  outenc1
			n_inp =  1000
			n_out =  1000
			act =  tanh
			noise =  binomial
			out =  outenc2
			params (gradients) =  [Wenc2, benc2]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  None
			allocW, allocb, allocmask =  True True ones
		----  Encoding  layer #3 ----
			**** DenseLayer.__init__ ****
			tag =  enc3
			inp =  outenc2
			n_inp =  1000
			n_out =  1000
			act =  rectifier
			noise =  binomial
			out =  outenc3
			params (gradients) =  [Wenc3, benc3]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  None
			allocW, allocb, allocmask =  True True ones
	---- Output Layer ----
		**** Logistic_regression.__init__ ****
		inp =  outenc3
		n_inp =  1000
		n_out =  5
		out =  Softmax.0
		params (gradients) =  [W, b]
		wdreg (weigth decay) =  l2
		upmaskbool =  None
		allocW, allocb =  True True
		----  Decoding  layer #3 ----
			**** DenseLayer.__init__ ****
			tag =  dec3
			inp =  outenc3
			n_inp =  1000
			n_out =  1000
			act =  rectifier
			noise =  binomial
			out =  outdec3
			params (gradients) =  [InplaceDimShuffle{1,0}.0, bdec3]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc2
			allocW, allocb, allocmask =  False True False
		----  Decoding  layer #2 ----
			**** DenseLayer.__init__ ****
			tag =  dec2
			inp =  outdec3
			n_inp =  1000
			n_out =  1000
			act =  tanh
			noise =  binomial
			out =  outdec2
			params (gradients) =  [InplaceDimShuffle{1,0}.0, bdec2]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc1
			allocW, allocb, allocmask =  False True False
		----  Decoding  layer #1 ----
			**** DenseLayer.__init__ ****
			tag =  dec1
			inp =  outdec2
			n_inp =  1000
			n_out =  5000
			act =  tanh
			noise =  binomial_NLP
			out =  outdec1
			params (gradients) =  [InplaceDimShuffle{1,0}.0, bdec1]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  None
			allocW, allocb, allocmask =  False True ones
	**** SDAE ****
	depth =  3
	mode =  Mixte
	depth_min, depth_max, update_type =  0 , 3 , global
	inp, n_inp =  inp , 5000
	n_hid =  [1000, 1000, 1000]
	layertype =  [<class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>]
	act =  ['tanh', 'tanh', 'rectifier']
	noise, noise_lvl =  ['binomial_NLP', 'binomial', 'binomial'] , None
	tie =  [True, True, True]
	maskbool =  [None, None, None]
	n_out, outtype =  5 , <class 'deepANN.Logistic_regression.LogisticRegression'>
	lr =  0.1
	sup_scaling, unsup_scaling, aux_scaling  =  1.0 1.0 None
	regularization, wdreg  =  [0.0, 0.0, 0.0, 0.0] , l2
	sparsity, spreg =  [0.0, 0.0, 0.01] , l1
	params, wd, sp =  [Wenc1, benc1, Wenc2, benc2, Wenc3, benc3, W, b, bdec3, bdec2, bdec1] , [] , [Elemwise{mul,no_inplace}.0]
	bbbool, hessscal =  None , None
	aux, auxtarget, aux_one_sided, auxdepth, auxregularization =  False , None , None , None , None
	auxact, auxn_out, auxwdreg =  None , None , None
BEGIN DEPTH 1 of 3 (33.33%)...
ceylon.iro.umontreal.ca 2010-08-11 13:28:38.972541: 0:00:02.800000 user+sys, 0:00:01.970000 real, 142.13% usage, 441.68 MB
	---- Auxiliary Layer ----
			**** DenseLayer.__init__ ****
			tag =  aux-2
			inp =  outenc1
			n_inp =  1000
			n_out =  5000
			act =  sigmoid
			noise =  None
			out =  outaux-2
			params (gradients) =  [Waux-2, baux-2]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  None
			allocW, allocb, allocmask =  True True ones
	**** SDAE ****
	depth =  3
	mode =  Mixte
	depth_min, depth_max, update_type =  0 , 4 , global
	inp, n_inp =  inp , 5000
	n_hid =  [1000, 1000, 1000]
	layertype =  [<class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>]
	act =  ['tanh', 'tanh', 'rectifier']
	noise, noise_lvl =  ['binomial_NLP', 'binomial', 'binomial'] , None
	tie =  [True, True, True]
	maskbool =  [None, None, None]
	n_out, outtype =  5 , <class 'deepANN.Logistic_regression.LogisticRegression'>
	lr =  0.1
	sup_scaling, unsup_scaling, aux_scaling  =  1.0 1.0 1.0
	regularization, wdreg  =  [0.0, 0.0, 0.0, 0.0] , l2
	sparsity, spreg =  [0.0, 0.0, 0.01] , l1
	params, wd, sp =  [Wenc1, benc1, Wenc2, benc2, Wenc3, benc3, W, b, bdec3, bdec2, bdec1, Waux-2, baux-2] , [] , [Elemwise{mul,no_inplace}.0]
	bbbool, hessscal =  None , None
	aux, auxtarget, aux_one_sided, auxdepth, auxregularization =  True , auxtarget , True , -2 , False
	auxact, auxn_out, auxwdreg =  sigmoid , 5000 , l2
		----  Encoding  layer #1 ----
			**** DenseLayer.__init__ ****
			tag =  enc1
			inp =  inp
			n_inp =  5000
			n_out =  1000
			act =  tanh
			noise =  binomial_NLP
			out =  outenc1
			params (gradients) =  [Wenc1, benc1]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc1
			allocW, allocb, allocmask =  False False False
MRG_RandomStreams Can't determine #streams from size (Shape.0), guessing 30*256
MRG_RandomStreams Can't determine #streams from size (Shape.0), guessing 30*256
	---- Auxiliary Layer ----
			**** DenseLayer.__init__ ****
			tag =  aux-2
			inp =  outenc1
			n_inp =  1000
			n_out =  5000
			act =  sigmoid
			noise =  None
			out =  outaux-2
			params (gradients) =  [Waux-2, baux-2]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  None
			allocW, allocb, allocmask =  False False ones
	**** SDAE ****
	depth =  3
	mode =  Aux
	depth_min, depth_max, update_type =  0 , 1 , special
	inp, n_inp =  inp , 5000
	n_hid =  [1000, 1000, 1000]
	layertype =  [<class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>]
	act =  ['tanh', 'tanh', 'rectifier']
	noise, noise_lvl =  ['binomial_NLP', 'binomial', 'binomial'] , (0.69999999999999996, 0.0041000000000000003)
	tie =  [True, True, True]
	maskbool =  [None, None, None]
	n_out, outtype =  5 , <class 'deepANN.Logistic_regression.LogisticRegression'>
	lr =  0.01
	sup_scaling, unsup_scaling, aux_scaling  =  None None 1.0
	regularization, wdreg  =  [0.0, 0.0, 0.0, 0.0] , l2
	sparsity, spreg =  [0.0, 0.0, 0.01] , l1
	params, wd, sp =  [Wenc1, benc1, Waux-2, baux-2] , [] , []
	bbbool, hessscal =  None , None
	aux, auxtarget, aux_one_sided, auxdepth, auxregularization =  True , auxtarget , True , -2 , False
	auxact, auxn_out, auxwdreg =  sigmoid , 5000 , l2
Validating (err={1000: {}, 10000: {}, 100: {}},epoch=0,model=<deepANN.ANN.SDAE object at 0x30fcb50>,depth=0,ACT=['tanh', 'tanh', 'rectifier'],LR=0.01,NOISE_LVL=(0.69999999999999996, 0.0041000000000000003),BATCHSIZE=10,train=<CudaNdarrayType(float32, matrix)>,datatrain=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_labels_1.pkl'),datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm,datatest=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_labels_1.pkl'),datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm,VALIDATION_TRAININGSIZE=[100, 1000, 10000],VALIDATION_RUNS_FOR_EACH_TRAININGSIZE={'100': 20, '10000': 1, '1000': 10},PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211)...
ceylon.iro.umontreal.ca 2010-08-11 13:28:46.122358: 0:00:09.510000 user+sys, 0:00:09.120000 real, 104.28% usage, 518.23 MB
		----  Encoding  layer #1 ----
			**** DenseLayer.__init__ ****
			tag =  enc1
			inp =  inp
			n_inp =  5000
			n_out =  1000
			act =  tanh
			noise =  binomial_NLP
			out =  outenc1
			params (gradients) =  [Wenc1, benc1]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc1
			allocW, allocb, allocmask =  False False False
	---- Auxiliary Layer ----
			**** DenseLayer.__init__ ****
			tag =  aux-2
			inp =  outenc1
			n_inp =  1000
			n_out =  5000
			act =  sigmoid
			noise =  None
			out =  outaux-2
			params (gradients) =  [Waux-2, baux-2]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  None
			allocW, allocb, allocmask =  False False ones
	**** SDAE ****
	depth =  3
	mode =  Aux
	depth_min, depth_max, update_type =  0 , 1 , special
	inp, n_inp =  inp , 5000
	n_hid =  [1000, 1000, 1000]
	layertype =  [<class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>]
	act =  ['tanh', 'tanh', 'rectifier']
	noise, noise_lvl =  ['binomial_NLP', 'binomial', 'binomial'] , None
	tie =  [True, True, True]
	maskbool =  [None, None, None]
	n_out, outtype =  5 , <class 'deepANN.Logistic_regression.LogisticRegression'>
	lr =  0.01
	sup_scaling, unsup_scaling, aux_scaling  =  None None 1.0
	regularization, wdreg  =  [0.0, 0.0, 0.0, 0.0] , l2
	sparsity, spreg =  [0.0, 0.0, 0.01] , l1
	params, wd, sp =  [Wenc1, benc1, Waux-2, baux-2] , [] , []
	bbbool, hessscal =  None , None
	aux, auxtarget, aux_one_sided, auxdepth, auxregularization =  True , auxtarget , True , -2 , False
	auxact, auxn_out, auxwdreg =  sigmoid , 5000 , l2
Creating libsvm file '/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm' (model=<deepANN.ANN.SDAE object at 0x30fcb50>, depth=0, datafiles=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_labels_1.pkl'))...
ceylon.iro.umontreal.ca 2010-08-11 13:28:48.732419: 0:00:12.070000 user+sys, 0:00:11.730000 real, 102.90% usage, 519.92 MB
...done creating libsvm files
ceylon.iro.umontreal.ca 2010-08-11 13:28:58.996705: 0:00:22.140000 user+sys, 0:00:21.990000 real, 100.68% usage, 533.78 MB
Creating libsvm file '/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm' (model=<deepANN.ANN.SDAE object at 0x30fcb50>, depth=0, datafiles=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_labels_1.pkl'))...
ceylon.iro.umontreal.ca 2010-08-11 13:28:58.996998: 0:00:22.140000 user+sys, 0:00:21.990000 real, 100.68% usage, 533.78 MB
...done creating libsvm files
ceylon.iro.umontreal.ca 2010-08-11 13:29:09.206153: 0:00:32.150000 user+sys, 0:00:32.200000 real, 99.84% usage, 533.78 MB
Starting SVM validation for 100 examples (numrums=20, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm, PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211, MAXSTEPS=20, STEPFACTOR=10.000000, INITIALC=0.010000)...
ceylon.iro.umontreal.ca 2010-08-11 13:29:09.206468: 0:00:32.150000 user+sys, 0:00:32.200000 real, 99.84% usage, 533.79 MB
		Training SVM with C=0.010000, nbinputs=100, numruns=20
		Training SVM with C=0.100000, nbinputs=100, numruns=20
	testerr[Cnew 0.100000] = 59.335000 < testerr[Ccurrent 0.010000] = 60.935000
	NEW BEST: Cbest <= 0.100000, testerr[Cbest] = 59.335000
	PROCEED: Cstepfactor remains 10.000000, Ccurrent is now 0.100000, Cnew is now 1.000000
		Training SVM with C=1.000000, nbinputs=100, numruns=20
	testerr[Cnew 1.000000] = 61.130000 > testerr[Ccurrent 0.100000] = 59.335000
	REVERSE: Cstepfactor is now 0.316228, Ccurrent remains 0.100000, Cnew is now 0.031623
		Training SVM with C=0.031623, nbinputs=100, numruns=20
	testerr[Cnew 0.031623] = 61.295000 > testerr[Ccurrent 0.100000] = 59.335000
	REVERSE: Cstepfactor is now 1.778279, Ccurrent remains 0.100000, Cnew is now 0.177828
		Training SVM with C=0.177828, nbinputs=100, numruns=20
	testerr[Cnew 0.177828] = 59.995000 > testerr[Ccurrent 0.100000] = 59.335000
	REVERSE: Cstepfactor is now 0.749894, Ccurrent remains 0.100000, Cnew is now 0.074989
		Training SVM with C=0.074989, nbinputs=100, numruns=20
	testerr[Cnew 0.074989] = 61.055000 > testerr[Ccurrent 0.100000] = 59.335000
	REVERSE: Cstepfactor is now 1.154782, Ccurrent remains 0.100000, Cnew is now 0.115478
		Training SVM with C=0.115478, nbinputs=100, numruns=20
	testerr[Cnew 0.115478] = 59.170000 < testerr[Ccurrent 0.100000] = 59.335000
	NEW BEST: Cbest <= 0.115478, testerr[Cbest] = 59.170000
	PROCEED: Cstepfactor remains 1.154782, Ccurrent is now 0.115478, Cnew is now 0.133352
		Training SVM with C=0.133352, nbinputs=100, numruns=20
	testerr[Cnew 0.133352] = 59.415000 > testerr[Ccurrent 0.115478] = 59.170000
	REVERSE: Cstepfactor is now 0.930572, Ccurrent remains 0.115478, Cnew is now 0.107461
		Training SVM with C=0.107461, nbinputs=100, numruns=20
	testerr[Cnew 0.107461] = 60.150000 > testerr[Ccurrent 0.115478] = 59.170000
	REVERSE: Cstepfactor is now 1.036633, Ccurrent remains 0.115478, Cnew is now 0.119709
		Training SVM with C=0.119709, nbinputs=100, numruns=20
	testerr[Cnew 0.119709] = 59.290000 > testerr[Ccurrent 0.115478] = 59.170000
	REVERSE: Cstepfactor is now 0.982172, Ccurrent remains 0.115478, Cnew is now 0.113419
		Training SVM with C=0.113419, nbinputs=100, numruns=20
	testerr[Cnew 0.113419] = 60.230000 > testerr[Ccurrent 0.115478] = 59.170000
	REVERSE: Cstepfactor is now 1.009035, Ccurrent remains 0.115478, Cnew is now 0.116522
		Training SVM with C=0.116522, nbinputs=100, numruns=20
	testerr[Cnew 0.116522] = 60.665000 > testerr[Ccurrent 0.115478] = 59.170000
	REVERSE: Cstepfactor is now 0.995513, Ccurrent remains 0.115478, Cnew is now 0.114960
		Training SVM with C=0.114960, nbinputs=100, numruns=20
	testerr[Cnew 0.114960] = 59.365000 > testerr[Ccurrent 0.115478] = 59.170000
	REVERSE: Cstepfactor is now 1.002251, Ccurrent remains 0.115478, Cnew is now 0.115738
		Training SVM with C=0.115738, nbinputs=100, numruns=20
	testerr[Cnew 0.115738] = 59.170000 > testerr[Ccurrent 0.115478] = 59.170000
	REVERSE: Cstepfactor is now 0.998876, Ccurrent remains 0.115478, Cnew is now 0.115348
		Training SVM with C=0.115348, nbinputs=100, numruns=20
	testerr[Cnew 0.115348] = 60.135000 > testerr[Ccurrent 0.115478] = 59.170000
	REVERSE: Cstepfactor is now 1.000562, Ccurrent remains 0.115478, Cnew is now 0.115543
		Training SVM with C=0.115543, nbinputs=100, numruns=20
	testerr[Cnew 0.115543] = 59.170000 > testerr[Ccurrent 0.115478] = 59.170000
	REVERSE: Cstepfactor is now 0.999719, Ccurrent remains 0.115478, Cnew is now 0.115446
		Training SVM with C=0.115446, nbinputs=100, numruns=20
	testerr[Cnew 0.115446] = 59.170000 > testerr[Ccurrent 0.115478] = 59.170000
	REVERSE: Cstepfactor is now 1.000141, Ccurrent remains 0.115478, Cnew is now 0.115494
		Training SVM with C=0.115494, nbinputs=100, numruns=20
	testerr[Cnew 0.115494] = 59.170000 > testerr[Ccurrent 0.115478] = 59.170000
	REVERSE: Cstepfactor is now 0.999930, Ccurrent remains 0.115478, Cnew is now 0.115470
		Training SVM with C=0.115470, nbinputs=100, numruns=20
	testerr[Cnew 0.115470] = 59.175000 > testerr[Ccurrent 0.115478] = 59.170000
	REVERSE: Cstepfactor is now 1.000035, Ccurrent remains 0.115478, Cnew is now 0.115482
		Training SVM with C=0.115482, nbinputs=100, numruns=20
	testerr[Cnew 0.115482] = 59.170000 > testerr[Ccurrent 0.115478] = 59.170000
	REVERSE: Cstepfactor is now 0.999982, Ccurrent remains 0.115478, Cnew is now 0.115476
	testerr[C 0.010000] = 60.935000 
	testerr[C 0.031623] = 61.295000 
	testerr[C 0.074989] = 61.055000 
	testerr[C 0.100000] = 59.335000 
	testerr[C 0.107461] = 60.150000 
	testerr[C 0.113419] = 60.230000 
	testerr[C 0.114960] = 59.365000 
	testerr[C 0.115348] = 60.135000 
	testerr[C 0.115446] = 59.170000 
	testerr[C 0.115470] = 59.175000 
	testerr[C 0.115478] = 59.170000  *best* (testerr = 59.170000, testerrdev = 2.752290, trainerr = 2.850000, trainerrdev = 1.620960)
	testerr[C 0.115482] = 59.170000 
	testerr[C 0.115494] = 59.170000 
	testerr[C 0.115543] = 59.170000 
	testerr[C 0.115738] = 59.170000 
	testerr[C 0.116522] = 60.665000 
	testerr[C 0.119709] = 59.290000 
	testerr[C 0.133352] = 59.415000 
	testerr[C 0.177828] = 59.995000 
	testerr[C 1.000000] = 61.130000 
...done with SVM validation for 100 examples (numrums=20, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm)...
ceylon.iro.umontreal.ca 2010-08-11 13:29:33.620154: 0:00:32.220000 user+sys, 0:00:56.610000 real, 56.92% usage, 533.79 MB
Starting SVM validation for 1000 examples (numrums=10, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm, PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211, MAXSTEPS=20, STEPFACTOR=10.000000, INITIALC=0.010000)...
ceylon.iro.umontreal.ca 2010-08-11 13:29:33.620377: 0:00:32.220000 user+sys, 0:00:56.610000 real, 56.92% usage, 533.79 MB
		Training SVM with C=0.010000, nbinputs=1000, numruns=10
		Training SVM with C=0.100000, nbinputs=1000, numruns=10
	testerr[Cnew 0.100000] = 53.030000 < testerr[Ccurrent 0.010000] = 53.390000
	NEW BEST: Cbest <= 0.100000, testerr[Cbest] = 53.030000
	PROCEED: Cstepfactor remains 10.000000, Ccurrent is now 0.100000, Cnew is now 1.000000
		Training SVM with C=1.000000, nbinputs=1000, numruns=10
	testerr[Cnew 1.000000] = 54.860000 > testerr[Ccurrent 0.100000] = 53.030000
	REVERSE: Cstepfactor is now 0.316228, Ccurrent remains 0.100000, Cnew is now 0.031623
		Training SVM with C=0.031623, nbinputs=1000, numruns=10
	testerr[Cnew 0.031623] = 53.160000 > testerr[Ccurrent 0.100000] = 53.030000
	REVERSE: Cstepfactor is now 1.778279, Ccurrent remains 0.100000, Cnew is now 0.177828
		Training SVM with C=0.177828, nbinputs=1000, numruns=10
	testerr[Cnew 0.177828] = 53.600000 > testerr[Ccurrent 0.100000] = 53.030000
	REVERSE: Cstepfactor is now 0.749894, Ccurrent remains 0.100000, Cnew is now 0.074989
		Training SVM with C=0.074989, nbinputs=1000, numruns=10
	testerr[Cnew 0.074989] = 53.150000 > testerr[Ccurrent 0.100000] = 53.030000
	REVERSE: Cstepfactor is now 1.154782, Ccurrent remains 0.100000, Cnew is now 0.115478
		Training SVM with C=0.115478, nbinputs=1000, numruns=10
	testerr[Cnew 0.115478] = 53.470000 > testerr[Ccurrent 0.100000] = 53.030000
	REVERSE: Cstepfactor is now 0.930572, Ccurrent remains 0.100000, Cnew is now 0.093057
		Training SVM with C=0.093057, nbinputs=1000, numruns=10
	testerr[Cnew 0.093057] = 53.180000 > testerr[Ccurrent 0.100000] = 53.030000
	REVERSE: Cstepfactor is now 1.036633, Ccurrent remains 0.100000, Cnew is now 0.103663
		Training SVM with C=0.103663, nbinputs=1000, numruns=10
	testerr[Cnew 0.103663] = 53.230000 > testerr[Ccurrent 0.100000] = 53.030000
	REVERSE: Cstepfactor is now 0.982172, Ccurrent remains 0.100000, Cnew is now 0.098217
		Training SVM with C=0.098217, nbinputs=1000, numruns=10
	testerr[Cnew 0.098217] = 53.180000 > testerr[Ccurrent 0.100000] = 53.030000
	REVERSE: Cstepfactor is now 1.009035, Ccurrent remains 0.100000, Cnew is now 0.100904
		Training SVM with C=0.100904, nbinputs=1000, numruns=10
	testerr[Cnew 0.100904] = 53.150000 > testerr[Ccurrent 0.100000] = 53.030000
	REVERSE: Cstepfactor is now 0.995513, Ccurrent remains 0.100000, Cnew is now 0.099551
		Training SVM with C=0.099551, nbinputs=1000, numruns=10
	testerr[Cnew 0.099551] = 53.150000 > testerr[Ccurrent 0.100000] = 53.030000
	REVERSE: Cstepfactor is now 1.002251, Ccurrent remains 0.100000, Cnew is now 0.100225
		Training SVM with C=0.100225, nbinputs=1000, numruns=10
	testerr[Cnew 0.100225] = 53.090000 > testerr[Ccurrent 0.100000] = 53.030000
	REVERSE: Cstepfactor is now 0.998876, Ccurrent remains 0.100000, Cnew is now 0.099888
		Training SVM with C=0.099888, nbinputs=1000, numruns=10
	testerr[Cnew 0.099888] = 53.190000 > testerr[Ccurrent 0.100000] = 53.030000
	REVERSE: Cstepfactor is now 1.000562, Ccurrent remains 0.100000, Cnew is now 0.100056
		Training SVM with C=0.100056, nbinputs=1000, numruns=10
	testerr[Cnew 0.100056] = 53.110000 > testerr[Ccurrent 0.100000] = 53.030000
	REVERSE: Cstepfactor is now 0.999719, Ccurrent remains 0.100000, Cnew is now 0.099972
		Training SVM with C=0.099972, nbinputs=1000, numruns=10
	testerr[Cnew 0.099972] = 53.140000 > testerr[Ccurrent 0.100000] = 53.030000
	REVERSE: Cstepfactor is now 1.000141, Ccurrent remains 0.100000, Cnew is now 0.100014
		Training SVM with C=0.100014, nbinputs=1000, numruns=10
	testerr[Cnew 0.100014] = 53.010000 < testerr[Ccurrent 0.100000] = 53.030000
	NEW BEST: Cbest <= 0.100014, testerr[Cbest] = 53.010000
	PROCEED: Cstepfactor remains 1.000141, Ccurrent is now 0.100014, Cnew is now 0.100028
		Training SVM with C=0.100028, nbinputs=1000, numruns=10
	testerr[Cnew 0.100028] = 53.100000 > testerr[Ccurrent 0.100014] = 53.010000
	REVERSE: Cstepfactor is now 0.999930, Ccurrent remains 0.100014, Cnew is now 0.100007
		Training SVM with C=0.100007, nbinputs=1000, numruns=10
	testerr[Cnew 0.100007] = 53.240000 > testerr[Ccurrent 0.100014] = 53.010000
	REVERSE: Cstepfactor is now 1.000035, Ccurrent remains 0.100014, Cnew is now 0.100018
		Training SVM with C=0.100018, nbinputs=1000, numruns=10
	testerr[Cnew 0.100018] = 53.190000 > testerr[Ccurrent 0.100014] = 53.010000
	REVERSE: Cstepfactor is now 0.999982, Ccurrent remains 0.100014, Cnew is now 0.100012
	testerr[C 0.010000] = 53.390000 
	testerr[C 0.031623] = 53.160000 
	testerr[C 0.074989] = 53.150000 
	testerr[C 0.093057] = 53.180000 
	testerr[C 0.098217] = 53.180000 
	testerr[C 0.099551] = 53.150000 
	testerr[C 0.099888] = 53.190000 
	testerr[C 0.099972] = 53.140000 
	testerr[C 0.100000] = 53.030000 
	testerr[C 0.100007] = 53.240000 
	testerr[C 0.100014] = 53.010000  *best* (testerr = 53.010000, testerrdev = 0.197231, trainerr = 18.520000, trainerrdev = 0.160000)
	testerr[C 0.100018] = 53.190000 
	testerr[C 0.100028] = 53.100000 
	testerr[C 0.100056] = 53.110000 
	testerr[C 0.100225] = 53.090000 
	testerr[C 0.100904] = 53.150000 
	testerr[C 0.103663] = 53.230000 
	testerr[C 0.115478] = 53.470000 
	testerr[C 0.177828] = 53.600000 
	testerr[C 1.000000] = 54.860000 
...done with SVM validation for 1000 examples (numrums=10, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm)...
ceylon.iro.umontreal.ca 2010-08-11 13:30:35.577663: 0:00:32.280000 user+sys, 0:01:58.560000 real, 27.23% usage, 533.79 MB
Starting SVM validation for 10000 examples (numrums=1, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm, PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211, MAXSTEPS=20, STEPFACTOR=10.000000, INITIALC=0.010000)...
ceylon.iro.umontreal.ca 2010-08-11 13:30:35.577892: 0:00:32.280000 user+sys, 0:01:58.560000 real, 27.23% usage, 533.79 MB
		Training SVM with C=0.010000, nbinputs=10000, numruns=1
		Training SVM with C=0.100000, nbinputs=10000, numruns=1
	testerr[Cnew 0.100000] = 53.300000 < testerr[Ccurrent 0.010000] = 53.500000
	NEW BEST: Cbest <= 0.100000, testerr[Cbest] = 53.300000
	PROCEED: Cstepfactor remains 10.000000, Ccurrent is now 0.100000, Cnew is now 1.000000
		Training SVM with C=1.000000, nbinputs=10000, numruns=1
	testerr[Cnew 1.000000] = 54.900000 > testerr[Ccurrent 0.100000] = 53.300000
	REVERSE: Cstepfactor is now 0.316228, Ccurrent remains 0.100000, Cnew is now 0.031623
		Training SVM with C=0.031623, nbinputs=10000, numruns=1
	testerr[Cnew 0.031623] = 52.800000 < testerr[Ccurrent 0.100000] = 53.300000
	NEW BEST: Cbest <= 0.031623, testerr[Cbest] = 52.800000
	PROCEED: Cstepfactor remains 0.316228, Ccurrent is now 0.031623, Cnew is now 0.010000
		Training SVM with C=0.010000, nbinputs=10000, numruns=1
	testerr[Cnew 0.010000] = 53.500000 > testerr[Ccurrent 0.031623] = 52.800000
	REVERSE: Cstepfactor is now 1.778279, Ccurrent remains 0.031623, Cnew is now 0.056234
		Training SVM with C=0.056234, nbinputs=10000, numruns=1
	testerr[Cnew 0.056234] = 52.300000 < testerr[Ccurrent 0.031623] = 52.800000
	NEW BEST: Cbest <= 0.056234, testerr[Cbest] = 52.300000
	PROCEED: Cstepfactor remains 1.778279, Ccurrent is now 0.056234, Cnew is now 0.100000
		Training SVM with C=0.100000, nbinputs=10000, numruns=1
	testerr[Cnew 0.100000] = 53.300000 > testerr[Ccurrent 0.056234] = 52.300000
	REVERSE: Cstepfactor is now 0.749894, Ccurrent remains 0.056234, Cnew is now 0.042170
		Training SVM with C=0.042170, nbinputs=10000, numruns=1
	testerr[Cnew 0.042170] = 52.600000 > testerr[Ccurrent 0.056234] = 52.300000
	REVERSE: Cstepfactor is now 1.154782, Ccurrent remains 0.056234, Cnew is now 0.064938
		Training SVM with C=0.064938, nbinputs=10000, numruns=1
	testerr[Cnew 0.064938] = 53.000000 > testerr[Ccurrent 0.056234] = 52.300000
	REVERSE: Cstepfactor is now 0.930572, Ccurrent remains 0.056234, Cnew is now 0.052330
		Training SVM with C=0.052330, nbinputs=10000, numruns=1
	testerr[Cnew 0.052330] = 52.800000 > testerr[Ccurrent 0.056234] = 52.300000
	REVERSE: Cstepfactor is now 1.036633, Ccurrent remains 0.056234, Cnew is now 0.058294
		Training SVM with C=0.058294, nbinputs=10000, numruns=1
	testerr[Cnew 0.058294] = 52.800000 > testerr[Ccurrent 0.056234] = 52.300000
	REVERSE: Cstepfactor is now 0.982172, Ccurrent remains 0.056234, Cnew is now 0.055232
		Training SVM with C=0.055232, nbinputs=10000, numruns=1
	testerr[Cnew 0.055232] = 52.500000 > testerr[Ccurrent 0.056234] = 52.300000
	REVERSE: Cstepfactor is now 1.009035, Ccurrent remains 0.056234, Cnew is now 0.056742
		Training SVM with C=0.056742, nbinputs=10000, numruns=1
	testerr[Cnew 0.056742] = 52.600000 > testerr[Ccurrent 0.056234] = 52.300000
	REVERSE: Cstepfactor is now 0.995513, Ccurrent remains 0.056234, Cnew is now 0.055982
		Training SVM with C=0.055982, nbinputs=10000, numruns=1
	testerr[Cnew 0.055982] = 52.600000 > testerr[Ccurrent 0.056234] = 52.300000
	REVERSE: Cstepfactor is now 1.002251, Ccurrent remains 0.056234, Cnew is now 0.056361
		Training SVM with C=0.056361, nbinputs=10000, numruns=1
	testerr[Cnew 0.056361] = 52.900000 > testerr[Ccurrent 0.056234] = 52.300000
	REVERSE: Cstepfactor is now 0.998876, Ccurrent remains 0.056234, Cnew is now 0.056171
		Training SVM with C=0.056171, nbinputs=10000, numruns=1
	testerr[Cnew 0.056171] = 52.300000 > testerr[Ccurrent 0.056234] = 52.300000
	REVERSE: Cstepfactor is now 1.000562, Ccurrent remains 0.056234, Cnew is now 0.056266
		Training SVM with C=0.056266, nbinputs=10000, numruns=1
	testerr[Cnew 0.056266] = 52.800000 > testerr[Ccurrent 0.056234] = 52.300000
	REVERSE: Cstepfactor is now 0.999719, Ccurrent remains 0.056234, Cnew is now 0.056218
		Training SVM with C=0.056218, nbinputs=10000, numruns=1
	testerr[Cnew 0.056218] = 52.300000 > testerr[Ccurrent 0.056234] = 52.300000
	REVERSE: Cstepfactor is now 1.000141, Ccurrent remains 0.056234, Cnew is now 0.056242
		Training SVM with C=0.056242, nbinputs=10000, numruns=1
	testerr[Cnew 0.056242] = 52.300000 > testerr[Ccurrent 0.056234] = 52.300000
	REVERSE: Cstepfactor is now 0.999930, Ccurrent remains 0.056234, Cnew is now 0.056230
		Training SVM with C=0.056230, nbinputs=10000, numruns=1
	testerr[Cnew 0.056230] = 52.300000 > testerr[Ccurrent 0.056234] = 52.300000
	REVERSE: Cstepfactor is now 1.000035, Ccurrent remains 0.056234, Cnew is now 0.056236
	testerr[C 0.010000] = 53.500000 
	testerr[C 0.010000] = 53.500000 
	testerr[C 0.031623] = 52.800000 
	testerr[C 0.042170] = 52.600000 
	testerr[C 0.052330] = 52.800000 
	testerr[C 0.055232] = 52.500000 
	testerr[C 0.055982] = 52.600000 
	testerr[C 0.056171] = 52.300000 
	testerr[C 0.056218] = 52.300000 
	testerr[C 0.056230] = 52.300000 
	testerr[C 0.056234] = 52.300000  *best* (testerr = 52.300000, testerrdev = 0.000000, trainerr = 22.800000, trainerrdev = 0.000000)
	testerr[C 0.056242] = 52.300000 
	testerr[C 0.056266] = 52.800000 
	testerr[C 0.056361] = 52.900000 
	testerr[C 0.056742] = 52.600000 
	testerr[C 0.058294] = 52.800000 
	testerr[C 0.064938] = 53.000000 
	testerr[C 0.100000] = 53.300000 
	testerr[C 0.100000] = 53.300000 
	testerr[C 1.000000] = 54.900000 
...done with SVM validation for 10000 examples (numrums=1, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm)...
ceylon.iro.umontreal.ca 2010-08-11 13:30:54.411856: 0:00:32.350000 user+sys, 0:02:17.390000 real, 23.55% usage, 533.79 MB
		----  Encoding  layer #1 ----
			**** DenseLayer.__init__ ****
			tag =  enc1
			inp =  inp
			n_inp =  5000
			n_out =  1000
			act =  tanh
			noise =  binomial_NLP
			out =  outenc1
			params (gradients) =  [Wenc1, benc1]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc1
			allocW, allocb, allocmask =  False False False
MRG_RandomStreams Can't determine #streams from size (Shape.0), guessing 30*256
MRG_RandomStreams Can't determine #streams from size (Shape.0), guessing 30*256
	---- Auxiliary Layer ----
			**** DenseLayer.__init__ ****
			tag =  aux-2
			inp =  outenc1
			n_inp =  1000
			n_out =  5000
			act =  sigmoid
			noise =  None
			out =  outaux-2
			params (gradients) =  [Waux-2, baux-2]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  None
			allocW, allocb, allocmask =  False False ones
	**** SDAE ****
	depth =  3
	mode =  Aux
	depth_min, depth_max, update_type =  0 , 1 , special
	inp, n_inp =  inp , 5000
	n_hid =  [1000, 1000, 1000]
	layertype =  [<class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>]
	act =  ['tanh', 'tanh', 'rectifier']
	noise, noise_lvl =  ['binomial_NLP', 'binomial', 'binomial'] , (0.69999999999999996, 0.0041000000000000003)
	tie =  [True, True, True]
	maskbool =  [None, None, None]
	n_out, outtype =  5 , <class 'deepANN.Logistic_regression.LogisticRegression'>
	lr =  0.01
	sup_scaling, unsup_scaling, aux_scaling  =  None None 1.0
	regularization, wdreg  =  [0.0, 0.0, 0.0, 0.0] , l2
	sparsity, spreg =  [0.0, 0.0, 0.01] , l1
	params, wd, sp =  [Wenc1, benc1, Waux-2, baux-2] , [] , []
	bbbool, hessscal =  None , None
	aux, auxtarget, aux_one_sided, auxdepth, auxregularization =  True , auxtarget , True , -2 , False
	auxact, auxn_out, auxwdreg =  sigmoid , 5000 , l2
##########  TEST ############ EPOCH :  0
CURRENT RECONSTRUCTION ERROR (is this on test or train?):  3466.00485937
CURRENT 100 SVM ERROR:  (0.11547819846894583, 59.170000000000002, 2.7522899999999999, 2.8500000000000001, 1.62096)
CURRENT 1000 SVM ERROR:  (0.10001405485169473, 53.009999999999998, 0.19723099999999999, 18.52, 0.16)
CURRENT 10000 SVM ERROR:  (0.056234132519034918, 52.299999999999997, 0.0, 22.800000000000001, 0.0)
ceylon.iro.umontreal.ca 2010-08-11 13:31:06.645914: 0:00:44.520000 user+sys, 0:02:29.620000 real, 29.76% usage, 533.79 MB
...done validating (err={1000: {0: (0.10001405485169473, 53.009999999999998, 0.19723099999999999, 18.52, 0.16)}, 10000: {0: (0.056234132519034918, 52.299999999999997, 0.0, 22.800000000000001, 0.0)}, 100: {0: (0.11547819846894583, 59.170000000000002, 2.7522899999999999, 2.8500000000000001, 1.62096)}},epoch=0,model=<deepANN.ANN.SDAE object at 0x30fcb50>,depth=0,ACT=['tanh', 'tanh', 'rectifier'],LR=0.01,NOISE_LVL=(0.69999999999999996, 0.0041000000000000003),BATCHSIZE=10,train=<CudaNdarrayType(float32, matrix)>,datatrain=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_labels_1.pkl'),datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm,datatest=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_labels_1.pkl'),datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm,VALIDATION_TRAININGSIZE=[100, 1000, 10000],VALIDATION_RUNS_FOR_EACH_TRAININGSIZE={'100': 20, '10000': 1, '1000': 10},PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211)
ceylon.iro.umontreal.ca 2010-08-11 13:31:06.646220: 0:00:44.520000 user+sys, 0:02:29.620000 real, 29.76% usage, 533.79 MB
File: 1 29.3074700832 ----
ceylon.iro.umontreal.ca 2010-08-11 13:31:35.953848: 0:01:13.820000 user+sys, 0:02:58.930000 real, 41.26% usage, 533.79 MB
File: 2 29.2288959026 ----
ceylon.iro.umontreal.ca 2010-08-11 13:32:05.183789: 0:01:43.040000 user+sys, 0:03:28.150000 real, 49.50% usage, 533.79 MB
File: 3 29.2303950787 ----
ceylon.iro.umontreal.ca 2010-08-11 13:32:34.414695: 0:02:12.250000 user+sys, 0:03:57.380000 real, 55.71% usage, 533.79 MB
File: 4 29.2439680099 ----
ceylon.iro.umontreal.ca 2010-08-11 13:33:03.659159: 0:02:41.420000 user+sys, 0:04:26.620000 real, 60.54% usage, 533.79 MB
File: 5 29.2220611572 ----
ceylon.iro.umontreal.ca 2010-08-11 13:33:32.881724: 0:03:10.640000 user+sys, 0:04:55.840000 real, 64.44% usage, 533.79 MB
File: 6 29.283520937 ----
ceylon.iro.umontreal.ca 2010-08-11 13:34:02.165749: 0:03:39.900000 user+sys, 0:05:25.110000 real, 67.64% usage, 533.79 MB
File: 7 29.4103450775 ----
ceylon.iro.umontreal.ca 2010-08-11 13:34:31.576596: 0:04:09.280000 user+sys, 0:05:54.520000 real, 70.31% usage, 533.79 MB
File: 8 29.5253651142 ----
ceylon.iro.umontreal.ca 2010-08-11 13:35:01.102627: 0:04:38.750000 user+sys, 0:06:24.040000 real, 72.58% usage, 533.79 MB
File: 9 29.5021688938 ----
ceylon.iro.umontreal.ca 2010-08-11 13:35:30.605521: 0:05:08.240000 user+sys, 0:06:53.540000 real, 74.54% usage, 533.79 MB
File: 10 29.4196081161 ----
ceylon.iro.umontreal.ca 2010-08-11 13:36:00.025856: 0:05:37.650000 user+sys, 0:07:22.960000 real, 76.23% usage, 533.79 MB
File: 11 29.5256512165 ----
ceylon.iro.umontreal.ca 2010-08-11 13:36:29.552249: 0:06:06.970000 user+sys, 0:07:52.480000 real, 77.67% usage, 533.79 MB
File: 12 29.2560710907 ----
ceylon.iro.umontreal.ca 2010-08-11 13:36:58.809077: 0:06:36.220000 user+sys, 0:08:21.730000 real, 78.97% usage, 533.79 MB
File: 13 29.2632699013 ----
ceylon.iro.umontreal.ca 2010-08-11 13:37:28.072918: 0:07:05.420000 user+sys, 0:08:50.990000 real, 80.12% usage, 533.79 MB
File: 14 29.2612159252 ----
ceylon.iro.umontreal.ca 2010-08-11 13:37:57.334657: 0:07:34.640000 user+sys, 0:09:20.250000 real, 81.15% usage, 533.79 MB
File: 15 27.837608099 ----
ceylon.iro.umontreal.ca 2010-08-11 13:38:25.172763: 0:08:02.440000 user+sys, 0:09:48.080000 real, 82.04% usage, 533.79 MB
...finished training epoch #1 of 3 (33.33%)
ceylon.iro.umontreal.ca 2010-08-11 13:38:25.173221: 0:08:02.440000 user+sys, 0:09:48.080000 real, 82.04% usage, 533.79 MB
Validating (err={1000: {0: (0.10001405485169473, 53.009999999999998, 0.19723099999999999, 18.52, 0.16)}, 10000: {0: (0.056234132519034918, 52.299999999999997, 0.0, 22.800000000000001, 0.0)}, 100: {0: (0.11547819846894583, 59.170000000000002, 2.7522899999999999, 2.8500000000000001, 1.62096)}},epoch=1,model=<deepANN.ANN.SDAE object at 0x30fcb50>,depth=0,ACT=['tanh', 'tanh', 'rectifier'],LR=0.01,NOISE_LVL=(0.69999999999999996, 0.0041000000000000003),BATCHSIZE=10,train=<CudaNdarrayType(float32, matrix)>,datatrain=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_labels_1.pkl'),datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm,datatest=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_labels_1.pkl'),datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm,VALIDATION_TRAININGSIZE=[100, 1000, 10000],VALIDATION_RUNS_FOR_EACH_TRAININGSIZE={'100': 20, '10000': 1, '1000': 10},PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211)...
ceylon.iro.umontreal.ca 2010-08-11 13:38:25.173492: 0:08:02.440000 user+sys, 0:09:48.080000 real, 82.04% usage, 533.79 MB
		----  Encoding  layer #1 ----
			**** DenseLayer.__init__ ****
			tag =  enc1
			inp =  inp
			n_inp =  5000
			n_out =  1000
			act =  tanh
			noise =  binomial_NLP
			out =  outenc1
			params (gradients) =  [Wenc1, benc1]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc1
			allocW, allocb, allocmask =  False False False
	---- Auxiliary Layer ----
			**** DenseLayer.__init__ ****
			tag =  aux-2
			inp =  outenc1
			n_inp =  1000
			n_out =  5000
			act =  sigmoid
			noise =  None
			out =  outaux-2
			params (gradients) =  [Waux-2, baux-2]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  None
			allocW, allocb, allocmask =  False False ones
	**** SDAE ****
	depth =  3
	mode =  Aux
	depth_min, depth_max, update_type =  0 , 1 , special
	inp, n_inp =  inp , 5000
	n_hid =  [1000, 1000, 1000]
	layertype =  [<class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>]
	act =  ['tanh', 'tanh', 'rectifier']
	noise, noise_lvl =  ['binomial_NLP', 'binomial', 'binomial'] , None
	tie =  [True, True, True]
	maskbool =  [None, None, None]
	n_out, outtype =  5 , <class 'deepANN.Logistic_regression.LogisticRegression'>
	lr =  0.01
	sup_scaling, unsup_scaling, aux_scaling  =  None None 1.0
	regularization, wdreg  =  [0.0, 0.0, 0.0, 0.0] , l2
	sparsity, spreg =  [0.0, 0.0, 0.01] , l1
	params, wd, sp =  [Wenc1, benc1, Waux-2, baux-2] , [] , []
	bbbool, hessscal =  None , None
	aux, auxtarget, aux_one_sided, auxdepth, auxregularization =  True , auxtarget , True , -2 , False
	auxact, auxn_out, auxwdreg =  sigmoid , 5000 , l2
Creating libsvm file '/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm' (model=<deepANN.ANN.SDAE object at 0x30fcb50>, depth=0, datafiles=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_labels_1.pkl'))...
ceylon.iro.umontreal.ca 2010-08-11 13:38:27.910988: 0:08:05.050000 user+sys, 0:09:50.820000 real, 82.10% usage, 533.79 MB
...done creating libsvm files
ceylon.iro.umontreal.ca 2010-08-11 13:38:37.999779: 0:08:14.920000 user+sys, 0:10:00.910000 real, 82.36% usage, 533.79 MB
Creating libsvm file '/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm' (model=<deepANN.ANN.SDAE object at 0x30fcb50>, depth=0, datafiles=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_labels_1.pkl'))...
ceylon.iro.umontreal.ca 2010-08-11 13:38:38.000076: 0:08:14.920000 user+sys, 0:10:00.910000 real, 82.36% usage, 533.79 MB
...done creating libsvm files
ceylon.iro.umontreal.ca 2010-08-11 13:38:48.090336: 0:08:24.820000 user+sys, 0:10:11 real, 82.62% usage, 533.79 MB
Starting SVM validation for 100 examples (numrums=20, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm, PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211, MAXSTEPS=20, STEPFACTOR=10.000000, INITIALC=0.010000)...
ceylon.iro.umontreal.ca 2010-08-11 13:38:48.090650: 0:08:24.820000 user+sys, 0:10:11 real, 82.62% usage, 533.79 MB
		Training SVM with C=0.010000, nbinputs=100, numruns=20
		Training SVM with C=0.100000, nbinputs=100, numruns=20
	testerr[Cnew 0.100000] = 58.720000 > testerr[Ccurrent 0.010000] = 55.130000
	Cbest <= 0.010000, testerr[Cbest] = 55.130000
	REVERSE: Cstepfactor is now 0.316228, Ccurrent remains 0.010000, Cnew is now 0.003162
		Training SVM with C=0.003162, nbinputs=100, numruns=20
	testerr[Cnew 0.003162] = 55.100000 < testerr[Ccurrent 0.010000] = 55.130000
	NEW BEST: Cbest <= 0.003162, testerr[Cbest] = 55.100000
	PROCEED: Cstepfactor remains 0.316228, Ccurrent is now 0.003162, Cnew is now 0.001000
		Training SVM with C=0.001000, nbinputs=100, numruns=20
	testerr[Cnew 0.001000] = 58.000000 > testerr[Ccurrent 0.003162] = 55.100000
	REVERSE: Cstepfactor is now 1.778279, Ccurrent remains 0.003162, Cnew is now 0.005623
		Training SVM with C=0.005623, nbinputs=100, numruns=20
	testerr[Cnew 0.005623] = 55.805000 > testerr[Ccurrent 0.003162] = 55.100000
	REVERSE: Cstepfactor is now 0.749894, Ccurrent remains 0.003162, Cnew is now 0.002371
		Training SVM with C=0.002371, nbinputs=100, numruns=20
	testerr[Cnew 0.002371] = 55.405000 > testerr[Ccurrent 0.003162] = 55.100000
	REVERSE: Cstepfactor is now 1.154782, Ccurrent remains 0.003162, Cnew is now 0.003652
		Training SVM with C=0.003652, nbinputs=100, numruns=20
	testerr[Cnew 0.003652] = 55.145000 > testerr[Ccurrent 0.003162] = 55.100000
	REVERSE: Cstepfactor is now 0.930572, Ccurrent remains 0.003162, Cnew is now 0.002943
		Training SVM with C=0.002943, nbinputs=100, numruns=20
	testerr[Cnew 0.002943] = 57.245000 > testerr[Ccurrent 0.003162] = 55.100000
	REVERSE: Cstepfactor is now 1.036633, Ccurrent remains 0.003162, Cnew is now 0.003278
		Training SVM with C=0.003278, nbinputs=100, numruns=20
	testerr[Cnew 0.003278] = 54.830000 < testerr[Ccurrent 0.003162] = 55.100000
	NEW BEST: Cbest <= 0.003278, testerr[Cbest] = 54.830000
	PROCEED: Cstepfactor remains 1.036633, Ccurrent is now 0.003278, Cnew is now 0.003398
		Training SVM with C=0.003398, nbinputs=100, numruns=20
	testerr[Cnew 0.003398] = 56.020000 > testerr[Ccurrent 0.003278] = 54.830000
	REVERSE: Cstepfactor is now 0.982172, Ccurrent remains 0.003278, Cnew is now 0.003220
		Training SVM with C=0.003220, nbinputs=100, numruns=20
	testerr[Cnew 0.003220] = 54.180000 < testerr[Ccurrent 0.003278] = 54.830000
	NEW BEST: Cbest <= 0.003220, testerr[Cbest] = 54.180000
	PROCEED: Cstepfactor remains 0.982172, Ccurrent is now 0.003220, Cnew is now 0.003162
		Training SVM with C=0.003162, nbinputs=100, numruns=20
	testerr[Cnew 0.003162] = 55.100000 > testerr[Ccurrent 0.003220] = 54.180000
	REVERSE: Cstepfactor is now 1.009035, Ccurrent remains 0.003220, Cnew is now 0.003249
		Training SVM with C=0.003249, nbinputs=100, numruns=20
	testerr[Cnew 0.003249] = 54.860000 > testerr[Ccurrent 0.003220] = 54.180000
	REVERSE: Cstepfactor is now 0.995513, Ccurrent remains 0.003220, Cnew is now 0.003205
		Training SVM with C=0.003205, nbinputs=100, numruns=20
	testerr[Cnew 0.003205] = 55.840000 > testerr[Ccurrent 0.003220] = 54.180000
	REVERSE: Cstepfactor is now 1.002251, Ccurrent remains 0.003220, Cnew is now 0.003227
		Training SVM with C=0.003227, nbinputs=100, numruns=20
	testerr[Cnew 0.003227] = 54.440000 > testerr[Ccurrent 0.003220] = 54.180000
	REVERSE: Cstepfactor is now 0.998876, Ccurrent remains 0.003220, Cnew is now 0.003216
		Training SVM with C=0.003216, nbinputs=100, numruns=20
	testerr[Cnew 0.003216] = 55.440000 > testerr[Ccurrent 0.003220] = 54.180000
	REVERSE: Cstepfactor is now 1.000562, Ccurrent remains 0.003220, Cnew is now 0.003221
		Training SVM with C=0.003221, nbinputs=100, numruns=20
	testerr[Cnew 0.003221] = 53.880000 < testerr[Ccurrent 0.003220] = 54.180000
	NEW BEST: Cbest <= 0.003221, testerr[Cbest] = 53.880000
	PROCEED: Cstepfactor remains 1.000562, Ccurrent is now 0.003221, Cnew is now 0.003223
		Training SVM with C=0.003223, nbinputs=100, numruns=20
	testerr[Cnew 0.003223] = 55.085000 > testerr[Ccurrent 0.003221] = 53.880000
	REVERSE: Cstepfactor is now 0.999719, Ccurrent remains 0.003221, Cnew is now 0.003221
		Training SVM with C=0.003221, nbinputs=100, numruns=20
	testerr[Cnew 0.003221] = 54.180000 > testerr[Ccurrent 0.003221] = 53.880000
	REVERSE: Cstepfactor is now 1.000141, Ccurrent remains 0.003221, Cnew is now 0.003222
		Training SVM with C=0.003222, nbinputs=100, numruns=20
	testerr[Cnew 0.003222] = 53.880000 > testerr[Ccurrent 0.003221] = 53.880000
	REVERSE: Cstepfactor is now 0.999930, Ccurrent remains 0.003221, Cnew is now 0.003221
	testerr[C 0.001000] = 58.000000 
	testerr[C 0.002371] = 55.405000 
	testerr[C 0.002943] = 57.245000 
	testerr[C 0.003162] = 55.100000 
	testerr[C 0.003162] = 55.100000 
	testerr[C 0.003205] = 55.840000 
	testerr[C 0.003216] = 55.440000 
	testerr[C 0.003220] = 54.180000 
	testerr[C 0.003221] = 54.180000 
	testerr[C 0.003221] = 53.880000  *best* (testerr = 53.880000, testerrdev = 2.412800, trainerr = 17.800000, trainerrdev = 3.668790)
	testerr[C 0.003222] = 53.880000 
	testerr[C 0.003223] = 55.085000 
	testerr[C 0.003227] = 54.440000 
	testerr[C 0.003249] = 54.860000 
	testerr[C 0.003278] = 54.830000 
	testerr[C 0.003398] = 56.020000 
	testerr[C 0.003652] = 55.145000 
	testerr[C 0.005623] = 55.805000 
	testerr[C 0.010000] = 55.130000 
	testerr[C 0.100000] = 58.720000 
...done with SVM validation for 100 examples (numrums=20, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm)...
ceylon.iro.umontreal.ca 2010-08-11 13:39:14.641232: 0:08:24.880000 user+sys, 0:10:37.540000 real, 79.19% usage, 533.79 MB
Starting SVM validation for 1000 examples (numrums=10, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm, PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211, MAXSTEPS=20, STEPFACTOR=10.000000, INITIALC=0.010000)...
ceylon.iro.umontreal.ca 2010-08-11 13:39:14.641458: 0:08:24.880000 user+sys, 0:10:37.540000 real, 79.19% usage, 533.79 MB
		Training SVM with C=0.010000, nbinputs=1000, numruns=10
		Training SVM with C=0.100000, nbinputs=1000, numruns=10
	testerr[Cnew 0.100000] = 54.970000 > testerr[Ccurrent 0.010000] = 47.730000
	Cbest <= 0.010000, testerr[Cbest] = 47.730000
	REVERSE: Cstepfactor is now 0.316228, Ccurrent remains 0.010000, Cnew is now 0.003162
		Training SVM with C=0.003162, nbinputs=1000, numruns=10
	testerr[Cnew 0.003162] = 47.420000 < testerr[Ccurrent 0.010000] = 47.730000
	NEW BEST: Cbest <= 0.003162, testerr[Cbest] = 47.420000
	PROCEED: Cstepfactor remains 0.316228, Ccurrent is now 0.003162, Cnew is now 0.001000
		Training SVM with C=0.001000, nbinputs=1000, numruns=10
	testerr[Cnew 0.001000] = 49.660000 > testerr[Ccurrent 0.003162] = 47.420000
	REVERSE: Cstepfactor is now 1.778279, Ccurrent remains 0.003162, Cnew is now 0.005623
		Training SVM with C=0.005623, nbinputs=1000, numruns=10
	testerr[Cnew 0.005623] = 47.200000 < testerr[Ccurrent 0.003162] = 47.420000
	NEW BEST: Cbest <= 0.005623, testerr[Cbest] = 47.200000
	PROCEED: Cstepfactor remains 1.778279, Ccurrent is now 0.005623, Cnew is now 0.010000
	testerr[Cnew 0.010000] = 47.730000 > testerr[Ccurrent 0.005623] = 47.200000
	REVERSE: Cstepfactor is now 0.749894, Ccurrent remains 0.005623, Cnew is now 0.004217
		Training SVM with C=0.004217, nbinputs=1000, numruns=10
	testerr[Cnew 0.004217] = 47.120000 < testerr[Ccurrent 0.005623] = 47.200000
	NEW BEST: Cbest <= 0.004217, testerr[Cbest] = 47.120000
	PROCEED: Cstepfactor remains 0.749894, Ccurrent is now 0.004217, Cnew is now 0.003162
		Training SVM with C=0.003162, nbinputs=1000, numruns=10
	testerr[Cnew 0.003162] = 47.420000 > testerr[Ccurrent 0.004217] = 47.120000
	REVERSE: Cstepfactor is now 1.154782, Ccurrent remains 0.004217, Cnew is now 0.004870
		Training SVM with C=0.004870, nbinputs=1000, numruns=10
	testerr[Cnew 0.004870] = 47.000000 < testerr[Ccurrent 0.004217] = 47.120000
	NEW BEST: Cbest <= 0.004870, testerr[Cbest] = 47.000000
	PROCEED: Cstepfactor remains 1.154782, Ccurrent is now 0.004870, Cnew is now 0.005623
		Training SVM with C=0.005623, nbinputs=1000, numruns=10
	testerr[Cnew 0.005623] = 47.200000 > testerr[Ccurrent 0.004870] = 47.000000
	REVERSE: Cstepfactor is now 0.930572, Ccurrent remains 0.004870, Cnew is now 0.004532
		Training SVM with C=0.004532, nbinputs=1000, numruns=10
	testerr[Cnew 0.004532] = 47.030000 > testerr[Ccurrent 0.004870] = 47.000000
	REVERSE: Cstepfactor is now 1.036633, Ccurrent remains 0.004870, Cnew is now 0.005048
		Training SVM with C=0.005048, nbinputs=1000, numruns=10
	testerr[Cnew 0.005048] = 46.870000 < testerr[Ccurrent 0.004870] = 47.000000
	NEW BEST: Cbest <= 0.005048, testerr[Cbest] = 46.870000
	PROCEED: Cstepfactor remains 1.036633, Ccurrent is now 0.005048, Cnew is now 0.005233
		Training SVM with C=0.005233, nbinputs=1000, numruns=10
	testerr[Cnew 0.005233] = 47.160000 > testerr[Ccurrent 0.005048] = 46.870000
	REVERSE: Cstepfactor is now 0.982172, Ccurrent remains 0.005048, Cnew is now 0.004958
		Training SVM with C=0.004958, nbinputs=1000, numruns=10
	testerr[Cnew 0.004958] = 46.930000 > testerr[Ccurrent 0.005048] = 46.870000
	REVERSE: Cstepfactor is now 1.009035, Ccurrent remains 0.005048, Cnew is now 0.005094
		Training SVM with C=0.005094, nbinputs=1000, numruns=10
	testerr[Cnew 0.005094] = 47.130000 > testerr[Ccurrent 0.005048] = 46.870000
	REVERSE: Cstepfactor is now 0.995513, Ccurrent remains 0.005048, Cnew is now 0.005025
		Training SVM with C=0.005025, nbinputs=1000, numruns=10
	testerr[Cnew 0.005025] = 46.890000 > testerr[Ccurrent 0.005048] = 46.870000
	REVERSE: Cstepfactor is now 1.002251, Ccurrent remains 0.005048, Cnew is now 0.005059
		Training SVM with C=0.005059, nbinputs=1000, numruns=10
	testerr[Cnew 0.005059] = 46.930000 > testerr[Ccurrent 0.005048] = 46.870000
	REVERSE: Cstepfactor is now 0.998876, Ccurrent remains 0.005048, Cnew is now 0.005042
		Training SVM with C=0.005042, nbinputs=1000, numruns=10
	testerr[Cnew 0.005042] = 46.990000 > testerr[Ccurrent 0.005048] = 46.870000
	REVERSE: Cstepfactor is now 1.000562, Ccurrent remains 0.005048, Cnew is now 0.005051
		Training SVM with C=0.005051, nbinputs=1000, numruns=10
	testerr[Cnew 0.005051] = 47.110000 > testerr[Ccurrent 0.005048] = 46.870000
	REVERSE: Cstepfactor is now 0.999719, Ccurrent remains 0.005048, Cnew is now 0.005047
		Training SVM with C=0.005047, nbinputs=1000, numruns=10
	testerr[Cnew 0.005047] = 46.940000 > testerr[Ccurrent 0.005048] = 46.870000
	REVERSE: Cstepfactor is now 1.000141, Ccurrent remains 0.005048, Cnew is now 0.005049
		Training SVM with C=0.005049, nbinputs=1000, numruns=10
	testerr[Cnew 0.005049] = 47.100000 > testerr[Ccurrent 0.005048] = 46.870000
	REVERSE: Cstepfactor is now 0.999930, Ccurrent remains 0.005048, Cnew is now 0.005048
	testerr[C 0.001000] = 49.660000 
	testerr[C 0.003162] = 47.420000 
	testerr[C 0.003162] = 47.420000 
	testerr[C 0.004217] = 47.120000 
	testerr[C 0.004532] = 47.030000 
	testerr[C 0.004870] = 47.000000 
	testerr[C 0.004958] = 46.930000 
	testerr[C 0.005025] = 46.890000 
	testerr[C 0.005042] = 46.990000 
	testerr[C 0.005047] = 46.940000 
	testerr[C 0.005048] = 46.870000  *best* (testerr = 46.870000, testerrdev = 0.232594, trainerr = 29.260000, trainerrdev = 0.162481)
	testerr[C 0.005049] = 47.100000 
	testerr[C 0.005051] = 47.110000 
	testerr[C 0.005059] = 46.930000 
	testerr[C 0.005094] = 47.130000 
	testerr[C 0.005233] = 47.160000 
	testerr[C 0.005623] = 47.200000 
	testerr[C 0.005623] = 47.200000 
	testerr[C 0.010000] = 47.730000 
	testerr[C 0.100000] = 54.970000 
...done with SVM validation for 1000 examples (numrums=10, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm)...
ceylon.iro.umontreal.ca 2010-08-11 13:40:38.606832: 0:08:24.950000 user+sys, 0:12:01.500000 real, 69.99% usage, 533.79 MB
Starting SVM validation for 10000 examples (numrums=1, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm, PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211, MAXSTEPS=20, STEPFACTOR=10.000000, INITIALC=0.010000)...
ceylon.iro.umontreal.ca 2010-08-11 13:40:38.607045: 0:08:24.950000 user+sys, 0:12:01.500000 real, 69.99% usage, 533.79 MB
		Training SVM with C=0.010000, nbinputs=10000, numruns=1
		Training SVM with C=0.100000, nbinputs=10000, numruns=1
	testerr[Cnew 0.100000] = 55.000000 > testerr[Ccurrent 0.010000] = 47.400000
	Cbest <= 0.010000, testerr[Cbest] = 47.400000
	REVERSE: Cstepfactor is now 0.316228, Ccurrent remains 0.010000, Cnew is now 0.003162
		Training SVM with C=0.003162, nbinputs=10000, numruns=1
	testerr[Cnew 0.003162] = 47.600000 > testerr[Ccurrent 0.010000] = 47.400000
	REVERSE: Cstepfactor is now 1.778279, Ccurrent remains 0.010000, Cnew is now 0.017783
		Training SVM with C=0.017783, nbinputs=10000, numruns=1
	testerr[Cnew 0.017783] = 49.600000 > testerr[Ccurrent 0.010000] = 47.400000
	REVERSE: Cstepfactor is now 0.749894, Ccurrent remains 0.010000, Cnew is now 0.007499
		Training SVM with C=0.007499, nbinputs=10000, numruns=1
	testerr[Cnew 0.007499] = 48.100000 > testerr[Ccurrent 0.010000] = 47.400000
	REVERSE: Cstepfactor is now 1.154782, Ccurrent remains 0.010000, Cnew is now 0.011548
		Training SVM with C=0.011548, nbinputs=10000, numruns=1
	testerr[Cnew 0.011548] = 48.700000 > testerr[Ccurrent 0.010000] = 47.400000
	REVERSE: Cstepfactor is now 0.930572, Ccurrent remains 0.010000, Cnew is now 0.009306
		Training SVM with C=0.009306, nbinputs=10000, numruns=1
	testerr[Cnew 0.009306] = 47.300000 < testerr[Ccurrent 0.010000] = 47.400000
	NEW BEST: Cbest <= 0.009306, testerr[Cbest] = 47.300000
	PROCEED: Cstepfactor remains 0.930572, Ccurrent is now 0.009306, Cnew is now 0.008660
		Training SVM with C=0.008660, nbinputs=10000, numruns=1
	testerr[Cnew 0.008660] = 48.100000 > testerr[Ccurrent 0.009306] = 47.300000
	REVERSE: Cstepfactor is now 1.036633, Ccurrent remains 0.009306, Cnew is now 0.009647
		Training SVM with C=0.009647, nbinputs=10000, numruns=1
	testerr[Cnew 0.009647] = 47.400000 > testerr[Ccurrent 0.009306] = 47.300000
	REVERSE: Cstepfactor is now 0.982172, Ccurrent remains 0.009306, Cnew is now 0.009140
		Training SVM with C=0.009140, nbinputs=10000, numruns=1
	testerr[Cnew 0.009140] = 47.900000 > testerr[Ccurrent 0.009306] = 47.300000
	REVERSE: Cstepfactor is now 1.009035, Ccurrent remains 0.009306, Cnew is now 0.009390
		Training SVM with C=0.009390, nbinputs=10000, numruns=1
	testerr[Cnew 0.009390] = 47.700000 > testerr[Ccurrent 0.009306] = 47.300000
	REVERSE: Cstepfactor is now 0.995513, Ccurrent remains 0.009306, Cnew is now 0.009264
		Training SVM with C=0.009264, nbinputs=10000, numruns=1
	testerr[Cnew 0.009264] = 48.000000 > testerr[Ccurrent 0.009306] = 47.300000
	REVERSE: Cstepfactor is now 1.002251, Ccurrent remains 0.009306, Cnew is now 0.009327
		Training SVM with C=0.009327, nbinputs=10000, numruns=1
	testerr[Cnew 0.009327] = 47.900000 > testerr[Ccurrent 0.009306] = 47.300000
	REVERSE: Cstepfactor is now 0.998876, Ccurrent remains 0.009306, Cnew is now 0.009295
		Training SVM with C=0.009295, nbinputs=10000, numruns=1
	testerr[Cnew 0.009295] = 47.700000 > testerr[Ccurrent 0.009306] = 47.300000
	REVERSE: Cstepfactor is now 1.000562, Ccurrent remains 0.009306, Cnew is now 0.009311
		Training SVM with C=0.009311, nbinputs=10000, numruns=1
	testerr[Cnew 0.009311] = 47.700000 > testerr[Ccurrent 0.009306] = 47.300000
	REVERSE: Cstepfactor is now 0.999719, Ccurrent remains 0.009306, Cnew is now 0.009303
		Training SVM with C=0.009303, nbinputs=10000, numruns=1
	testerr[Cnew 0.009303] = 47.300000 > testerr[Ccurrent 0.009306] = 47.300000
	REVERSE: Cstepfactor is now 1.000141, Ccurrent remains 0.009306, Cnew is now 0.009307
		Training SVM with C=0.009307, nbinputs=10000, numruns=1
	testerr[Cnew 0.009307] = 48.200000 > testerr[Ccurrent 0.009306] = 47.300000
	REVERSE: Cstepfactor is now 0.999930, Ccurrent remains 0.009306, Cnew is now 0.009305
		Training SVM with C=0.009305, nbinputs=10000, numruns=1
	testerr[Cnew 0.009305] = 47.300000 > testerr[Ccurrent 0.009306] = 47.300000
	REVERSE: Cstepfactor is now 1.000035, Ccurrent remains 0.009306, Cnew is now 0.009306
		Training SVM with C=0.009306, nbinputs=10000, numruns=1
	testerr[Cnew 0.009306] = 48.200000 > testerr[Ccurrent 0.009306] = 47.300000
	REVERSE: Cstepfactor is now 0.999982, Ccurrent remains 0.009306, Cnew is now 0.009306
		Training SVM with C=0.009306, nbinputs=10000, numruns=1
	testerr[Cnew 0.009306] = 47.300000 > testerr[Ccurrent 0.009306] = 47.300000
	REVERSE: Cstepfactor is now 1.000009, Ccurrent remains 0.009306, Cnew is now 0.009306
	testerr[C 0.003162] = 47.600000 
	testerr[C 0.007499] = 48.100000 
	testerr[C 0.008660] = 48.100000 
	testerr[C 0.009140] = 47.900000 
	testerr[C 0.009264] = 48.000000 
	testerr[C 0.009295] = 47.700000 
	testerr[C 0.009303] = 47.300000 
	testerr[C 0.009305] = 47.300000 
	testerr[C 0.009306] = 47.300000 
	testerr[C 0.009306] = 47.300000  *best* (testerr = 47.300000, testerrdev = 0.000000, trainerr = 25.000000, trainerrdev = 0.000000)
	testerr[C 0.009306] = 48.200000 
	testerr[C 0.009307] = 48.200000 
	testerr[C 0.009311] = 47.700000 
	testerr[C 0.009327] = 47.900000 
	testerr[C 0.009390] = 47.700000 
	testerr[C 0.009647] = 47.400000 
	testerr[C 0.010000] = 47.400000 
	testerr[C 0.011548] = 48.700000 
	testerr[C 0.017783] = 49.600000 
	testerr[C 0.100000] = 55.000000 
...done with SVM validation for 10000 examples (numrums=1, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm)...
ceylon.iro.umontreal.ca 2010-08-11 13:41:02.421462: 0:08:25.010000 user+sys, 0:12:25.310000 real, 67.76% usage, 533.79 MB
		----  Encoding  layer #1 ----
			**** DenseLayer.__init__ ****
			tag =  enc1
			inp =  inp
			n_inp =  5000
			n_out =  1000
			act =  tanh
			noise =  binomial_NLP
			out =  outenc1
			params (gradients) =  [Wenc1, benc1]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc1
			allocW, allocb, allocmask =  False False False
MRG_RandomStreams Can't determine #streams from size (Shape.0), guessing 30*256
MRG_RandomStreams Can't determine #streams from size (Shape.0), guessing 30*256
	---- Auxiliary Layer ----
			**** DenseLayer.__init__ ****
			tag =  aux-2
			inp =  outenc1
			n_inp =  1000
			n_out =  5000
			act =  sigmoid
			noise =  None
			out =  outaux-2
			params (gradients) =  [Waux-2, baux-2]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  None
			allocW, allocb, allocmask =  False False ones
	**** SDAE ****
	depth =  3
	mode =  Aux
	depth_min, depth_max, update_type =  0 , 1 , special
	inp, n_inp =  inp , 5000
	n_hid =  [1000, 1000, 1000]
	layertype =  [<class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>]
	act =  ['tanh', 'tanh', 'rectifier']
	noise, noise_lvl =  ['binomial_NLP', 'binomial', 'binomial'] , (0.69999999999999996, 0.0041000000000000003)
	tie =  [True, True, True]
	maskbool =  [None, None, None]
	n_out, outtype =  5 , <class 'deepANN.Logistic_regression.LogisticRegression'>
	lr =  0.01
	sup_scaling, unsup_scaling, aux_scaling  =  None None 1.0
	regularization, wdreg  =  [0.0, 0.0, 0.0, 0.0] , l2
	sparsity, spreg =  [0.0, 0.0, 0.01] , l1
	params, wd, sp =  [Wenc1, benc1, Waux-2, baux-2] , [] , []
	bbbool, hessscal =  None , None
	aux, auxtarget, aux_one_sided, auxdepth, auxregularization =  True , auxtarget , True , -2 , False
	auxact, auxn_out, auxwdreg =  sigmoid , 5000 , l2
##########  TEST ############ EPOCH :  1
CURRENT RECONSTRUCTION ERROR (is this on test or train?):  98.4821807861
CURRENT 100 SVM ERROR:  (0.0032214889100156403, 53.880000000000003, 2.4127999999999998, 17.800000000000001, 3.66879)
CURRENT 1000 SVM ERROR:  (0.0050480657166674719, 46.869999999999997, 0.232594, 29.260000000000002, 0.16248099999999999)
CURRENT 10000 SVM ERROR:  (0.0093057204092969886, 47.299999999999997, 0.0, 25.0, 0.0)
ceylon.iro.umontreal.ca 2010-08-11 13:41:15.583132: 0:08:38.040000 user+sys, 0:12:38.470000 real, 68.30% usage, 533.79 MB
params.pkl saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth1pre1
Wenc1 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth1pre1/Layer1_W.pkl
benc1 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth1pre1/Layer1_b.pkl
maskenc1 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth1pre1/Layer1_mask.pkl
Wenc2 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth1pre1/Layer2_W.pkl
benc2 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth1pre1/Layer2_b.pkl
maskenc2 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth1pre1/Layer2_mask.pkl
Wenc3 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth1pre1/Layer3_W.pkl
benc3 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth1pre1/Layer3_b.pkl
maskenc3 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth1pre1/Layer3_mask.pkl
Waux-2 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth1pre1/Layeraux_W.pkl
baux-2 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth1pre1/Layeraux_b.pkl
maskaux-2 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth1pre1/Layeraux_mask.pkl
W saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth1pre1/Layerout_W.pkl
b saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth1pre1/Layerout_b.pkl
saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth1pre1
...done validating (err={1000: {0: (0.10001405485169473, 53.009999999999998, 0.19723099999999999, 18.52, 0.16), 1: (0.0050480657166674719, 46.869999999999997, 0.232594, 29.260000000000002, 0.16248099999999999)}, 10000: {0: (0.056234132519034918, 52.299999999999997, 0.0, 22.800000000000001, 0.0), 1: (0.0093057204092969886, 47.299999999999997, 0.0, 25.0, 0.0)}, 100: {0: (0.11547819846894583, 59.170000000000002, 2.7522899999999999, 2.8500000000000001, 1.62096), 1: (0.0032214889100156403, 53.880000000000003, 2.4127999999999998, 17.800000000000001, 3.66879)}},epoch=1,model=<deepANN.ANN.SDAE object at 0x30fcb50>,depth=0,ACT=['tanh', 'tanh', 'rectifier'],LR=0.01,NOISE_LVL=(0.69999999999999996, 0.0041000000000000003),BATCHSIZE=10,train=<CudaNdarrayType(float32, matrix)>,datatrain=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_labels_1.pkl'),datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm,datatest=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_labels_1.pkl'),datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm,VALIDATION_TRAININGSIZE=[100, 1000, 10000],VALIDATION_RUNS_FOR_EACH_TRAININGSIZE={'100': 20, '10000': 1, '1000': 10},PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211)
ceylon.iro.umontreal.ca 2010-08-11 13:41:16.304316: 0:08:38.130000 user+sys, 0:12:39.190000 real, 68.25% usage, 565.09 MB
File: 1 29.2376451492 ----
ceylon.iro.umontreal.ca 2010-08-11 13:41:45.542130: 0:09:07.290000 user+sys, 0:13:08.420000 real, 69.42% usage, 565.09 MB
File: 2 29.2493879795 ----
ceylon.iro.umontreal.ca 2010-08-11 13:42:14.792036: 0:09:36.460000 user+sys, 0:13:37.670000 real, 70.50% usage, 565.09 MB
File: 3 29.2653870583 ----
ceylon.iro.umontreal.ca 2010-08-11 13:42:44.057955: 0:10:05.650000 user+sys, 0:14:06.930000 real, 71.51% usage, 565.09 MB
File: 4 29.3089599609 ----
ceylon.iro.umontreal.ca 2010-08-11 13:43:13.367447: 0:10:34.840000 user+sys, 0:14:36.230000 real, 72.45% usage, 565.09 MB
File: 5 29.3002038002 ----
ceylon.iro.umontreal.ca 2010-08-11 13:43:42.668169: 0:11:04.030000 user+sys, 0:15:05.530000 real, 73.33% usage, 565.09 MB
File: 6 29.3824970722 ----
ceylon.iro.umontreal.ca 2010-08-11 13:44:12.051203: 0:11:33.370000 user+sys, 0:15:34.910000 real, 74.16% usage, 565.09 MB
File: 7 29.5181820393 ----
ceylon.iro.umontreal.ca 2010-08-11 13:44:41.569911: 0:12:02.830000 user+sys, 0:16:04.420000 real, 74.95% usage, 565.09 MB
File: 8 29.5432298183 ----
ceylon.iro.umontreal.ca 2010-08-11 13:45:11.113674: 0:12:32.330000 user+sys, 0:16:33.960000 real, 75.69% usage, 565.09 MB
File: 9 29.4335720539 ----
ceylon.iro.umontreal.ca 2010-08-11 13:45:40.548016: 0:13:01.720000 user+sys, 0:17:03.390000 real, 76.39% usage, 565.09 MB
File: 10 29.2180809975 ----
ceylon.iro.umontreal.ca 2010-08-11 13:46:09.766637: 0:13:30.940000 user+sys, 0:17:32.610000 real, 77.04% usage, 565.09 MB
File: 11 29.2094709873 ----
ceylon.iro.umontreal.ca 2010-08-11 13:46:38.976618: 0:14:00.130000 user+sys, 0:18:01.810000 real, 77.66% usage, 565.09 MB
File: 12 29.1820380688 ----
ceylon.iro.umontreal.ca 2010-08-11 13:47:08.159173: 0:14:29.300000 user+sys, 0:18:30.990000 real, 78.25% usage, 565.09 MB
File: 13 29.1891109943 ----
ceylon.iro.umontreal.ca 2010-08-11 13:47:37.348811: 0:14:58.470000 user+sys, 0:19:00.170000 real, 78.80% usage, 565.09 MB
File: 14 29.1953151226 ----
ceylon.iro.umontreal.ca 2010-08-11 13:48:06.544639: 0:15:27.670000 user+sys, 0:19:29.370000 real, 79.33% usage, 565.09 MB
File: 15 27.7747271061 ----
ceylon.iro.umontreal.ca 2010-08-11 13:48:34.319874: 0:15:55.430000 user+sys, 0:19:57.140000 real, 79.81% usage, 565.09 MB
...finished training epoch #2 of 3 (66.67%)
ceylon.iro.umontreal.ca 2010-08-11 13:48:34.320360: 0:15:55.430000 user+sys, 0:19:57.140000 real, 79.81% usage, 565.09 MB
Validating (err={1000: {0: (0.10001405485169473, 53.009999999999998, 0.19723099999999999, 18.52, 0.16), 1: (0.0050480657166674719, 46.869999999999997, 0.232594, 29.260000000000002, 0.16248099999999999)}, 10000: {0: (0.056234132519034918, 52.299999999999997, 0.0, 22.800000000000001, 0.0), 1: (0.0093057204092969886, 47.299999999999997, 0.0, 25.0, 0.0)}, 100: {0: (0.11547819846894583, 59.170000000000002, 2.7522899999999999, 2.8500000000000001, 1.62096), 1: (0.0032214889100156403, 53.880000000000003, 2.4127999999999998, 17.800000000000001, 3.66879)}},epoch=2,model=<deepANN.ANN.SDAE object at 0x30fcb50>,depth=0,ACT=['tanh', 'tanh', 'rectifier'],LR=0.01,NOISE_LVL=(0.69999999999999996, 0.0041000000000000003),BATCHSIZE=10,train=<CudaNdarrayType(float32, matrix)>,datatrain=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_labels_1.pkl'),datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm,datatest=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_labels_1.pkl'),datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm,VALIDATION_TRAININGSIZE=[100, 1000, 10000],VALIDATION_RUNS_FOR_EACH_TRAININGSIZE={'100': 20, '10000': 1, '1000': 10},PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211)...
ceylon.iro.umontreal.ca 2010-08-11 13:48:34.320638: 0:15:55.430000 user+sys, 0:19:57.140000 real, 79.81% usage, 565.09 MB
		----  Encoding  layer #1 ----
			**** DenseLayer.__init__ ****
			tag =  enc1
			inp =  inp
			n_inp =  5000
			n_out =  1000
			act =  tanh
			noise =  binomial_NLP
			out =  outenc1
			params (gradients) =  [Wenc1, benc1]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc1
			allocW, allocb, allocmask =  False False False
	---- Auxiliary Layer ----
			**** DenseLayer.__init__ ****
			tag =  aux-2
			inp =  outenc1
			n_inp =  1000
			n_out =  5000
			act =  sigmoid
			noise =  None
			out =  outaux-2
			params (gradients) =  [Waux-2, baux-2]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  None
			allocW, allocb, allocmask =  False False ones
	**** SDAE ****
	depth =  3
	mode =  Aux
	depth_min, depth_max, update_type =  0 , 1 , special
	inp, n_inp =  inp , 5000
	n_hid =  [1000, 1000, 1000]
	layertype =  [<class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>]
	act =  ['tanh', 'tanh', 'rectifier']
	noise, noise_lvl =  ['binomial_NLP', 'binomial', 'binomial'] , None
	tie =  [True, True, True]
	maskbool =  [None, None, None]
	n_out, outtype =  5 , <class 'deepANN.Logistic_regression.LogisticRegression'>
	lr =  0.01
	sup_scaling, unsup_scaling, aux_scaling  =  None None 1.0
	regularization, wdreg  =  [0.0, 0.0, 0.0, 0.0] , l2
	sparsity, spreg =  [0.0, 0.0, 0.01] , l1
	params, wd, sp =  [Wenc1, benc1, Waux-2, baux-2] , [] , []
	bbbool, hessscal =  None , None
	aux, auxtarget, aux_one_sided, auxdepth, auxregularization =  True , auxtarget , True , -2 , False
	auxact, auxn_out, auxwdreg =  sigmoid , 5000 , l2
Creating libsvm file '/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm' (model=<deepANN.ANN.SDAE object at 0x30fcb50>, depth=0, datafiles=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_labels_1.pkl'))...
ceylon.iro.umontreal.ca 2010-08-11 13:48:37.029728: 0:15:58.040000 user+sys, 0:19:59.850000 real, 79.85% usage, 565.09 MB
...done creating libsvm files
ceylon.iro.umontreal.ca 2010-08-11 13:48:47.097711: 0:16:07.930000 user+sys, 0:20:09.910000 real, 80.00% usage, 565.09 MB
Creating libsvm file '/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm' (model=<deepANN.ANN.SDAE object at 0x30fcb50>, depth=0, datafiles=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_labels_1.pkl'))...
ceylon.iro.umontreal.ca 2010-08-11 13:48:47.098032: 0:16:07.930000 user+sys, 0:20:09.910000 real, 80.00% usage, 565.09 MB
...done creating libsvm files
ceylon.iro.umontreal.ca 2010-08-11 13:48:57.158617: 0:16:17.820000 user+sys, 0:20:19.970000 real, 80.15% usage, 565.09 MB
Starting SVM validation for 100 examples (numrums=20, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm, PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211, MAXSTEPS=20, STEPFACTOR=10.000000, INITIALC=0.010000)...
ceylon.iro.umontreal.ca 2010-08-11 13:48:57.158949: 0:16:17.820000 user+sys, 0:20:19.970000 real, 80.15% usage, 565.09 MB
		Training SVM with C=0.010000, nbinputs=100, numruns=20
		Training SVM with C=0.100000, nbinputs=100, numruns=20
	testerr[Cnew 0.100000] = 57.785000 > testerr[Ccurrent 0.010000] = 55.235000
	Cbest <= 0.010000, testerr[Cbest] = 55.235000
	REVERSE: Cstepfactor is now 0.316228, Ccurrent remains 0.010000, Cnew is now 0.003162
		Training SVM with C=0.003162, nbinputs=100, numruns=20
	testerr[Cnew 0.003162] = 54.555000 < testerr[Ccurrent 0.010000] = 55.235000
	NEW BEST: Cbest <= 0.003162, testerr[Cbest] = 54.555000
	PROCEED: Cstepfactor remains 0.316228, Ccurrent is now 0.003162, Cnew is now 0.001000
		Training SVM with C=0.001000, nbinputs=100, numruns=20
	testerr[Cnew 0.001000] = 58.035000 > testerr[Ccurrent 0.003162] = 54.555000
	REVERSE: Cstepfactor is now 1.778279, Ccurrent remains 0.003162, Cnew is now 0.005623
		Training SVM with C=0.005623, nbinputs=100, numruns=20
	testerr[Cnew 0.005623] = 55.805000 > testerr[Ccurrent 0.003162] = 54.555000
	REVERSE: Cstepfactor is now 0.749894, Ccurrent remains 0.003162, Cnew is now 0.002371
		Training SVM with C=0.002371, nbinputs=100, numruns=20
	testerr[Cnew 0.002371] = 55.725000 > testerr[Ccurrent 0.003162] = 54.555000
	REVERSE: Cstepfactor is now 1.154782, Ccurrent remains 0.003162, Cnew is now 0.003652
		Training SVM with C=0.003652, nbinputs=100, numruns=20
	testerr[Cnew 0.003652] = 54.865000 > testerr[Ccurrent 0.003162] = 54.555000
	REVERSE: Cstepfactor is now 0.930572, Ccurrent remains 0.003162, Cnew is now 0.002943
		Training SVM with C=0.002943, nbinputs=100, numruns=20
	testerr[Cnew 0.002943] = 55.450000 > testerr[Ccurrent 0.003162] = 54.555000
	REVERSE: Cstepfactor is now 1.036633, Ccurrent remains 0.003162, Cnew is now 0.003278
		Training SVM with C=0.003278, nbinputs=100, numruns=20
	testerr[Cnew 0.003278] = 54.655000 > testerr[Ccurrent 0.003162] = 54.555000
	REVERSE: Cstepfactor is now 0.982172, Ccurrent remains 0.003162, Cnew is now 0.003106
		Training SVM with C=0.003106, nbinputs=100, numruns=20
	testerr[Cnew 0.003106] = 53.430000 < testerr[Ccurrent 0.003162] = 54.555000
	NEW BEST: Cbest <= 0.003106, testerr[Cbest] = 53.430000
	PROCEED: Cstepfactor remains 0.982172, Ccurrent is now 0.003106, Cnew is now 0.003051
		Training SVM with C=0.003051, nbinputs=100, numruns=20
	testerr[Cnew 0.003051] = 55.320000 > testerr[Ccurrent 0.003106] = 53.430000
	REVERSE: Cstepfactor is now 1.009035, Ccurrent remains 0.003106, Cnew is now 0.003134
		Training SVM with C=0.003134, nbinputs=100, numruns=20
	testerr[Cnew 0.003134] = 56.685000 > testerr[Ccurrent 0.003106] = 53.430000
	REVERSE: Cstepfactor is now 0.995513, Ccurrent remains 0.003106, Cnew is now 0.003092
		Training SVM with C=0.003092, nbinputs=100, numruns=20
	testerr[Cnew 0.003092] = 55.755000 > testerr[Ccurrent 0.003106] = 53.430000
	REVERSE: Cstepfactor is now 1.002251, Ccurrent remains 0.003106, Cnew is now 0.003113
		Training SVM with C=0.003113, nbinputs=100, numruns=20
	testerr[Cnew 0.003113] = 56.730000 > testerr[Ccurrent 0.003106] = 53.430000
	REVERSE: Cstepfactor is now 0.998876, Ccurrent remains 0.003106, Cnew is now 0.003102
		Training SVM with C=0.003102, nbinputs=100, numruns=20
	testerr[Cnew 0.003102] = 56.245000 > testerr[Ccurrent 0.003106] = 53.430000
	REVERSE: Cstepfactor is now 1.000562, Ccurrent remains 0.003106, Cnew is now 0.003108
		Training SVM with C=0.003108, nbinputs=100, numruns=20
	testerr[Cnew 0.003108] = 54.055000 > testerr[Ccurrent 0.003106] = 53.430000
	REVERSE: Cstepfactor is now 0.999719, Ccurrent remains 0.003106, Cnew is now 0.003105
		Training SVM with C=0.003105, nbinputs=100, numruns=20
	testerr[Cnew 0.003105] = 53.430000 > testerr[Ccurrent 0.003106] = 53.430000
	REVERSE: Cstepfactor is now 1.000141, Ccurrent remains 0.003106, Cnew is now 0.003106
		Training SVM with C=0.003106, nbinputs=100, numruns=20
	testerr[Cnew 0.003106] = 54.045000 > testerr[Ccurrent 0.003106] = 53.430000
	REVERSE: Cstepfactor is now 0.999930, Ccurrent remains 0.003106, Cnew is now 0.003106
		Training SVM with C=0.003106, nbinputs=100, numruns=20
	testerr[Cnew 0.003106] = 53.430000 > testerr[Ccurrent 0.003106] = 53.430000
	REVERSE: Cstepfactor is now 1.000035, Ccurrent remains 0.003106, Cnew is now 0.003106
		Training SVM with C=0.003106, nbinputs=100, numruns=20
	testerr[Cnew 0.003106] = 56.355000 > testerr[Ccurrent 0.003106] = 53.430000
	REVERSE: Cstepfactor is now 0.999982, Ccurrent remains 0.003106, Cnew is now 0.003106
	testerr[C 0.001000] = 58.035000 
	testerr[C 0.002371] = 55.725000 
	testerr[C 0.002943] = 55.450000 
	testerr[C 0.003051] = 55.320000 
	testerr[C 0.003092] = 55.755000 
	testerr[C 0.003102] = 56.245000 
	testerr[C 0.003105] = 53.430000 
	testerr[C 0.003106] = 53.430000 
	testerr[C 0.003106] = 53.430000  *best* (testerr = 53.430000, testerrdev = 2.158730, trainerr = 14.750000, trainerrdev = 4.169830)
	testerr[C 0.003106] = 56.355000 
	testerr[C 0.003106] = 54.045000 
	testerr[C 0.003108] = 54.055000 
	testerr[C 0.003113] = 56.730000 
	testerr[C 0.003134] = 56.685000 
	testerr[C 0.003162] = 54.555000 
	testerr[C 0.003278] = 54.655000 
	testerr[C 0.003652] = 54.865000 
	testerr[C 0.005623] = 55.805000 
	testerr[C 0.010000] = 55.235000 
	testerr[C 0.100000] = 57.785000 
...done with SVM validation for 100 examples (numrums=20, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm)...
ceylon.iro.umontreal.ca 2010-08-11 13:49:22.342789: 0:16:17.900000 user+sys, 0:20:45.150000 real, 78.54% usage, 565.09 MB
Starting SVM validation for 1000 examples (numrums=10, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm, PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211, MAXSTEPS=20, STEPFACTOR=10.000000, INITIALC=0.010000)...
ceylon.iro.umontreal.ca 2010-08-11 13:49:22.343015: 0:16:17.900000 user+sys, 0:20:45.150000 real, 78.54% usage, 565.09 MB
		Training SVM with C=0.010000, nbinputs=1000, numruns=10
		Training SVM with C=0.100000, nbinputs=1000, numruns=10
	testerr[Cnew 0.100000] = 54.490000 > testerr[Ccurrent 0.010000] = 47.950000
	Cbest <= 0.010000, testerr[Cbest] = 47.950000
	REVERSE: Cstepfactor is now 0.316228, Ccurrent remains 0.010000, Cnew is now 0.003162
		Training SVM with C=0.003162, nbinputs=1000, numruns=10
	testerr[Cnew 0.003162] = 46.810000 < testerr[Ccurrent 0.010000] = 47.950000
	NEW BEST: Cbest <= 0.003162, testerr[Cbest] = 46.810000
	PROCEED: Cstepfactor remains 0.316228, Ccurrent is now 0.003162, Cnew is now 0.001000
		Training SVM with C=0.001000, nbinputs=1000, numruns=10
	testerr[Cnew 0.001000] = 49.390000 > testerr[Ccurrent 0.003162] = 46.810000
	REVERSE: Cstepfactor is now 1.778279, Ccurrent remains 0.003162, Cnew is now 0.005623
		Training SVM with C=0.005623, nbinputs=1000, numruns=10
	testerr[Cnew 0.005623] = 47.380000 > testerr[Ccurrent 0.003162] = 46.810000
	REVERSE: Cstepfactor is now 0.749894, Ccurrent remains 0.003162, Cnew is now 0.002371
		Training SVM with C=0.002371, nbinputs=1000, numruns=10
	testerr[Cnew 0.002371] = 47.090000 > testerr[Ccurrent 0.003162] = 46.810000
	REVERSE: Cstepfactor is now 1.154782, Ccurrent remains 0.003162, Cnew is now 0.003652
		Training SVM with C=0.003652, nbinputs=1000, numruns=10
	testerr[Cnew 0.003652] = 47.010000 > testerr[Ccurrent 0.003162] = 46.810000
	REVERSE: Cstepfactor is now 0.930572, Ccurrent remains 0.003162, Cnew is now 0.002943
		Training SVM with C=0.002943, nbinputs=1000, numruns=10
	testerr[Cnew 0.002943] = 46.540000 < testerr[Ccurrent 0.003162] = 46.810000
	NEW BEST: Cbest <= 0.002943, testerr[Cbest] = 46.540000
	PROCEED: Cstepfactor remains 0.930572, Ccurrent is now 0.002943, Cnew is now 0.002738
		Training SVM with C=0.002738, nbinputs=1000, numruns=10
	testerr[Cnew 0.002738] = 46.720000 > testerr[Ccurrent 0.002943] = 46.540000
	REVERSE: Cstepfactor is now 1.036633, Ccurrent remains 0.002943, Cnew is now 0.003051
		Training SVM with C=0.003051, nbinputs=1000, numruns=10
	testerr[Cnew 0.003051] = 46.500000 < testerr[Ccurrent 0.002943] = 46.540000
	NEW BEST: Cbest <= 0.003051, testerr[Cbest] = 46.500000
	PROCEED: Cstepfactor remains 1.036633, Ccurrent is now 0.003051, Cnew is now 0.003162
	testerr[Cnew 0.003162] = 46.810000 > testerr[Ccurrent 0.003051] = 46.500000
	REVERSE: Cstepfactor is now 0.982172, Ccurrent remains 0.003051, Cnew is now 0.002996
		Training SVM with C=0.002996, nbinputs=1000, numruns=10
	testerr[Cnew 0.002996] = 46.510000 > testerr[Ccurrent 0.003051] = 46.500000
	REVERSE: Cstepfactor is now 1.009035, Ccurrent remains 0.003051, Cnew is now 0.003078
		Training SVM with C=0.003078, nbinputs=1000, numruns=10
	testerr[Cnew 0.003078] = 46.650000 > testerr[Ccurrent 0.003051] = 46.500000
	REVERSE: Cstepfactor is now 0.995513, Ccurrent remains 0.003051, Cnew is now 0.003037
		Training SVM with C=0.003037, nbinputs=1000, numruns=10
	testerr[Cnew 0.003037] = 46.680000 > testerr[Ccurrent 0.003051] = 46.500000
	REVERSE: Cstepfactor is now 1.002251, Ccurrent remains 0.003051, Cnew is now 0.003057
		Training SVM with C=0.003057, nbinputs=1000, numruns=10
	testerr[Cnew 0.003057] = 46.610000 > testerr[Ccurrent 0.003051] = 46.500000
	REVERSE: Cstepfactor is now 0.998876, Ccurrent remains 0.003051, Cnew is now 0.003047
		Training SVM with C=0.003047, nbinputs=1000, numruns=10
	testerr[Cnew 0.003047] = 46.530000 > testerr[Ccurrent 0.003051] = 46.500000
	REVERSE: Cstepfactor is now 1.000562, Ccurrent remains 0.003051, Cnew is now 0.003052
		Training SVM with C=0.003052, nbinputs=1000, numruns=10
	testerr[Cnew 0.003052] = 46.570000 > testerr[Ccurrent 0.003051] = 46.500000
	REVERSE: Cstepfactor is now 0.999719, Ccurrent remains 0.003051, Cnew is now 0.003050
		Training SVM with C=0.003050, nbinputs=1000, numruns=10
	testerr[Cnew 0.003050] = 46.580000 > testerr[Ccurrent 0.003051] = 46.500000
	REVERSE: Cstepfactor is now 1.000141, Ccurrent remains 0.003051, Cnew is now 0.003051
		Training SVM with C=0.003051, nbinputs=1000, numruns=10
	testerr[Cnew 0.003051] = 46.680000 > testerr[Ccurrent 0.003051] = 46.500000
	REVERSE: Cstepfactor is now 0.999930, Ccurrent remains 0.003051, Cnew is now 0.003050
		Training SVM with C=0.003050, nbinputs=1000, numruns=10
	testerr[Cnew 0.003050] = 46.510000 > testerr[Ccurrent 0.003051] = 46.500000
	REVERSE: Cstepfactor is now 1.000035, Ccurrent remains 0.003051, Cnew is now 0.003051
		Training SVM with C=0.003051, nbinputs=1000, numruns=10
	testerr[Cnew 0.003051] = 46.660000 > testerr[Ccurrent 0.003051] = 46.500000
	REVERSE: Cstepfactor is now 0.999982, Ccurrent remains 0.003051, Cnew is now 0.003050
	testerr[C 0.001000] = 49.390000 
	testerr[C 0.002371] = 47.090000 
	testerr[C 0.002738] = 46.720000 
	testerr[C 0.002943] = 46.540000 
	testerr[C 0.002996] = 46.510000 
	testerr[C 0.003037] = 46.680000 
	testerr[C 0.003047] = 46.530000 
	testerr[C 0.003050] = 46.580000 
	testerr[C 0.003050] = 46.510000 
	testerr[C 0.003051] = 46.500000  *best* (testerr = 46.500000, testerrdev = 0.264575, trainerr = 28.430000, trainerrdev = 0.249199)
	testerr[C 0.003051] = 46.660000 
	testerr[C 0.003051] = 46.680000 
	testerr[C 0.003052] = 46.570000 
	testerr[C 0.003057] = 46.610000 
	testerr[C 0.003078] = 46.650000 
	testerr[C 0.003162] = 46.810000 
	testerr[C 0.003652] = 47.010000 
	testerr[C 0.005623] = 47.380000 
	testerr[C 0.010000] = 47.950000 
	testerr[C 0.100000] = 54.490000 
...done with SVM validation for 1000 examples (numrums=10, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm)...
ceylon.iro.umontreal.ca 2010-08-11 13:50:30.395726: 0:16:17.980000 user+sys, 0:21:53.190000 real, 74.47% usage, 565.09 MB
Starting SVM validation for 10000 examples (numrums=1, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm, PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211, MAXSTEPS=20, STEPFACTOR=10.000000, INITIALC=0.010000)...
ceylon.iro.umontreal.ca 2010-08-11 13:50:30.396103: 0:16:17.980000 user+sys, 0:21:53.190000 real, 74.47% usage, 565.09 MB
		Training SVM with C=0.010000, nbinputs=10000, numruns=1
		Training SVM with C=0.100000, nbinputs=10000, numruns=1
	testerr[Cnew 0.100000] = 54.400000 > testerr[Ccurrent 0.010000] = 48.100000
	Cbest <= 0.010000, testerr[Cbest] = 48.100000
	REVERSE: Cstepfactor is now 0.316228, Ccurrent remains 0.010000, Cnew is now 0.003162
		Training SVM with C=0.003162, nbinputs=10000, numruns=1
	testerr[Cnew 0.003162] = 46.800000 < testerr[Ccurrent 0.010000] = 48.100000
	NEW BEST: Cbest <= 0.003162, testerr[Cbest] = 46.800000
	PROCEED: Cstepfactor remains 0.316228, Ccurrent is now 0.003162, Cnew is now 0.001000
		Training SVM with C=0.001000, nbinputs=10000, numruns=1
	testerr[Cnew 0.001000] = 49.500000 > testerr[Ccurrent 0.003162] = 46.800000
	REVERSE: Cstepfactor is now 1.778279, Ccurrent remains 0.003162, Cnew is now 0.005623
		Training SVM with C=0.005623, nbinputs=10000, numruns=1
	testerr[Cnew 0.005623] = 47.600000 > testerr[Ccurrent 0.003162] = 46.800000
	REVERSE: Cstepfactor is now 0.749894, Ccurrent remains 0.003162, Cnew is now 0.002371
		Training SVM with C=0.002371, nbinputs=10000, numruns=1
	testerr[Cnew 0.002371] = 47.800000 > testerr[Ccurrent 0.003162] = 46.800000
	REVERSE: Cstepfactor is now 1.154782, Ccurrent remains 0.003162, Cnew is now 0.003652
		Training SVM with C=0.003652, nbinputs=10000, numruns=1
	testerr[Cnew 0.003652] = 46.700000 < testerr[Ccurrent 0.003162] = 46.800000
	NEW BEST: Cbest <= 0.003652, testerr[Cbest] = 46.700000
	PROCEED: Cstepfactor remains 1.154782, Ccurrent is now 0.003652, Cnew is now 0.004217
		Training SVM with C=0.004217, nbinputs=10000, numruns=1
	testerr[Cnew 0.004217] = 47.500000 > testerr[Ccurrent 0.003652] = 46.700000
	REVERSE: Cstepfactor is now 0.930572, Ccurrent remains 0.003652, Cnew is now 0.003398
		Training SVM with C=0.003398, nbinputs=10000, numruns=1
	testerr[Cnew 0.003398] = 46.900000 > testerr[Ccurrent 0.003652] = 46.700000
	REVERSE: Cstepfactor is now 1.036633, Ccurrent remains 0.003652, Cnew is now 0.003786
		Training SVM with C=0.003786, nbinputs=10000, numruns=1
	testerr[Cnew 0.003786] = 46.800000 > testerr[Ccurrent 0.003652] = 46.700000
	REVERSE: Cstepfactor is now 0.982172, Ccurrent remains 0.003652, Cnew is now 0.003587
		Training SVM with C=0.003587, nbinputs=10000, numruns=1
	testerr[Cnew 0.003587] = 47.000000 > testerr[Ccurrent 0.003652] = 46.700000
	REVERSE: Cstepfactor is now 1.009035, Ccurrent remains 0.003652, Cnew is now 0.003685
		Training SVM with C=0.003685, nbinputs=10000, numruns=1
	testerr[Cnew 0.003685] = 46.700000 > testerr[Ccurrent 0.003652] = 46.700000
	REVERSE: Cstepfactor is now 0.995513, Ccurrent remains 0.003652, Cnew is now 0.003635
		Training SVM with C=0.003635, nbinputs=10000, numruns=1
	testerr[Cnew 0.003635] = 47.300000 > testerr[Ccurrent 0.003652] = 46.700000
	REVERSE: Cstepfactor is now 1.002251, Ccurrent remains 0.003652, Cnew is now 0.003660
		Training SVM with C=0.003660, nbinputs=10000, numruns=1
	testerr[Cnew 0.003660] = 46.600000 < testerr[Ccurrent 0.003652] = 46.700000
	NEW BEST: Cbest <= 0.003660, testerr[Cbest] = 46.600000
	PROCEED: Cstepfactor remains 1.002251, Ccurrent is now 0.003660, Cnew is now 0.003668
		Training SVM with C=0.003668, nbinputs=10000, numruns=1
	testerr[Cnew 0.003668] = 46.800000 > testerr[Ccurrent 0.003660] = 46.600000
	REVERSE: Cstepfactor is now 0.998876, Ccurrent remains 0.003660, Cnew is now 0.003656
		Training SVM with C=0.003656, nbinputs=10000, numruns=1
	testerr[Cnew 0.003656] = 47.100000 > testerr[Ccurrent 0.003660] = 46.600000
	REVERSE: Cstepfactor is now 1.000562, Ccurrent remains 0.003660, Cnew is now 0.003662
		Training SVM with C=0.003662, nbinputs=10000, numruns=1
	testerr[Cnew 0.003662] = 47.100000 > testerr[Ccurrent 0.003660] = 46.600000
	REVERSE: Cstepfactor is now 0.999719, Ccurrent remains 0.003660, Cnew is now 0.003659
		Training SVM with C=0.003659, nbinputs=10000, numruns=1
	testerr[Cnew 0.003659] = 46.800000 > testerr[Ccurrent 0.003660] = 46.600000
	REVERSE: Cstepfactor is now 1.000141, Ccurrent remains 0.003660, Cnew is now 0.003660
		Training SVM with C=0.003660, nbinputs=10000, numruns=1
	testerr[Cnew 0.003660] = 46.600000 > testerr[Ccurrent 0.003660] = 46.600000
	REVERSE: Cstepfactor is now 0.999930, Ccurrent remains 0.003660, Cnew is now 0.003660
		Training SVM with C=0.003660, nbinputs=10000, numruns=1
	testerr[Cnew 0.003660] = 46.800000 > testerr[Ccurrent 0.003660] = 46.600000
	REVERSE: Cstepfactor is now 1.000035, Ccurrent remains 0.003660, Cnew is now 0.003660
	testerr[C 0.001000] = 49.500000 
	testerr[C 0.002371] = 47.800000 
	testerr[C 0.003162] = 46.800000 
	testerr[C 0.003398] = 46.900000 
	testerr[C 0.003587] = 47.000000 
	testerr[C 0.003635] = 47.300000 
	testerr[C 0.003652] = 46.700000 
	testerr[C 0.003656] = 47.100000 
	testerr[C 0.003659] = 46.800000 
	testerr[C 0.003660] = 46.800000 
	testerr[C 0.003660] = 46.600000  *best* (testerr = 46.600000, testerrdev = 0.000000, trainerr = 27.300000, trainerrdev = 0.000000)
	testerr[C 0.003660] = 46.600000 
	testerr[C 0.003662] = 47.100000 
	testerr[C 0.003668] = 46.800000 
	testerr[C 0.003685] = 46.700000 
	testerr[C 0.003786] = 46.800000 
	testerr[C 0.004217] = 47.500000 
	testerr[C 0.005623] = 47.600000 
	testerr[C 0.010000] = 48.100000 
	testerr[C 0.100000] = 54.400000 
...done with SVM validation for 10000 examples (numrums=1, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm)...
ceylon.iro.umontreal.ca 2010-08-11 13:50:50.527666: 0:16:18.070000 user+sys, 0:22:13.320000 real, 73.36% usage, 565.09 MB
		----  Encoding  layer #1 ----
			**** DenseLayer.__init__ ****
			tag =  enc1
			inp =  inp
			n_inp =  5000
			n_out =  1000
			act =  tanh
			noise =  binomial_NLP
			out =  outenc1
			params (gradients) =  [Wenc1, benc1]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc1
			allocW, allocb, allocmask =  False False False
MRG_RandomStreams Can't determine #streams from size (Shape.0), guessing 30*256
MRG_RandomStreams Can't determine #streams from size (Shape.0), guessing 30*256
	---- Auxiliary Layer ----
			**** DenseLayer.__init__ ****
			tag =  aux-2
			inp =  outenc1
			n_inp =  1000
			n_out =  5000
			act =  sigmoid
			noise =  None
			out =  outaux-2
			params (gradients) =  [Waux-2, baux-2]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  None
			allocW, allocb, allocmask =  False False ones
	**** SDAE ****
	depth =  3
	mode =  Aux
	depth_min, depth_max, update_type =  0 , 1 , special
	inp, n_inp =  inp , 5000
	n_hid =  [1000, 1000, 1000]
	layertype =  [<class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>]
	act =  ['tanh', 'tanh', 'rectifier']
	noise, noise_lvl =  ['binomial_NLP', 'binomial', 'binomial'] , (0.69999999999999996, 0.0041000000000000003)
	tie =  [True, True, True]
	maskbool =  [None, None, None]
	n_out, outtype =  5 , <class 'deepANN.Logistic_regression.LogisticRegression'>
	lr =  0.01
	sup_scaling, unsup_scaling, aux_scaling  =  None None 1.0
	regularization, wdreg  =  [0.0, 0.0, 0.0, 0.0] , l2
	sparsity, spreg =  [0.0, 0.0, 0.01] , l1
	params, wd, sp =  [Wenc1, benc1, Waux-2, baux-2] , [] , []
	bbbool, hessscal =  None , None
	aux, auxtarget, aux_one_sided, auxdepth, auxregularization =  True , auxtarget , True , -2 , False
	auxact, auxn_out, auxwdreg =  sigmoid , 5000 , l2
##########  TEST ############ EPOCH :  2
CURRENT RECONSTRUCTION ERROR (is this on test or train?):  94.4073773499
CURRENT 100 SVM ERROR:  (0.0031059002236247051, 53.43, 2.1587299999999998, 14.75, 4.1698300000000001)
CURRENT 1000 SVM ERROR:  (0.0030505278902670254, 46.5, 0.264575, 28.43, 0.249199)
CURRENT 10000 SVM ERROR:  (0.0036599618836802342, 46.600000000000001, 0.0, 27.300000000000001, 0.0)
ceylon.iro.umontreal.ca 2010-08-11 13:51:03.651920: 0:16:31.100000 user+sys, 0:22:26.450000 real, 73.61% usage, 565.09 MB
params.pkl saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth1pre2
Wenc1 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth1pre2/Layer1_W.pkl
benc1 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth1pre2/Layer1_b.pkl
maskenc1 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth1pre2/Layer1_mask.pkl
Wenc2 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth1pre2/Layer2_W.pkl
benc2 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth1pre2/Layer2_b.pkl
maskenc2 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth1pre2/Layer2_mask.pkl
Wenc3 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth1pre2/Layer3_W.pkl
benc3 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth1pre2/Layer3_b.pkl
maskenc3 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth1pre2/Layer3_mask.pkl
Waux-2 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth1pre2/Layeraux_W.pkl
baux-2 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth1pre2/Layeraux_b.pkl
maskaux-2 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth1pre2/Layeraux_mask.pkl
W saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth1pre2/Layerout_W.pkl
b saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth1pre2/Layerout_b.pkl
saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth1pre2
...done validating (err={1000: {0: (0.10001405485169473, 53.009999999999998, 0.19723099999999999, 18.52, 0.16), 1: (0.0050480657166674719, 46.869999999999997, 0.232594, 29.260000000000002, 0.16248099999999999), 2: (0.0030505278902670254, 46.5, 0.264575, 28.43, 0.249199)}, 10000: {0: (0.056234132519034918, 52.299999999999997, 0.0, 22.800000000000001, 0.0), 1: (0.0093057204092969886, 47.299999999999997, 0.0, 25.0, 0.0), 2: (0.0036599618836802342, 46.600000000000001, 0.0, 27.300000000000001, 0.0)}, 100: {0: (0.11547819846894583, 59.170000000000002, 2.7522899999999999, 2.8500000000000001, 1.62096), 1: (0.0032214889100156403, 53.880000000000003, 2.4127999999999998, 17.800000000000001, 3.66879), 2: (0.0031059002236247051, 53.43, 2.1587299999999998, 14.75, 4.1698300000000001)}},epoch=2,model=<deepANN.ANN.SDAE object at 0x30fcb50>,depth=0,ACT=['tanh', 'tanh', 'rectifier'],LR=0.01,NOISE_LVL=(0.69999999999999996, 0.0041000000000000003),BATCHSIZE=10,train=<CudaNdarrayType(float32, matrix)>,datatrain=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_labels_1.pkl'),datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm,datatest=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_labels_1.pkl'),datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm,VALIDATION_TRAININGSIZE=[100, 1000, 10000],VALIDATION_RUNS_FOR_EACH_TRAININGSIZE={'100': 20, '10000': 1, '1000': 10},PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211)
ceylon.iro.umontreal.ca 2010-08-11 13:51:04.339816: 0:16:31.180000 user+sys, 0:22:27.130000 real, 73.58% usage, 565.09 MB
File: 1 29.4771988392 ----
ceylon.iro.umontreal.ca 2010-08-11 13:51:33.817200: 0:17:00.640000 user+sys, 0:22:56.610000 real, 74.14% usage, 565.09 MB
File: 2 29.4439749718 ----
ceylon.iro.umontreal.ca 2010-08-11 13:52:03.261788: 0:17:30.070000 user+sys, 0:23:26.050000 real, 74.68% usage, 565.09 MB
File: 3 29.3543319702 ----
ceylon.iro.umontreal.ca 2010-08-11 13:52:32.616731: 0:17:59.400000 user+sys, 0:23:55.400000 real, 75.20% usage, 565.09 MB
File: 4 29.1747210026 ----
ceylon.iro.umontreal.ca 2010-08-11 13:53:01.792138: 0:18:28.540000 user+sys, 0:24:24.570000 real, 75.69% usage, 565.09 MB
File: 5 29.1785511971 ----
ceylon.iro.umontreal.ca 2010-08-11 13:53:30.971291: 0:18:57.700000 user+sys, 0:24:53.740000 real, 76.16% usage, 565.09 MB
File: 6 29.2417171001 ----
ceylon.iro.umontreal.ca 2010-08-11 13:54:00.213608: 0:19:26.880000 user+sys, 0:25:22.980000 real, 76.62% usage, 565.09 MB
File: 7 29.1543440819 ----
ceylon.iro.umontreal.ca 2010-08-11 13:54:29.368348: 0:19:56 user+sys, 0:25:52.130000 real, 77.06% usage, 565.09 MB
File: 8 29.1454639435 ----
ceylon.iro.umontreal.ca 2010-08-11 13:54:58.514381: 0:20:25.090000 user+sys, 0:26:21.270000 real, 77.48% usage, 565.09 MB
File: 9 29.161714077 ----
ceylon.iro.umontreal.ca 2010-08-11 13:55:27.676659: 0:20:54.210000 user+sys, 0:26:50.430000 real, 77.88% usage, 565.09 MB
File: 10 29.1600329876 ----
ceylon.iro.umontreal.ca 2010-08-11 13:55:56.837262: 0:21:23.320000 user+sys, 0:27:19.590000 real, 78.27% usage, 565.09 MB
File: 11 29.1619949341 ----
ceylon.iro.umontreal.ca 2010-08-11 13:56:25.999819: 0:21:52.450000 user+sys, 0:27:48.740000 real, 78.65% usage, 565.09 MB
File: 12 29.207652092 ----
ceylon.iro.umontreal.ca 2010-08-11 13:56:55.208037: 0:22:21.600000 user+sys, 0:28:17.950000 real, 79.01% usage, 565.09 MB
File: 13 29.3516819477 ----
ceylon.iro.umontreal.ca 2010-08-11 13:57:24.560294: 0:22:50.920000 user+sys, 0:28:47.300000 real, 79.37% usage, 565.09 MB
File: 14 29.4511270523 ----
ceylon.iro.umontreal.ca 2010-08-11 13:57:54.011999: 0:23:20.320000 user+sys, 0:29:16.740000 real, 79.71% usage, 565.09 MB
File: 15 28.0866348743 ----
ceylon.iro.umontreal.ca 2010-08-11 13:58:22.099208: 0:23:48.360000 user+sys, 0:29:44.830000 real, 80.03% usage, 565.09 MB
...finished training epoch #3 of 3 (100.00%)
ceylon.iro.umontreal.ca 2010-08-11 13:58:22.099757: 0:23:48.370000 user+sys, 0:29:44.830000 real, 80.03% usage, 565.09 MB
...DONE DEPTH 1 of 3 (33.33%)
ceylon.iro.umontreal.ca 2010-08-11 13:58:22.100078: 0:23:48.370000 user+sys, 0:29:44.830000 real, 80.03% usage, 565.09 MB
BEGIN DEPTH 2 of 3 (66.67%)...
ceylon.iro.umontreal.ca 2010-08-11 13:58:22.100196: 0:23:48.370000 user+sys, 0:29:44.830000 real, 80.03% usage, 565.09 MB
	---- Auxiliary Layer ----
			**** DenseLayer.__init__ ****
			tag =  aux-1
			inp =  outenc2
			n_inp =  1000
			n_out =  1000
			act =  sigmoid
			noise =  None
			out =  outaux-1
			params (gradients) =  [Waux-1, baux-1]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  None
			allocW, allocb, allocmask =  True True ones
	**** SDAE ****
	depth =  3
	mode =  Aux
	depth_min, depth_max, update_type =  0 , 2 , special
	inp, n_inp =  inp , 5000
	n_hid =  [1000, 1000, 1000]
	layertype =  [<class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>]
	act =  ['tanh', 'tanh', 'rectifier']
	noise, noise_lvl =  ['binomial_NLP', 'binomial', 'binomial'] , (0.69999999999999996, 0.0041000000000000003)
	tie =  [True, True, True]
	maskbool =  [None, None, None]
	n_out, outtype =  5 , <class 'deepANN.Logistic_regression.LogisticRegression'>
	lr =  0.01
	sup_scaling, unsup_scaling, aux_scaling  =  None None 1.0
	regularization, wdreg  =  [0.0, 0.0, 0.0, 0.0] , l2
	sparsity, spreg =  [0.0, 0.0, 0.01] , l1
	params, wd, sp =  [Wenc1, benc1, Waux-1, baux-1] , [] , []
	bbbool, hessscal =  None , None
	aux, auxtarget, aux_one_sided, auxdepth, auxregularization =  True , auxtarget , True , -1 , False
	auxact, auxn_out, auxwdreg =  sigmoid , 1000 , l2
		----  Encoding  layer #1 ----
			**** DenseLayer.__init__ ****
			tag =  enc1
			inp =  inp
			n_inp =  5000
			n_out =  1000
			act =  tanh
			noise =  binomial_NLP
			out =  outenc1
			params (gradients) =  [Wenc1, benc1]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc1
			allocW, allocb, allocmask =  False False False
		----  Encoding  layer #2 ----
			**** DenseLayer.__init__ ****
			tag =  enc2
			inp =  outenc1
			n_inp =  1000
			n_out =  1000
			act =  tanh
			noise =  binomial
			out =  outenc2
			params (gradients) =  [Wenc2, benc2]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc2
			allocW, allocb, allocmask =  False False False
MRG_RandomStreams Can't determine #streams from size (Shape.0), guessing 30*256
	---- Auxiliary Layer ----
			**** DenseLayer.__init__ ****
			tag =  aux-1
			inp =  outenc2
			n_inp =  1000
			n_out =  1000
			act =  sigmoid
			noise =  None
			out =  outaux-1
			params (gradients) =  [Waux-1, baux-1]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  None
			allocW, allocb, allocmask =  False False ones
	**** SDAE ****
	depth =  3
	mode =  Aux
	depth_min, depth_max, update_type =  0 , 2 , special
	inp, n_inp =  inp , 5000
	n_hid =  [1000, 1000, 1000]
	layertype =  [<class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>]
	act =  ['tanh', 'tanh', 'rectifier']
	noise, noise_lvl =  ['binomial_NLP', 'binomial', 'binomial'] , 0.5
	tie =  [True, True, True]
	maskbool =  [None, None, None]
	n_out, outtype =  5 , <class 'deepANN.Logistic_regression.LogisticRegression'>
	lr =  0.001
	sup_scaling, unsup_scaling, aux_scaling  =  None None 1.0
	regularization, wdreg  =  [0.0, 0.0, 0.0, 0.0] , l2
	sparsity, spreg =  [0.0, 0.0, 0.01] , l1
	params, wd, sp =  [Wenc2, benc2, Waux-1, baux-1] , [] , []
	bbbool, hessscal =  None , None
	aux, auxtarget, aux_one_sided, auxdepth, auxregularization =  True , auxtarget , True , -1 , False
	auxact, auxn_out, auxwdreg =  sigmoid , 1000 , l2
Validating (err={1000: {}, 10000: {}, 100: {}},epoch=0,model=<deepANN.ANN.SDAE object at 0x30fcb50>,depth=1,ACT=['tanh', 'tanh', 'rectifier'],LR=0.001,NOISE_LVL=0.5,BATCHSIZE=10,train=<CudaNdarrayType(float32, matrix)>,datatrain=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_labels_1.pkl'),datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm,datatest=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_labels_1.pkl'),datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm,VALIDATION_TRAININGSIZE=[100, 1000, 10000],VALIDATION_RUNS_FOR_EACH_TRAININGSIZE={'100': 20, '10000': 1, '1000': 10},PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211)...
ceylon.iro.umontreal.ca 2010-08-11 13:58:26.627805: 0:23:52.720000 user+sys, 0:29:49.350000 real, 80.07% usage, 583.55 MB
		----  Encoding  layer #1 ----
			**** DenseLayer.__init__ ****
			tag =  enc1
			inp =  inp
			n_inp =  5000
			n_out =  1000
			act =  tanh
			noise =  binomial_NLP
			out =  outenc1
			params (gradients) =  [Wenc1, benc1]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc1
			allocW, allocb, allocmask =  False False False
		----  Encoding  layer #2 ----
			**** DenseLayer.__init__ ****
			tag =  enc2
			inp =  outenc1
			n_inp =  1000
			n_out =  1000
			act =  tanh
			noise =  binomial
			out =  outenc2
			params (gradients) =  [Wenc2, benc2]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc2
			allocW, allocb, allocmask =  False False False
	---- Auxiliary Layer ----
			**** DenseLayer.__init__ ****
			tag =  aux-1
			inp =  outenc2
			n_inp =  1000
			n_out =  1000
			act =  sigmoid
			noise =  None
			out =  outaux-1
			params (gradients) =  [Waux-1, baux-1]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  None
			allocW, allocb, allocmask =  False False ones
	**** SDAE ****
	depth =  3
	mode =  Aux
	depth_min, depth_max, update_type =  0 , 2 , special
	inp, n_inp =  inp , 5000
	n_hid =  [1000, 1000, 1000]
	layertype =  [<class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>]
	act =  ['tanh', 'tanh', 'rectifier']
	noise, noise_lvl =  ['binomial_NLP', 'binomial', 'binomial'] , None
	tie =  [True, True, True]
	maskbool =  [None, None, None]
	n_out, outtype =  5 , <class 'deepANN.Logistic_regression.LogisticRegression'>
	lr =  0.001
	sup_scaling, unsup_scaling, aux_scaling  =  None None 1.0
	regularization, wdreg  =  [0.0, 0.0, 0.0, 0.0] , l2
	sparsity, spreg =  [0.0, 0.0, 0.01] , l1
	params, wd, sp =  [Wenc2, benc2, Waux-1, baux-1] , [] , []
	bbbool, hessscal =  None , None
	aux, auxtarget, aux_one_sided, auxdepth, auxregularization =  True , auxtarget , True , -1 , False
	auxact, auxn_out, auxwdreg =  sigmoid , 1000 , l2
Creating libsvm file '/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm' (model=<deepANN.ANN.SDAE object at 0x30fcb50>, depth=1, datafiles=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_labels_1.pkl'))...
ceylon.iro.umontreal.ca 2010-08-11 13:58:29.143112: 0:23:55.170000 user+sys, 0:29:51.870000 real, 80.09% usage, 583.55 MB
...done creating libsvm files
ceylon.iro.umontreal.ca 2010-08-11 13:58:39.424892: 0:24:05.220000 user+sys, 0:30:02.150000 real, 80.19% usage, 583.55 MB
Creating libsvm file '/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm' (model=<deepANN.ANN.SDAE object at 0x30fcb50>, depth=1, datafiles=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_labels_1.pkl'))...
ceylon.iro.umontreal.ca 2010-08-11 13:58:39.425383: 0:24:05.220000 user+sys, 0:30:02.150000 real, 80.19% usage, 583.55 MB
...done creating libsvm files
ceylon.iro.umontreal.ca 2010-08-11 13:58:49.727544: 0:24:15.300000 user+sys, 0:30:12.450000 real, 80.29% usage, 583.55 MB
Starting SVM validation for 100 examples (numrums=20, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm, PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211, MAXSTEPS=20, STEPFACTOR=10.000000, INITIALC=0.010000)...
ceylon.iro.umontreal.ca 2010-08-11 13:58:49.728041: 0:24:15.300000 user+sys, 0:30:12.450000 real, 80.29% usage, 583.55 MB
		Training SVM with C=0.010000, nbinputs=100, numruns=20
		Training SVM with C=0.100000, nbinputs=100, numruns=20
	testerr[Cnew 0.100000] = 57.350000 < testerr[Ccurrent 0.010000] = 57.690000
	NEW BEST: Cbest <= 0.100000, testerr[Cbest] = 57.350000
	PROCEED: Cstepfactor remains 10.000000, Ccurrent is now 0.100000, Cnew is now 1.000000
		Training SVM with C=1.000000, nbinputs=100, numruns=20
	testerr[Cnew 1.000000] = 57.000000 < testerr[Ccurrent 0.100000] = 57.350000
	NEW BEST: Cbest <= 1.000000, testerr[Cbest] = 57.000000
	PROCEED: Cstepfactor remains 10.000000, Ccurrent is now 1.000000, Cnew is now 10.000000
		Training SVM with C=10.000000, nbinputs=100, numruns=20
	testerr[Cnew 10.000000] = 57.000000 > testerr[Ccurrent 1.000000] = 57.000000
	REVERSE: Cstepfactor is now 0.316228, Ccurrent remains 1.000000, Cnew is now 0.316228
		Training SVM with C=0.316228, nbinputs=100, numruns=20
	testerr[Cnew 0.316228] = 57.000000 > testerr[Ccurrent 1.000000] = 57.000000
	REVERSE: Cstepfactor is now 1.778279, Ccurrent remains 1.000000, Cnew is now 1.778279
		Training SVM with C=1.778279, nbinputs=100, numruns=20
	testerr[Cnew 1.778279] = 57.000000 > testerr[Ccurrent 1.000000] = 57.000000
	REVERSE: Cstepfactor is now 0.749894, Ccurrent remains 1.000000, Cnew is now 0.749894
		Training SVM with C=0.749894, nbinputs=100, numruns=20
	testerr[Cnew 0.749894] = 57.000000 > testerr[Ccurrent 1.000000] = 57.000000
	REVERSE: Cstepfactor is now 1.154782, Ccurrent remains 1.000000, Cnew is now 1.154782
		Training SVM with C=1.154782, nbinputs=100, numruns=20
	testerr[Cnew 1.154782] = 57.000000 > testerr[Ccurrent 1.000000] = 57.000000
	REVERSE: Cstepfactor is now 0.930572, Ccurrent remains 1.000000, Cnew is now 0.930572
		Training SVM with C=0.930572, nbinputs=100, numruns=20
	testerr[Cnew 0.930572] = 57.000000 > testerr[Ccurrent 1.000000] = 57.000000
	REVERSE: Cstepfactor is now 1.036633, Ccurrent remains 1.000000, Cnew is now 1.036633
		Training SVM with C=1.036633, nbinputs=100, numruns=20
	testerr[Cnew 1.036633] = 57.000000 > testerr[Ccurrent 1.000000] = 57.000000
	REVERSE: Cstepfactor is now 0.982172, Ccurrent remains 1.000000, Cnew is now 0.982172
		Training SVM with C=0.982172, nbinputs=100, numruns=20
	testerr[Cnew 0.982172] = 57.000000 > testerr[Ccurrent 1.000000] = 57.000000
	REVERSE: Cstepfactor is now 1.009035, Ccurrent remains 1.000000, Cnew is now 1.009035
		Training SVM with C=1.009035, nbinputs=100, numruns=20
	testerr[Cnew 1.009035] = 57.000000 > testerr[Ccurrent 1.000000] = 57.000000
	REVERSE: Cstepfactor is now 0.995513, Ccurrent remains 1.000000, Cnew is now 0.995513
		Training SVM with C=0.995513, nbinputs=100, numruns=20
	testerr[Cnew 0.995513] = 57.000000 > testerr[Ccurrent 1.000000] = 57.000000
	REVERSE: Cstepfactor is now 1.002251, Ccurrent remains 1.000000, Cnew is now 1.002251
		Training SVM with C=1.002251, nbinputs=100, numruns=20
	testerr[Cnew 1.002251] = 57.000000 > testerr[Ccurrent 1.000000] = 57.000000
	REVERSE: Cstepfactor is now 0.998876, Ccurrent remains 1.000000, Cnew is now 0.998876
		Training SVM with C=0.998876, nbinputs=100, numruns=20
	testerr[Cnew 0.998876] = 57.000000 > testerr[Ccurrent 1.000000] = 57.000000
	REVERSE: Cstepfactor is now 1.000562, Ccurrent remains 1.000000, Cnew is now 1.000562
		Training SVM with C=1.000562, nbinputs=100, numruns=20
	testerr[Cnew 1.000562] = 57.000000 > testerr[Ccurrent 1.000000] = 57.000000
	REVERSE: Cstepfactor is now 0.999719, Ccurrent remains 1.000000, Cnew is now 0.999719
		Training SVM with C=0.999719, nbinputs=100, numruns=20
	testerr[Cnew 0.999719] = 57.000000 > testerr[Ccurrent 1.000000] = 57.000000
	REVERSE: Cstepfactor is now 1.000141, Ccurrent remains 1.000000, Cnew is now 1.000141
		Training SVM with C=1.000141, nbinputs=100, numruns=20
	testerr[Cnew 1.000141] = 57.000000 > testerr[Ccurrent 1.000000] = 57.000000
	REVERSE: Cstepfactor is now 0.999930, Ccurrent remains 1.000000, Cnew is now 0.999930
		Training SVM with C=0.999930, nbinputs=100, numruns=20
	testerr[Cnew 0.999930] = 57.000000 > testerr[Ccurrent 1.000000] = 57.000000
	REVERSE: Cstepfactor is now 1.000035, Ccurrent remains 1.000000, Cnew is now 1.000035
		Training SVM with C=1.000035, nbinputs=100, numruns=20
	testerr[Cnew 1.000035] = 57.000000 > testerr[Ccurrent 1.000000] = 57.000000
	REVERSE: Cstepfactor is now 0.999982, Ccurrent remains 1.000000, Cnew is now 0.999982
	testerr[C 0.010000] = 57.690000 
	testerr[C 0.100000] = 57.350000 
	testerr[C 0.316228] = 57.000000 
	testerr[C 0.749894] = 57.000000 
	testerr[C 0.930572] = 57.000000 
	testerr[C 0.982172] = 57.000000 
	testerr[C 0.995513] = 57.000000 
	testerr[C 0.998876] = 57.000000 
	testerr[C 0.999719] = 57.000000 
	testerr[C 0.999930] = 57.000000 
	testerr[C 1.000000] = 57.000000  *best* (testerr = 57.000000, testerrdev = 3.155150, trainerr = 0.000000, trainerrdev = 0.000000)
	testerr[C 1.000035] = 57.000000 
	testerr[C 1.000141] = 57.000000 
	testerr[C 1.000562] = 57.000000 
	testerr[C 1.002251] = 57.000000 
	testerr[C 1.009035] = 57.000000 
	testerr[C 1.036633] = 57.000000 
	testerr[C 1.154782] = 57.000000 
	testerr[C 1.778279] = 57.000000 
	testerr[C 10.000000] = 57.000000 
...done with SVM validation for 100 examples (numrums=20, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm)...
ceylon.iro.umontreal.ca 2010-08-11 13:59:34.112616: 0:24:15.390000 user+sys, 0:30:56.830000 real, 78.38% usage, 583.55 MB
Starting SVM validation for 1000 examples (numrums=10, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm, PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211, MAXSTEPS=20, STEPFACTOR=10.000000, INITIALC=0.010000)...
ceylon.iro.umontreal.ca 2010-08-11 13:59:34.112847: 0:24:15.390000 user+sys, 0:30:56.830000 real, 78.38% usage, 583.55 MB
		Training SVM with C=0.010000, nbinputs=1000, numruns=10
		Training SVM with C=0.100000, nbinputs=1000, numruns=10
	testerr[Cnew 0.100000] = 55.770000 > testerr[Ccurrent 0.010000] = 48.710000
	Cbest <= 0.010000, testerr[Cbest] = 48.710000
	REVERSE: Cstepfactor is now 0.316228, Ccurrent remains 0.010000, Cnew is now 0.003162
		Training SVM with C=0.003162, nbinputs=1000, numruns=10
	testerr[Cnew 0.003162] = 48.010000 < testerr[Ccurrent 0.010000] = 48.710000
	NEW BEST: Cbest <= 0.003162, testerr[Cbest] = 48.010000
	PROCEED: Cstepfactor remains 0.316228, Ccurrent is now 0.003162, Cnew is now 0.001000
		Training SVM with C=0.001000, nbinputs=1000, numruns=10
	testerr[Cnew 0.001000] = 48.650000 > testerr[Ccurrent 0.003162] = 48.010000
	REVERSE: Cstepfactor is now 1.778279, Ccurrent remains 0.003162, Cnew is now 0.005623
		Training SVM with C=0.005623, nbinputs=1000, numruns=10
	testerr[Cnew 0.005623] = 47.230000 < testerr[Ccurrent 0.003162] = 48.010000
	NEW BEST: Cbest <= 0.005623, testerr[Cbest] = 47.230000
	PROCEED: Cstepfactor remains 1.778279, Ccurrent is now 0.005623, Cnew is now 0.010000
	testerr[Cnew 0.010000] = 48.710000 > testerr[Ccurrent 0.005623] = 47.230000
	REVERSE: Cstepfactor is now 0.749894, Ccurrent remains 0.005623, Cnew is now 0.004217
		Training SVM with C=0.004217, nbinputs=1000, numruns=10
	testerr[Cnew 0.004217] = 47.290000 > testerr[Ccurrent 0.005623] = 47.230000
	REVERSE: Cstepfactor is now 1.154782, Ccurrent remains 0.005623, Cnew is now 0.006494
		Training SVM with C=0.006494, nbinputs=1000, numruns=10
	testerr[Cnew 0.006494] = 47.670000 > testerr[Ccurrent 0.005623] = 47.230000
	REVERSE: Cstepfactor is now 0.930572, Ccurrent remains 0.005623, Cnew is now 0.005233
		Training SVM with C=0.005233, nbinputs=1000, numruns=10
	testerr[Cnew 0.005233] = 47.100000 < testerr[Ccurrent 0.005623] = 47.230000
	NEW BEST: Cbest <= 0.005233, testerr[Cbest] = 47.100000
	PROCEED: Cstepfactor remains 0.930572, Ccurrent is now 0.005233, Cnew is now 0.004870
		Training SVM with C=0.004870, nbinputs=1000, numruns=10
	testerr[Cnew 0.004870] = 47.110000 > testerr[Ccurrent 0.005233] = 47.100000
	REVERSE: Cstepfactor is now 1.036633, Ccurrent remains 0.005233, Cnew is now 0.005425
		Training SVM with C=0.005425, nbinputs=1000, numruns=10
	testerr[Cnew 0.005425] = 47.110000 > testerr[Ccurrent 0.005233] = 47.100000
	REVERSE: Cstepfactor is now 0.982172, Ccurrent remains 0.005233, Cnew is now 0.005140
		Training SVM with C=0.005140, nbinputs=1000, numruns=10
	testerr[Cnew 0.005140] = 47.220000 > testerr[Ccurrent 0.005233] = 47.100000
	REVERSE: Cstepfactor is now 1.009035, Ccurrent remains 0.005233, Cnew is now 0.005280
		Training SVM with C=0.005280, nbinputs=1000, numruns=10
	testerr[Cnew 0.005280] = 47.160000 > testerr[Ccurrent 0.005233] = 47.100000
	REVERSE: Cstepfactor is now 0.995513, Ccurrent remains 0.005233, Cnew is now 0.005210
		Training SVM with C=0.005210, nbinputs=1000, numruns=10
	testerr[Cnew 0.005210] = 47.200000 > testerr[Ccurrent 0.005233] = 47.100000
	REVERSE: Cstepfactor is now 1.002251, Ccurrent remains 0.005233, Cnew is now 0.005245
		Training SVM with C=0.005245, nbinputs=1000, numruns=10
	testerr[Cnew 0.005245] = 47.210000 > testerr[Ccurrent 0.005233] = 47.100000
	REVERSE: Cstepfactor is now 0.998876, Ccurrent remains 0.005233, Cnew is now 0.005227
		Training SVM with C=0.005227, nbinputs=1000, numruns=10
	testerr[Cnew 0.005227] = 47.260000 > testerr[Ccurrent 0.005233] = 47.100000
	REVERSE: Cstepfactor is now 1.000562, Ccurrent remains 0.005233, Cnew is now 0.005236
		Training SVM with C=0.005236, nbinputs=1000, numruns=10
	testerr[Cnew 0.005236] = 47.140000 > testerr[Ccurrent 0.005233] = 47.100000
	REVERSE: Cstepfactor is now 0.999719, Ccurrent remains 0.005233, Cnew is now 0.005232
		Training SVM with C=0.005232, nbinputs=1000, numruns=10
	testerr[Cnew 0.005232] = 47.170000 > testerr[Ccurrent 0.005233] = 47.100000
	REVERSE: Cstepfactor is now 1.000141, Ccurrent remains 0.005233, Cnew is now 0.005234
		Training SVM with C=0.005234, nbinputs=1000, numruns=10
	testerr[Cnew 0.005234] = 47.100000 > testerr[Ccurrent 0.005233] = 47.100000
	REVERSE: Cstepfactor is now 0.999930, Ccurrent remains 0.005233, Cnew is now 0.005233
		Training SVM with C=0.005233, nbinputs=1000, numruns=10
	testerr[Cnew 0.005233] = 47.110000 > testerr[Ccurrent 0.005233] = 47.100000
	REVERSE: Cstepfactor is now 1.000035, Ccurrent remains 0.005233, Cnew is now 0.005233
		Training SVM with C=0.005233, nbinputs=1000, numruns=10
	testerr[Cnew 0.005233] = 47.190000 > testerr[Ccurrent 0.005233] = 47.100000
	REVERSE: Cstepfactor is now 0.999982, Ccurrent remains 0.005233, Cnew is now 0.005233
	testerr[C 0.001000] = 48.650000 
	testerr[C 0.003162] = 48.010000 
	testerr[C 0.004217] = 47.290000 
	testerr[C 0.004870] = 47.110000 
	testerr[C 0.005140] = 47.220000 
	testerr[C 0.005210] = 47.200000 
	testerr[C 0.005227] = 47.260000 
	testerr[C 0.005232] = 47.170000 
	testerr[C 0.005233] = 47.110000 
	testerr[C 0.005233] = 47.100000  *best* (testerr = 47.100000, testerrdev = 0.219089, trainerr = 26.260000, trainerrdev = 0.233238)
	testerr[C 0.005233] = 47.190000 
	testerr[C 0.005234] = 47.100000 
	testerr[C 0.005236] = 47.140000 
	testerr[C 0.005245] = 47.210000 
	testerr[C 0.005280] = 47.160000 
	testerr[C 0.005425] = 47.110000 
	testerr[C 0.005623] = 47.230000 
	testerr[C 0.006494] = 47.670000 
	testerr[C 0.010000] = 48.710000 
	testerr[C 0.100000] = 55.770000 
...done with SVM validation for 1000 examples (numrums=10, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm)...
ceylon.iro.umontreal.ca 2010-08-11 14:00:39.600223: 0:24:15.470000 user+sys, 0:32:02.310000 real, 75.71% usage, 583.55 MB
Starting SVM validation for 10000 examples (numrums=1, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm, PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211, MAXSTEPS=20, STEPFACTOR=10.000000, INITIALC=0.010000)...
ceylon.iro.umontreal.ca 2010-08-11 14:00:39.600456: 0:24:15.470000 user+sys, 0:32:02.310000 real, 75.71% usage, 583.55 MB
		Training SVM with C=0.010000, nbinputs=10000, numruns=1
		Training SVM with C=0.100000, nbinputs=10000, numruns=1
	testerr[Cnew 0.100000] = 55.700000 > testerr[Ccurrent 0.010000] = 49.100000
	Cbest <= 0.010000, testerr[Cbest] = 49.100000
	REVERSE: Cstepfactor is now 0.316228, Ccurrent remains 0.010000, Cnew is now 0.003162
		Training SVM with C=0.003162, nbinputs=10000, numruns=1
	testerr[Cnew 0.003162] = 47.900000 < testerr[Ccurrent 0.010000] = 49.100000
	NEW BEST: Cbest <= 0.003162, testerr[Cbest] = 47.900000
	PROCEED: Cstepfactor remains 0.316228, Ccurrent is now 0.003162, Cnew is now 0.001000
		Training SVM with C=0.001000, nbinputs=10000, numruns=1
	testerr[Cnew 0.001000] = 49.100000 > testerr[Ccurrent 0.003162] = 47.900000
	REVERSE: Cstepfactor is now 1.778279, Ccurrent remains 0.003162, Cnew is now 0.005623
		Training SVM with C=0.005623, nbinputs=10000, numruns=1
	testerr[Cnew 0.005623] = 47.300000 < testerr[Ccurrent 0.003162] = 47.900000
	NEW BEST: Cbest <= 0.005623, testerr[Cbest] = 47.300000
	PROCEED: Cstepfactor remains 1.778279, Ccurrent is now 0.005623, Cnew is now 0.010000
	testerr[Cnew 0.010000] = 49.100000 > testerr[Ccurrent 0.005623] = 47.300000
	REVERSE: Cstepfactor is now 0.749894, Ccurrent remains 0.005623, Cnew is now 0.004217
		Training SVM with C=0.004217, nbinputs=10000, numruns=1
	testerr[Cnew 0.004217] = 47.300000 > testerr[Ccurrent 0.005623] = 47.300000
	REVERSE: Cstepfactor is now 1.154782, Ccurrent remains 0.005623, Cnew is now 0.006494
		Training SVM with C=0.006494, nbinputs=10000, numruns=1
	testerr[Cnew 0.006494] = 47.700000 > testerr[Ccurrent 0.005623] = 47.300000
	REVERSE: Cstepfactor is now 0.930572, Ccurrent remains 0.005623, Cnew is now 0.005233
		Training SVM with C=0.005233, nbinputs=10000, numruns=1
	testerr[Cnew 0.005233] = 46.900000 < testerr[Ccurrent 0.005623] = 47.300000
	NEW BEST: Cbest <= 0.005233, testerr[Cbest] = 46.900000
	PROCEED: Cstepfactor remains 0.930572, Ccurrent is now 0.005233, Cnew is now 0.004870
		Training SVM with C=0.004870, nbinputs=10000, numruns=1
	testerr[Cnew 0.004870] = 47.000000 > testerr[Ccurrent 0.005233] = 46.900000
	REVERSE: Cstepfactor is now 1.036633, Ccurrent remains 0.005233, Cnew is now 0.005425
		Training SVM with C=0.005425, nbinputs=10000, numruns=1
	testerr[Cnew 0.005425] = 47.000000 > testerr[Ccurrent 0.005233] = 46.900000
	REVERSE: Cstepfactor is now 0.982172, Ccurrent remains 0.005233, Cnew is now 0.005140
		Training SVM with C=0.005140, nbinputs=10000, numruns=1
	testerr[Cnew 0.005140] = 46.900000 > testerr[Ccurrent 0.005233] = 46.900000
	REVERSE: Cstepfactor is now 1.009035, Ccurrent remains 0.005233, Cnew is now 0.005280
		Training SVM with C=0.005280, nbinputs=10000, numruns=1
	testerr[Cnew 0.005280] = 47.600000 > testerr[Ccurrent 0.005233] = 46.900000
	REVERSE: Cstepfactor is now 0.995513, Ccurrent remains 0.005233, Cnew is now 0.005210
		Training SVM with C=0.005210, nbinputs=10000, numruns=1
	testerr[Cnew 0.005210] = 47.300000 > testerr[Ccurrent 0.005233] = 46.900000
	REVERSE: Cstepfactor is now 1.002251, Ccurrent remains 0.005233, Cnew is now 0.005245
		Training SVM with C=0.005245, nbinputs=10000, numruns=1
	testerr[Cnew 0.005245] = 47.100000 > testerr[Ccurrent 0.005233] = 46.900000
	REVERSE: Cstepfactor is now 0.998876, Ccurrent remains 0.005233, Cnew is now 0.005227
		Training SVM with C=0.005227, nbinputs=10000, numruns=1
	testerr[Cnew 0.005227] = 47.400000 > testerr[Ccurrent 0.005233] = 46.900000
	REVERSE: Cstepfactor is now 1.000562, Ccurrent remains 0.005233, Cnew is now 0.005236
		Training SVM with C=0.005236, nbinputs=10000, numruns=1
	testerr[Cnew 0.005236] = 47.100000 > testerr[Ccurrent 0.005233] = 46.900000
	REVERSE: Cstepfactor is now 0.999719, Ccurrent remains 0.005233, Cnew is now 0.005232
		Training SVM with C=0.005232, nbinputs=10000, numruns=1
	testerr[Cnew 0.005232] = 46.900000 > testerr[Ccurrent 0.005233] = 46.900000
	REVERSE: Cstepfactor is now 1.000141, Ccurrent remains 0.005233, Cnew is now 0.005234
		Training SVM with C=0.005234, nbinputs=10000, numruns=1
	testerr[Cnew 0.005234] = 47.400000 > testerr[Ccurrent 0.005233] = 46.900000
	REVERSE: Cstepfactor is now 0.999930, Ccurrent remains 0.005233, Cnew is now 0.005233
		Training SVM with C=0.005233, nbinputs=10000, numruns=1
	testerr[Cnew 0.005233] = 46.900000 > testerr[Ccurrent 0.005233] = 46.900000
	REVERSE: Cstepfactor is now 1.000035, Ccurrent remains 0.005233, Cnew is now 0.005233
		Training SVM with C=0.005233, nbinputs=10000, numruns=1
	testerr[Cnew 0.005233] = 47.300000 > testerr[Ccurrent 0.005233] = 46.900000
	REVERSE: Cstepfactor is now 0.999982, Ccurrent remains 0.005233, Cnew is now 0.005233
	testerr[C 0.001000] = 49.100000 
	testerr[C 0.003162] = 47.900000 
	testerr[C 0.004217] = 47.300000 
	testerr[C 0.004870] = 47.000000 
	testerr[C 0.005140] = 46.900000 
	testerr[C 0.005210] = 47.300000 
	testerr[C 0.005227] = 47.400000 
	testerr[C 0.005232] = 46.900000 
	testerr[C 0.005233] = 46.900000 
	testerr[C 0.005233] = 46.900000  *best* (testerr = 46.900000, testerrdev = 0.000000, trainerr = 26.100000, trainerrdev = 0.000000)
	testerr[C 0.005233] = 47.300000 
	testerr[C 0.005234] = 47.400000 
	testerr[C 0.005236] = 47.100000 
	testerr[C 0.005245] = 47.100000 
	testerr[C 0.005280] = 47.600000 
	testerr[C 0.005425] = 47.000000 
	testerr[C 0.005623] = 47.300000 
	testerr[C 0.006494] = 47.700000 
	testerr[C 0.010000] = 49.100000 
	testerr[C 0.100000] = 55.700000 
...done with SVM validation for 10000 examples (numrums=1, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm)...
ceylon.iro.umontreal.ca 2010-08-11 14:00:59.076251: 0:24:15.550000 user+sys, 0:32:21.780000 real, 74.96% usage, 583.55 MB
		----  Encoding  layer #1 ----
			**** DenseLayer.__init__ ****
			tag =  enc1
			inp =  inp
			n_inp =  5000
			n_out =  1000
			act =  tanh
			noise =  binomial_NLP
			out =  outenc1
			params (gradients) =  [Wenc1, benc1]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc1
			allocW, allocb, allocmask =  False False False
		----  Encoding  layer #2 ----
			**** DenseLayer.__init__ ****
			tag =  enc2
			inp =  outenc1
			n_inp =  1000
			n_out =  1000
			act =  tanh
			noise =  binomial
			out =  outenc2
			params (gradients) =  [Wenc2, benc2]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc2
			allocW, allocb, allocmask =  False False False
MRG_RandomStreams Can't determine #streams from size (Shape.0), guessing 30*256
	---- Auxiliary Layer ----
			**** DenseLayer.__init__ ****
			tag =  aux-1
			inp =  outenc2
			n_inp =  1000
			n_out =  1000
			act =  sigmoid
			noise =  None
			out =  outaux-1
			params (gradients) =  [Waux-1, baux-1]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  None
			allocW, allocb, allocmask =  False False ones
	**** SDAE ****
	depth =  3
	mode =  Aux
	depth_min, depth_max, update_type =  0 , 2 , special
	inp, n_inp =  inp , 5000
	n_hid =  [1000, 1000, 1000]
	layertype =  [<class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>]
	act =  ['tanh', 'tanh', 'rectifier']
	noise, noise_lvl =  ['binomial_NLP', 'binomial', 'binomial'] , 0.5
	tie =  [True, True, True]
	maskbool =  [None, None, None]
	n_out, outtype =  5 , <class 'deepANN.Logistic_regression.LogisticRegression'>
	lr =  0.001
	sup_scaling, unsup_scaling, aux_scaling  =  None None 1.0
	regularization, wdreg  =  [0.0, 0.0, 0.0, 0.0] , l2
	sparsity, spreg =  [0.0, 0.0, 0.01] , l1
	params, wd, sp =  [Wenc2, benc2, Waux-1, baux-1] , [] , []
	bbbool, hessscal =  None , None
	aux, auxtarget, aux_one_sided, auxdepth, auxregularization =  True , auxtarget , True , -1 , False
	auxact, auxn_out, auxwdreg =  sigmoid , 1000 , l2
##########  TEST ############ EPOCH :  0
CURRENT RECONSTRUCTION ERROR (is this on test or train?):  703.68967627
CURRENT 100 SVM ERROR:  (1.0, 57.0, 3.1551499999999999, 0.0, 0.0)
CURRENT 1000 SVM ERROR:  (0.0052329911468149467, 47.100000000000001, 0.21908900000000001, 26.260000000000002, 0.233238)
CURRENT 10000 SVM ERROR:  (0.0052329911468149467, 46.899999999999999, 0.0, 26.100000000000001, 0.0)
ceylon.iro.umontreal.ca 2010-08-11 14:01:04.880796: 0:24:21.230000 user+sys, 0:32:27.580000 real, 75.03% usage, 583.55 MB
...done validating (err={1000: {0: (0.0052329911468149467, 47.100000000000001, 0.21908900000000001, 26.260000000000002, 0.233238)}, 10000: {0: (0.0052329911468149467, 46.899999999999999, 0.0, 26.100000000000001, 0.0)}, 100: {0: (1.0, 57.0, 3.1551499999999999, 0.0, 0.0)}},epoch=0,model=<deepANN.ANN.SDAE object at 0x30fcb50>,depth=1,ACT=['tanh', 'tanh', 'rectifier'],LR=0.001,NOISE_LVL=0.5,BATCHSIZE=10,train=<CudaNdarrayType(float32, matrix)>,datatrain=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_labels_1.pkl'),datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm,datatest=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_labels_1.pkl'),datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm,VALIDATION_TRAININGSIZE=[100, 1000, 10000],VALIDATION_RUNS_FOR_EACH_TRAININGSIZE={'100': 20, '10000': 1, '1000': 10},PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211)
ceylon.iro.umontreal.ca 2010-08-11 14:01:04.881147: 0:24:21.230000 user+sys, 0:32:27.580000 real, 75.03% usage, 583.55 MB
File: 1 16.632581234 ----
ceylon.iro.umontreal.ca 2010-08-11 14:01:21.513882: 0:24:37.810000 user+sys, 0:32:44.210000 real, 75.24% usage, 583.55 MB
File: 2 16.5790598392 ----
ceylon.iro.umontreal.ca 2010-08-11 14:01:38.093518: 0:24:54.390000 user+sys, 0:33:00.790000 real, 75.44% usage, 583.55 MB
File: 3 16.5875828266 ----
ceylon.iro.umontreal.ca 2010-08-11 14:01:54.681680: 0:25:10.970000 user+sys, 0:33:17.380000 real, 75.65% usage, 583.55 MB
File: 4 16.5797498226 ----
ceylon.iro.umontreal.ca 2010-08-11 14:02:11.261995: 0:25:27.550000 user+sys, 0:33:33.950000 real, 75.85% usage, 583.55 MB
File: 5 16.5825631618 ----
ceylon.iro.umontreal.ca 2010-08-11 14:02:27.845133: 0:25:44.120000 user+sys, 0:33:50.530000 real, 76.05% usage, 583.55 MB
File: 6 16.5816118717 ----
ceylon.iro.umontreal.ca 2010-08-11 14:02:44.427327: 0:26:00.710000 user+sys, 0:34:07.120000 real, 76.24% usage, 583.55 MB
File: 7 16.5735070705 ----
ceylon.iro.umontreal.ca 2010-08-11 14:03:01.001426: 0:26:17.270000 user+sys, 0:34:23.690000 real, 76.43% usage, 583.55 MB
File: 8 16.5854318142 ----
ceylon.iro.umontreal.ca 2010-08-11 14:03:17.587423: 0:26:33.850000 user+sys, 0:34:40.270000 real, 76.62% usage, 583.55 MB
File: 9 16.6375100613 ----
ceylon.iro.umontreal.ca 2010-08-11 14:03:34.225515: 0:26:50.480000 user+sys, 0:34:56.910000 real, 76.80% usage, 583.55 MB
File: 10 16.6048231125 ----
ceylon.iro.umontreal.ca 2010-08-11 14:03:50.830712: 0:27:07.070000 user+sys, 0:35:13.510000 real, 76.98% usage, 583.55 MB
File: 11 16.6724798679 ----
ceylon.iro.umontreal.ca 2010-08-11 14:04:07.503748: 0:27:23.740000 user+sys, 0:35:30.180000 real, 77.16% usage, 583.55 MB
File: 12 16.7694530487 ----
ceylon.iro.umontreal.ca 2010-08-11 14:04:24.273745: 0:27:40.500000 user+sys, 0:35:46.950000 real, 77.34% usage, 583.55 MB
File: 13 16.7836229801 ----
ceylon.iro.umontreal.ca 2010-08-11 14:04:41.057917: 0:27:57.280000 user+sys, 0:36:03.730000 real, 77.52% usage, 583.55 MB
File: 14 16.7686209679 ----
ceylon.iro.umontreal.ca 2010-08-11 14:04:57.827124: 0:28:14.040000 user+sys, 0:36:20.490000 real, 77.69% usage, 583.55 MB
File: 15 16.0691869259 ----
ceylon.iro.umontreal.ca 2010-08-11 14:05:13.896860: 0:28:30.100000 user+sys, 0:36:36.560000 real, 77.85% usage, 583.55 MB
...finished training epoch #1 of 3 (33.33%)
ceylon.iro.umontreal.ca 2010-08-11 14:05:13.897379: 0:28:30.110000 user+sys, 0:36:36.560000 real, 77.85% usage, 583.55 MB
Validating (err={1000: {0: (0.0052329911468149467, 47.100000000000001, 0.21908900000000001, 26.260000000000002, 0.233238)}, 10000: {0: (0.0052329911468149467, 46.899999999999999, 0.0, 26.100000000000001, 0.0)}, 100: {0: (1.0, 57.0, 3.1551499999999999, 0.0, 0.0)}},epoch=1,model=<deepANN.ANN.SDAE object at 0x30fcb50>,depth=1,ACT=['tanh', 'tanh', 'rectifier'],LR=0.001,NOISE_LVL=0.5,BATCHSIZE=10,train=<CudaNdarrayType(float32, matrix)>,datatrain=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_labels_1.pkl'),datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm,datatest=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_labels_1.pkl'),datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm,VALIDATION_TRAININGSIZE=[100, 1000, 10000],VALIDATION_RUNS_FOR_EACH_TRAININGSIZE={'100': 20, '10000': 1, '1000': 10},PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211)...
ceylon.iro.umontreal.ca 2010-08-11 14:05:13.897634: 0:28:30.110000 user+sys, 0:36:36.560000 real, 77.85% usage, 583.55 MB
		----  Encoding  layer #1 ----
			**** DenseLayer.__init__ ****
			tag =  enc1
			inp =  inp
			n_inp =  5000
			n_out =  1000
			act =  tanh
			noise =  binomial_NLP
			out =  outenc1
			params (gradients) =  [Wenc1, benc1]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc1
			allocW, allocb, allocmask =  False False False
		----  Encoding  layer #2 ----
			**** DenseLayer.__init__ ****
			tag =  enc2
			inp =  outenc1
			n_inp =  1000
			n_out =  1000
			act =  tanh
			noise =  binomial
			out =  outenc2
			params (gradients) =  [Wenc2, benc2]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc2
			allocW, allocb, allocmask =  False False False
	---- Auxiliary Layer ----
			**** DenseLayer.__init__ ****
			tag =  aux-1
			inp =  outenc2
			n_inp =  1000
			n_out =  1000
			act =  sigmoid
			noise =  None
			out =  outaux-1
			params (gradients) =  [Waux-1, baux-1]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  None
			allocW, allocb, allocmask =  False False ones
	**** SDAE ****
	depth =  3
	mode =  Aux
	depth_min, depth_max, update_type =  0 , 2 , special
	inp, n_inp =  inp , 5000
	n_hid =  [1000, 1000, 1000]
	layertype =  [<class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>]
	act =  ['tanh', 'tanh', 'rectifier']
	noise, noise_lvl =  ['binomial_NLP', 'binomial', 'binomial'] , None
	tie =  [True, True, True]
	maskbool =  [None, None, None]
	n_out, outtype =  5 , <class 'deepANN.Logistic_regression.LogisticRegression'>
	lr =  0.001
	sup_scaling, unsup_scaling, aux_scaling  =  None None 1.0
	regularization, wdreg  =  [0.0, 0.0, 0.0, 0.0] , l2
	sparsity, spreg =  [0.0, 0.0, 0.01] , l1
	params, wd, sp =  [Wenc2, benc2, Waux-1, baux-1] , [] , []
	bbbool, hessscal =  None , None
	aux, auxtarget, aux_one_sided, auxdepth, auxregularization =  True , auxtarget , True , -1 , False
	auxact, auxn_out, auxwdreg =  sigmoid , 1000 , l2
Creating libsvm file '/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm' (model=<deepANN.ANN.SDAE object at 0x30fcb50>, depth=1, datafiles=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_labels_1.pkl'))...
ceylon.iro.umontreal.ca 2010-08-11 14:05:16.395318: 0:28:32.520000 user+sys, 0:36:39.060000 real, 77.88% usage, 583.55 MB
...done creating libsvm files
ceylon.iro.umontreal.ca 2010-08-11 14:05:26.635763: 0:28:42.580000 user+sys, 0:36:49.300000 real, 77.97% usage, 583.55 MB
Creating libsvm file '/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm' (model=<deepANN.ANN.SDAE object at 0x30fcb50>, depth=1, datafiles=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_labels_1.pkl'))...
ceylon.iro.umontreal.ca 2010-08-11 14:05:26.636239: 0:28:42.580000 user+sys, 0:36:49.300000 real, 77.97% usage, 583.55 MB
...done creating libsvm files
ceylon.iro.umontreal.ca 2010-08-11 14:05:36.790749: 0:28:52.560000 user+sys, 0:36:59.450000 real, 78.06% usage, 583.55 MB
Starting SVM validation for 100 examples (numrums=20, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm, PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211, MAXSTEPS=20, STEPFACTOR=10.000000, INITIALC=0.010000)...
ceylon.iro.umontreal.ca 2010-08-11 14:05:36.791236: 0:28:52.560000 user+sys, 0:36:59.450000 real, 78.06% usage, 583.55 MB
		Training SVM with C=0.010000, nbinputs=100, numruns=20
		Training SVM with C=0.100000, nbinputs=100, numruns=20
	testerr[Cnew 0.100000] = 55.915000 < testerr[Ccurrent 0.010000] = 56.470000
	NEW BEST: Cbest <= 0.100000, testerr[Cbest] = 55.915000
	PROCEED: Cstepfactor remains 10.000000, Ccurrent is now 0.100000, Cnew is now 1.000000
		Training SVM with C=1.000000, nbinputs=100, numruns=20
	testerr[Cnew 1.000000] = 55.915000 > testerr[Ccurrent 0.100000] = 55.915000
	REVERSE: Cstepfactor is now 0.316228, Ccurrent remains 0.100000, Cnew is now 0.031623
		Training SVM with C=0.031623, nbinputs=100, numruns=20
	testerr[Cnew 0.031623] = 56.000000 > testerr[Ccurrent 0.100000] = 55.915000
	REVERSE: Cstepfactor is now 1.778279, Ccurrent remains 0.100000, Cnew is now 0.177828
		Training SVM with C=0.177828, nbinputs=100, numruns=20
	testerr[Cnew 0.177828] = 55.915000 > testerr[Ccurrent 0.100000] = 55.915000
	REVERSE: Cstepfactor is now 0.749894, Ccurrent remains 0.100000, Cnew is now 0.074989
		Training SVM with C=0.074989, nbinputs=100, numruns=20
	testerr[Cnew 0.074989] = 57.395000 > testerr[Ccurrent 0.100000] = 55.915000
	REVERSE: Cstepfactor is now 1.154782, Ccurrent remains 0.100000, Cnew is now 0.115478
		Training SVM with C=0.115478, nbinputs=100, numruns=20
	testerr[Cnew 0.115478] = 55.915000 > testerr[Ccurrent 0.100000] = 55.915000
	REVERSE: Cstepfactor is now 0.930572, Ccurrent remains 0.100000, Cnew is now 0.093057
		Training SVM with C=0.093057, nbinputs=100, numruns=20
	testerr[Cnew 0.093057] = 55.915000 > testerr[Ccurrent 0.100000] = 55.915000
	REVERSE: Cstepfactor is now 1.036633, Ccurrent remains 0.100000, Cnew is now 0.103663
		Training SVM with C=0.103663, nbinputs=100, numruns=20
	testerr[Cnew 0.103663] = 55.915000 > testerr[Ccurrent 0.100000] = 55.915000
	REVERSE: Cstepfactor is now 0.982172, Ccurrent remains 0.100000, Cnew is now 0.098217
		Training SVM with C=0.098217, nbinputs=100, numruns=20
	testerr[Cnew 0.098217] = 55.915000 > testerr[Ccurrent 0.100000] = 55.915000
	REVERSE: Cstepfactor is now 1.009035, Ccurrent remains 0.100000, Cnew is now 0.100904
		Training SVM with C=0.100904, nbinputs=100, numruns=20
	testerr[Cnew 0.100904] = 55.915000 > testerr[Ccurrent 0.100000] = 55.915000
	REVERSE: Cstepfactor is now 0.995513, Ccurrent remains 0.100000, Cnew is now 0.099551
		Training SVM with C=0.099551, nbinputs=100, numruns=20
	testerr[Cnew 0.099551] = 55.915000 > testerr[Ccurrent 0.100000] = 55.915000
	REVERSE: Cstepfactor is now 1.002251, Ccurrent remains 0.100000, Cnew is now 0.100225
		Training SVM with C=0.100225, nbinputs=100, numruns=20
	testerr[Cnew 0.100225] = 55.915000 > testerr[Ccurrent 0.100000] = 55.915000
	REVERSE: Cstepfactor is now 0.998876, Ccurrent remains 0.100000, Cnew is now 0.099888
		Training SVM with C=0.099888, nbinputs=100, numruns=20
	testerr[Cnew 0.099888] = 55.915000 > testerr[Ccurrent 0.100000] = 55.915000
	REVERSE: Cstepfactor is now 1.000562, Ccurrent remains 0.100000, Cnew is now 0.100056
		Training SVM with C=0.100056, nbinputs=100, numruns=20
	testerr[Cnew 0.100056] = 55.915000 > testerr[Ccurrent 0.100000] = 55.915000
	REVERSE: Cstepfactor is now 0.999719, Ccurrent remains 0.100000, Cnew is now 0.099972
		Training SVM with C=0.099972, nbinputs=100, numruns=20
	testerr[Cnew 0.099972] = 55.915000 > testerr[Ccurrent 0.100000] = 55.915000
	REVERSE: Cstepfactor is now 1.000141, Ccurrent remains 0.100000, Cnew is now 0.100014
		Training SVM with C=0.100014, nbinputs=100, numruns=20
	testerr[Cnew 0.100014] = 55.915000 > testerr[Ccurrent 0.100000] = 55.915000
	REVERSE: Cstepfactor is now 0.999930, Ccurrent remains 0.100000, Cnew is now 0.099993
		Training SVM with C=0.099993, nbinputs=100, numruns=20
	testerr[Cnew 0.099993] = 55.915000 > testerr[Ccurrent 0.100000] = 55.915000
	REVERSE: Cstepfactor is now 1.000035, Ccurrent remains 0.100000, Cnew is now 0.100004
		Training SVM with C=0.100004, nbinputs=100, numruns=20
	testerr[Cnew 0.100004] = 55.915000 > testerr[Ccurrent 0.100000] = 55.915000
	REVERSE: Cstepfactor is now 0.999982, Ccurrent remains 0.100000, Cnew is now 0.099998
		Training SVM with C=0.099998, nbinputs=100, numruns=20
	testerr[Cnew 0.099998] = 55.915000 > testerr[Ccurrent 0.100000] = 55.915000
	REVERSE: Cstepfactor is now 1.000009, Ccurrent remains 0.100000, Cnew is now 0.100001
	testerr[C 0.010000] = 56.470000 
	testerr[C 0.031623] = 56.000000 
	testerr[C 0.074989] = 57.395000 
	testerr[C 0.093057] = 55.915000 
	testerr[C 0.098217] = 55.915000 
	testerr[C 0.099551] = 55.915000 
	testerr[C 0.099888] = 55.915000 
	testerr[C 0.099972] = 55.915000 
	testerr[C 0.099993] = 55.915000 
	testerr[C 0.099998] = 55.915000 
	testerr[C 0.100000] = 55.915000  *best* (testerr = 55.915000, testerrdev = 2.852420, trainerr = 0.000000, trainerrdev = 0.000000)
	testerr[C 0.100004] = 55.915000 
	testerr[C 0.100014] = 55.915000 
	testerr[C 0.100056] = 55.915000 
	testerr[C 0.100225] = 55.915000 
	testerr[C 0.100904] = 55.915000 
	testerr[C 0.103663] = 55.915000 
	testerr[C 0.115478] = 55.915000 
	testerr[C 0.177828] = 55.915000 
	testerr[C 1.000000] = 55.915000 
...done with SVM validation for 100 examples (numrums=20, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm)...
ceylon.iro.umontreal.ca 2010-08-11 14:06:28.472342: 0:28:52.650000 user+sys, 0:37:51.130000 real, 76.29% usage, 583.55 MB
Starting SVM validation for 1000 examples (numrums=10, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm, PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211, MAXSTEPS=20, STEPFACTOR=10.000000, INITIALC=0.010000)...
ceylon.iro.umontreal.ca 2010-08-11 14:06:28.472721: 0:28:52.650000 user+sys, 0:37:51.130000 real, 76.29% usage, 583.55 MB
		Training SVM with C=0.010000, nbinputs=1000, numruns=10
		Training SVM with C=0.100000, nbinputs=1000, numruns=10
	testerr[Cnew 0.100000] = 56.140000 > testerr[Ccurrent 0.010000] = 48.890000
	Cbest <= 0.010000, testerr[Cbest] = 48.890000
	REVERSE: Cstepfactor is now 0.316228, Ccurrent remains 0.010000, Cnew is now 0.003162
		Training SVM with C=0.003162, nbinputs=1000, numruns=10
	testerr[Cnew 0.003162] = 47.420000 < testerr[Ccurrent 0.010000] = 48.890000
	NEW BEST: Cbest <= 0.003162, testerr[Cbest] = 47.420000
	PROCEED: Cstepfactor remains 0.316228, Ccurrent is now 0.003162, Cnew is now 0.001000
		Training SVM with C=0.001000, nbinputs=1000, numruns=10
	testerr[Cnew 0.001000] = 47.280000 < testerr[Ccurrent 0.003162] = 47.420000
	NEW BEST: Cbest <= 0.001000, testerr[Cbest] = 47.280000
	PROCEED: Cstepfactor remains 0.316228, Ccurrent is now 0.001000, Cnew is now 0.000316
		Training SVM with C=0.000316, nbinputs=1000, numruns=10
	testerr[Cnew 0.000316] = 49.880000 > testerr[Ccurrent 0.001000] = 47.280000
	REVERSE: Cstepfactor is now 1.778279, Ccurrent remains 0.001000, Cnew is now 0.001778
		Training SVM with C=0.001778, nbinputs=1000, numruns=10
	testerr[Cnew 0.001778] = 47.300000 > testerr[Ccurrent 0.001000] = 47.280000
	REVERSE: Cstepfactor is now 0.749894, Ccurrent remains 0.001000, Cnew is now 0.000750
		Training SVM with C=0.000750, nbinputs=1000, numruns=10
	testerr[Cnew 0.000750] = 47.510000 > testerr[Ccurrent 0.001000] = 47.280000
	REVERSE: Cstepfactor is now 1.154782, Ccurrent remains 0.001000, Cnew is now 0.001155
		Training SVM with C=0.001155, nbinputs=1000, numruns=10
	testerr[Cnew 0.001155] = 47.080000 < testerr[Ccurrent 0.001000] = 47.280000
	NEW BEST: Cbest <= 0.001155, testerr[Cbest] = 47.080000
	PROCEED: Cstepfactor remains 1.154782, Ccurrent is now 0.001155, Cnew is now 0.001334
		Training SVM with C=0.001334, nbinputs=1000, numruns=10
	testerr[Cnew 0.001334] = 46.940000 < testerr[Ccurrent 0.001155] = 47.080000
	NEW BEST: Cbest <= 0.001334, testerr[Cbest] = 46.940000
	PROCEED: Cstepfactor remains 1.154782, Ccurrent is now 0.001334, Cnew is now 0.001540
		Training SVM with C=0.001540, nbinputs=1000, numruns=10
	testerr[Cnew 0.001540] = 46.920000 < testerr[Ccurrent 0.001334] = 46.940000
	NEW BEST: Cbest <= 0.001540, testerr[Cbest] = 46.920000
	PROCEED: Cstepfactor remains 1.154782, Ccurrent is now 0.001540, Cnew is now 0.001778
		Training SVM with C=0.001778, nbinputs=1000, numruns=10
	testerr[Cnew 0.001778] = 47.300000 > testerr[Ccurrent 0.001540] = 46.920000
	REVERSE: Cstepfactor is now 0.930572, Ccurrent remains 0.001540, Cnew is now 0.001433
		Training SVM with C=0.001433, nbinputs=1000, numruns=10
	testerr[Cnew 0.001433] = 46.770000 < testerr[Ccurrent 0.001540] = 46.920000
	NEW BEST: Cbest <= 0.001433, testerr[Cbest] = 46.770000
	PROCEED: Cstepfactor remains 0.930572, Ccurrent is now 0.001433, Cnew is now 0.001334
	testerr[Cnew 0.001334] = 46.940000 > testerr[Ccurrent 0.001433] = 46.770000
	REVERSE: Cstepfactor is now 1.036633, Ccurrent remains 0.001433, Cnew is now 0.001486
		Training SVM with C=0.001486, nbinputs=1000, numruns=10
	testerr[Cnew 0.001486] = 46.750000 < testerr[Ccurrent 0.001433] = 46.770000
	NEW BEST: Cbest <= 0.001486, testerr[Cbest] = 46.750000
	PROCEED: Cstepfactor remains 1.036633, Ccurrent is now 0.001486, Cnew is now 0.001540
	testerr[Cnew 0.001540] = 46.920000 > testerr[Ccurrent 0.001486] = 46.750000
	REVERSE: Cstepfactor is now 0.982172, Ccurrent remains 0.001486, Cnew is now 0.001459
		Training SVM with C=0.001459, nbinputs=1000, numruns=10
	testerr[Cnew 0.001459] = 46.850000 > testerr[Ccurrent 0.001486] = 46.750000
	REVERSE: Cstepfactor is now 1.009035, Ccurrent remains 0.001486, Cnew is now 0.001499
		Training SVM with C=0.001499, nbinputs=1000, numruns=10
	testerr[Cnew 0.001499] = 46.910000 > testerr[Ccurrent 0.001486] = 46.750000
	REVERSE: Cstepfactor is now 0.995513, Ccurrent remains 0.001486, Cnew is now 0.001479
		Training SVM with C=0.001479, nbinputs=1000, numruns=10
	testerr[Cnew 0.001479] = 46.850000 > testerr[Ccurrent 0.001486] = 46.750000
	REVERSE: Cstepfactor is now 1.002251, Ccurrent remains 0.001486, Cnew is now 0.001489
		Training SVM with C=0.001489, nbinputs=1000, numruns=10
	testerr[Cnew 0.001489] = 46.900000 > testerr[Ccurrent 0.001486] = 46.750000
	REVERSE: Cstepfactor is now 0.998876, Ccurrent remains 0.001486, Cnew is now 0.001484
		Training SVM with C=0.001484, nbinputs=1000, numruns=10
	testerr[Cnew 0.001484] = 46.990000 > testerr[Ccurrent 0.001486] = 46.750000
	REVERSE: Cstepfactor is now 1.000562, Ccurrent remains 0.001486, Cnew is now 0.001486
		Training SVM with C=0.001486, nbinputs=1000, numruns=10
	testerr[Cnew 0.001486] = 46.880000 > testerr[Ccurrent 0.001486] = 46.750000
	REVERSE: Cstepfactor is now 0.999719, Ccurrent remains 0.001486, Cnew is now 0.001485
		Training SVM with C=0.001485, nbinputs=1000, numruns=10
	testerr[Cnew 0.001485] = 46.760000 > testerr[Ccurrent 0.001486] = 46.750000
	REVERSE: Cstepfactor is now 1.000141, Ccurrent remains 0.001486, Cnew is now 0.001486
	testerr[C 0.000316] = 49.880000 
	testerr[C 0.000750] = 47.510000 
	testerr[C 0.001000] = 47.280000 
	testerr[C 0.001155] = 47.080000 
	testerr[C 0.001334] = 46.940000 
	testerr[C 0.001433] = 46.770000 
	testerr[C 0.001459] = 46.850000 
	testerr[C 0.001479] = 46.850000 
	testerr[C 0.001484] = 46.990000 
	testerr[C 0.001485] = 46.760000 
	testerr[C 0.001486] = 46.750000  *best* (testerr = 46.750000, testerrdev = 0.276586, trainerr = 30.820000, trainerrdev = 0.153623)
	testerr[C 0.001486] = 46.880000 
	testerr[C 0.001489] = 46.900000 
	testerr[C 0.001499] = 46.910000 
	testerr[C 0.001540] = 46.920000 
	testerr[C 0.001778] = 47.300000 
	testerr[C 0.001778] = 47.300000 
	testerr[C 0.003162] = 47.420000 
	testerr[C 0.010000] = 48.890000 
	testerr[C 0.100000] = 56.140000 
...done with SVM validation for 1000 examples (numrums=10, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm)...
ceylon.iro.umontreal.ca 2010-08-11 14:07:42.268646: 0:28:52.740000 user+sys, 0:39:04.910000 real, 73.89% usage, 583.55 MB
Starting SVM validation for 10000 examples (numrums=1, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm, PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211, MAXSTEPS=20, STEPFACTOR=10.000000, INITIALC=0.010000)...
ceylon.iro.umontreal.ca 2010-08-11 14:07:42.269019: 0:28:52.740000 user+sys, 0:39:04.910000 real, 73.89% usage, 583.55 MB
		Training SVM with C=0.010000, nbinputs=10000, numruns=1
		Training SVM with C=0.100000, nbinputs=10000, numruns=1
	testerr[Cnew 0.100000] = 55.900000 > testerr[Ccurrent 0.010000] = 48.900000
	Cbest <= 0.010000, testerr[Cbest] = 48.900000
	REVERSE: Cstepfactor is now 0.316228, Ccurrent remains 0.010000, Cnew is now 0.003162
		Training SVM with C=0.003162, nbinputs=10000, numruns=1
	testerr[Cnew 0.003162] = 47.200000 < testerr[Ccurrent 0.010000] = 48.900000
	NEW BEST: Cbest <= 0.003162, testerr[Cbest] = 47.200000
	PROCEED: Cstepfactor remains 0.316228, Ccurrent is now 0.003162, Cnew is now 0.001000
		Training SVM with C=0.001000, nbinputs=10000, numruns=1
	testerr[Cnew 0.001000] = 46.900000 < testerr[Ccurrent 0.003162] = 47.200000
	NEW BEST: Cbest <= 0.001000, testerr[Cbest] = 46.900000
	PROCEED: Cstepfactor remains 0.316228, Ccurrent is now 0.001000, Cnew is now 0.000316
		Training SVM with C=0.000316, nbinputs=10000, numruns=1
	testerr[Cnew 0.000316] = 50.400000 > testerr[Ccurrent 0.001000] = 46.900000
	REVERSE: Cstepfactor is now 1.778279, Ccurrent remains 0.001000, Cnew is now 0.001778
		Training SVM with C=0.001778, nbinputs=10000, numruns=1
	testerr[Cnew 0.001778] = 47.100000 > testerr[Ccurrent 0.001000] = 46.900000
	REVERSE: Cstepfactor is now 0.749894, Ccurrent remains 0.001000, Cnew is now 0.000750
		Training SVM with C=0.000750, nbinputs=10000, numruns=1
	testerr[Cnew 0.000750] = 47.400000 > testerr[Ccurrent 0.001000] = 46.900000
	REVERSE: Cstepfactor is now 1.154782, Ccurrent remains 0.001000, Cnew is now 0.001155
		Training SVM with C=0.001155, nbinputs=10000, numruns=1
	testerr[Cnew 0.001155] = 47.000000 > testerr[Ccurrent 0.001000] = 46.900000
	REVERSE: Cstepfactor is now 0.930572, Ccurrent remains 0.001000, Cnew is now 0.000931
		Training SVM with C=0.000931, nbinputs=10000, numruns=1
	testerr[Cnew 0.000931] = 47.200000 > testerr[Ccurrent 0.001000] = 46.900000
	REVERSE: Cstepfactor is now 1.036633, Ccurrent remains 0.001000, Cnew is now 0.001037
		Training SVM with C=0.001037, nbinputs=10000, numruns=1
	testerr[Cnew 0.001037] = 47.200000 > testerr[Ccurrent 0.001000] = 46.900000
	REVERSE: Cstepfactor is now 0.982172, Ccurrent remains 0.001000, Cnew is now 0.000982
		Training SVM with C=0.000982, nbinputs=10000, numruns=1
	testerr[Cnew 0.000982] = 47.100000 > testerr[Ccurrent 0.001000] = 46.900000
	REVERSE: Cstepfactor is now 1.009035, Ccurrent remains 0.001000, Cnew is now 0.001009
		Training SVM with C=0.001009, nbinputs=10000, numruns=1
	testerr[Cnew 0.001009] = 47.500000 > testerr[Ccurrent 0.001000] = 46.900000
	REVERSE: Cstepfactor is now 0.995513, Ccurrent remains 0.001000, Cnew is now 0.000996
		Training SVM with C=0.000996, nbinputs=10000, numruns=1
	testerr[Cnew 0.000996] = 47.400000 > testerr[Ccurrent 0.001000] = 46.900000
	REVERSE: Cstepfactor is now 1.002251, Ccurrent remains 0.001000, Cnew is now 0.001002
		Training SVM with C=0.001002, nbinputs=10000, numruns=1
	testerr[Cnew 0.001002] = 46.700000 < testerr[Ccurrent 0.001000] = 46.900000
	NEW BEST: Cbest <= 0.001002, testerr[Cbest] = 46.700000
	PROCEED: Cstepfactor remains 1.002251, Ccurrent is now 0.001002, Cnew is now 0.001005
		Training SVM with C=0.001005, nbinputs=10000, numruns=1
	testerr[Cnew 0.001005] = 47.000000 > testerr[Ccurrent 0.001002] = 46.700000
	REVERSE: Cstepfactor is now 0.998876, Ccurrent remains 0.001002, Cnew is now 0.001001
		Training SVM with C=0.001001, nbinputs=10000, numruns=1
	testerr[Cnew 0.001001] = 47.000000 > testerr[Ccurrent 0.001002] = 46.700000
	REVERSE: Cstepfactor is now 1.000562, Ccurrent remains 0.001002, Cnew is now 0.001003
		Training SVM with C=0.001003, nbinputs=10000, numruns=1
	testerr[Cnew 0.001003] = 47.400000 > testerr[Ccurrent 0.001002] = 46.700000
	REVERSE: Cstepfactor is now 0.999719, Ccurrent remains 0.001002, Cnew is now 0.001002
		Training SVM with C=0.001002, nbinputs=10000, numruns=1
	testerr[Cnew 0.001002] = 46.700000 > testerr[Ccurrent 0.001002] = 46.700000
	REVERSE: Cstepfactor is now 1.000141, Ccurrent remains 0.001002, Cnew is now 0.001002
		Training SVM with C=0.001002, nbinputs=10000, numruns=1
	testerr[Cnew 0.001002] = 46.700000 > testerr[Ccurrent 0.001002] = 46.700000
	REVERSE: Cstepfactor is now 0.999930, Ccurrent remains 0.001002, Cnew is now 0.001002
		Training SVM with C=0.001002, nbinputs=10000, numruns=1
	testerr[Cnew 0.001002] = 46.700000 > testerr[Ccurrent 0.001002] = 46.700000
	REVERSE: Cstepfactor is now 1.000035, Ccurrent remains 0.001002, Cnew is now 0.001002
	testerr[C 0.000316] = 50.400000 
	testerr[C 0.000750] = 47.400000 
	testerr[C 0.000931] = 47.200000 
	testerr[C 0.000982] = 47.100000 
	testerr[C 0.000996] = 47.400000 
	testerr[C 0.001000] = 46.900000 
	testerr[C 0.001001] = 47.000000 
	testerr[C 0.001002] = 46.700000 
	testerr[C 0.001002] = 46.700000 
	testerr[C 0.001002] = 46.700000  *best* (testerr = 46.700000, testerrdev = 0.000000, trainerr = 33.400000, trainerrdev = 0.000000)
	testerr[C 0.001002] = 46.700000 
	testerr[C 0.001003] = 47.400000 
	testerr[C 0.001005] = 47.000000 
	testerr[C 0.001009] = 47.500000 
	testerr[C 0.001037] = 47.200000 
	testerr[C 0.001155] = 47.000000 
	testerr[C 0.001778] = 47.100000 
	testerr[C 0.003162] = 47.200000 
	testerr[C 0.010000] = 48.900000 
	testerr[C 0.100000] = 55.900000 
...done with SVM validation for 10000 examples (numrums=1, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm)...
ceylon.iro.umontreal.ca 2010-08-11 14:08:02.950735: 0:28:52.820000 user+sys, 0:39:25.590000 real, 73.25% usage, 583.55 MB
		----  Encoding  layer #1 ----
			**** DenseLayer.__init__ ****
			tag =  enc1
			inp =  inp
			n_inp =  5000
			n_out =  1000
			act =  tanh
			noise =  binomial_NLP
			out =  outenc1
			params (gradients) =  [Wenc1, benc1]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc1
			allocW, allocb, allocmask =  False False False
		----  Encoding  layer #2 ----
			**** DenseLayer.__init__ ****
			tag =  enc2
			inp =  outenc1
			n_inp =  1000
			n_out =  1000
			act =  tanh
			noise =  binomial
			out =  outenc2
			params (gradients) =  [Wenc2, benc2]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc2
			allocW, allocb, allocmask =  False False False
MRG_RandomStreams Can't determine #streams from size (Shape.0), guessing 30*256
	---- Auxiliary Layer ----
			**** DenseLayer.__init__ ****
			tag =  aux-1
			inp =  outenc2
			n_inp =  1000
			n_out =  1000
			act =  sigmoid
			noise =  None
			out =  outaux-1
			params (gradients) =  [Waux-1, baux-1]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  None
			allocW, allocb, allocmask =  False False ones
	**** SDAE ****
	depth =  3
	mode =  Aux
	depth_min, depth_max, update_type =  0 , 2 , special
	inp, n_inp =  inp , 5000
	n_hid =  [1000, 1000, 1000]
	layertype =  [<class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>]
	act =  ['tanh', 'tanh', 'rectifier']
	noise, noise_lvl =  ['binomial_NLP', 'binomial', 'binomial'] , 0.5
	tie =  [True, True, True]
	maskbool =  [None, None, None]
	n_out, outtype =  5 , <class 'deepANN.Logistic_regression.LogisticRegression'>
	lr =  0.001
	sup_scaling, unsup_scaling, aux_scaling  =  None None 1.0
	regularization, wdreg  =  [0.0, 0.0, 0.0, 0.0] , l2
	sparsity, spreg =  [0.0, 0.0, 0.01] , l1
	params, wd, sp =  [Wenc2, benc2, Waux-1, baux-1] , [] , []
	bbbool, hessscal =  None , None
	aux, auxtarget, aux_one_sided, auxdepth, auxregularization =  True , auxtarget , True , -1 , False
	auxact, auxn_out, auxwdreg =  sigmoid , 1000 , l2
##########  TEST ############ EPOCH :  1
CURRENT RECONSTRUCTION ERROR (is this on test or train?):  600.969958984
CURRENT 100 SVM ERROR:  (0.10000000000000001, 55.914999999999999, 2.85242, 0.0, 0.0)
CURRENT 1000 SVM ERROR:  (0.0014855080171727755, 46.75, 0.276586, 30.82, 0.15362300000000001)
CURRENT 10000 SVM ERROR:  (0.0010022511482929129, 46.700000000000003, 0.0, 33.399999999999999, 0.0)
ceylon.iro.umontreal.ca 2010-08-11 14:08:09.530545: 0:28:59.300000 user+sys, 0:39:32.170000 real, 73.32% usage, 583.55 MB
params.pkl saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth2pre1
Wenc1 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth2pre1/Layer1_W.pkl
benc1 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth2pre1/Layer1_b.pkl
maskenc1 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth2pre1/Layer1_mask.pkl
Wenc2 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth2pre1/Layer2_W.pkl
benc2 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth2pre1/Layer2_b.pkl
maskenc2 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth2pre1/Layer2_mask.pkl
Wenc3 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth2pre1/Layer3_W.pkl
benc3 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth2pre1/Layer3_b.pkl
maskenc3 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth2pre1/Layer3_mask.pkl
Waux-1 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth2pre1/Layeraux_W.pkl
baux-1 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth2pre1/Layeraux_b.pkl
maskaux-1 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth2pre1/Layeraux_mask.pkl
W saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth2pre1/Layerout_W.pkl
b saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth2pre1/Layerout_b.pkl
saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth2pre1
...done validating (err={1000: {0: (0.0052329911468149467, 47.100000000000001, 0.21908900000000001, 26.260000000000002, 0.233238), 1: (0.0014855080171727755, 46.75, 0.276586, 30.82, 0.15362300000000001)}, 10000: {0: (0.0052329911468149467, 46.899999999999999, 0.0, 26.100000000000001, 0.0), 1: (0.0010022511482929129, 46.700000000000003, 0.0, 33.399999999999999, 0.0)}, 100: {0: (1.0, 57.0, 3.1551499999999999, 0.0, 0.0), 1: (0.10000000000000001, 55.914999999999999, 2.85242, 0.0, 0.0)}},epoch=1,model=<deepANN.ANN.SDAE object at 0x30fcb50>,depth=1,ACT=['tanh', 'tanh', 'rectifier'],LR=0.001,NOISE_LVL=0.5,BATCHSIZE=10,train=<CudaNdarrayType(float32, matrix)>,datatrain=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_labels_1.pkl'),datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm,datatest=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_labels_1.pkl'),datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm,VALIDATION_TRAININGSIZE=[100, 1000, 10000],VALIDATION_RUNS_FOR_EACH_TRAININGSIZE={'100': 20, '10000': 1, '1000': 10},PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211)
ceylon.iro.umontreal.ca 2010-08-11 14:08:10.091100: 0:28:59.370000 user+sys, 0:39:32.730000 real, 73.31% usage, 583.55 MB
File: 1 16.6826908588 ----
ceylon.iro.umontreal.ca 2010-08-11 14:08:26.774179: 0:29:16.030000 user+sys, 0:39:49.410000 real, 73.49% usage, 583.55 MB
File: 2 16.6767618656 ----
ceylon.iro.umontreal.ca 2010-08-11 14:08:43.451740: 0:29:32.700000 user+sys, 0:40:06.080000 real, 73.68% usage, 583.55 MB
File: 3 16.7147679329 ----
ceylon.iro.umontreal.ca 2010-08-11 14:09:00.167307: 0:29:49.410000 user+sys, 0:40:22.800000 real, 73.86% usage, 583.55 MB
File: 4 16.5611081123 ----
ceylon.iro.umontreal.ca 2010-08-11 14:09:16.729876: 0:30:05.960000 user+sys, 0:40:39.360000 real, 74.03% usage, 583.55 MB
File: 5 16.5541639328 ----
ceylon.iro.umontreal.ca 2010-08-11 14:09:33.284830: 0:30:22.510000 user+sys, 0:40:55.910000 real, 74.21% usage, 583.55 MB
File: 6 16.5498130322 ----
ceylon.iro.umontreal.ca 2010-08-11 14:09:49.835447: 0:30:39.050000 user+sys, 0:41:12.460000 real, 74.38% usage, 583.55 MB
File: 7 16.5371069908 ----
ceylon.iro.umontreal.ca 2010-08-11 14:10:06.373323: 0:30:55.570000 user+sys, 0:41:28.990000 real, 74.55% usage, 583.55 MB
File: 8 16.5498981476 ----
ceylon.iro.umontreal.ca 2010-08-11 14:10:22.923998: 0:31:12.120000 user+sys, 0:41:45.540000 real, 74.72% usage, 583.55 MB
File: 9 16.5606958866 ----
ceylon.iro.umontreal.ca 2010-08-11 14:10:39.485477: 0:31:28.670000 user+sys, 0:42:02.100000 real, 74.88% usage, 583.55 MB
File: 10 16.5851960182 ----
ceylon.iro.umontreal.ca 2010-08-11 14:10:56.071426: 0:31:45.240000 user+sys, 0:42:18.680000 real, 75.05% usage, 583.55 MB
File: 11 16.7471911907 ----
ceylon.iro.umontreal.ca 2010-08-11 14:11:12.819405: 0:32:01.910000 user+sys, 0:42:35.430000 real, 75.21% usage, 583.55 MB
File: 12 16.6887218952 ----
ceylon.iro.umontreal.ca 2010-08-11 14:11:29.508895: 0:32:18.590000 user+sys, 0:42:52.120000 real, 75.37% usage, 583.55 MB
File: 13 16.8684139252 ----
ceylon.iro.umontreal.ca 2010-08-11 14:11:46.378104: 0:32:35.450000 user+sys, 0:43:08.980000 real, 75.53% usage, 583.55 MB
File: 14 16.8247048855 ----
ceylon.iro.umontreal.ca 2010-08-11 14:12:03.203622: 0:32:52.270000 user+sys, 0:43:25.810000 real, 75.69% usage, 583.55 MB
File: 15 16.1209139824 ----
ceylon.iro.umontreal.ca 2010-08-11 14:12:19.325317: 0:33:08.380000 user+sys, 0:43:41.920000 real, 75.84% usage, 583.55 MB
...finished training epoch #2 of 3 (66.67%)
ceylon.iro.umontreal.ca 2010-08-11 14:12:19.325969: 0:33:08.380000 user+sys, 0:43:41.930000 real, 75.84% usage, 583.55 MB
Validating (err={1000: {0: (0.0052329911468149467, 47.100000000000001, 0.21908900000000001, 26.260000000000002, 0.233238), 1: (0.0014855080171727755, 46.75, 0.276586, 30.82, 0.15362300000000001)}, 10000: {0: (0.0052329911468149467, 46.899999999999999, 0.0, 26.100000000000001, 0.0), 1: (0.0010022511482929129, 46.700000000000003, 0.0, 33.399999999999999, 0.0)}, 100: {0: (1.0, 57.0, 3.1551499999999999, 0.0, 0.0), 1: (0.10000000000000001, 55.914999999999999, 2.85242, 0.0, 0.0)}},epoch=2,model=<deepANN.ANN.SDAE object at 0x30fcb50>,depth=1,ACT=['tanh', 'tanh', 'rectifier'],LR=0.001,NOISE_LVL=0.5,BATCHSIZE=10,train=<CudaNdarrayType(float32, matrix)>,datatrain=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_labels_1.pkl'),datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm,datatest=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_labels_1.pkl'),datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm,VALIDATION_TRAININGSIZE=[100, 1000, 10000],VALIDATION_RUNS_FOR_EACH_TRAININGSIZE={'100': 20, '10000': 1, '1000': 10},PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211)...
ceylon.iro.umontreal.ca 2010-08-11 14:12:19.326415: 0:33:08.380000 user+sys, 0:43:41.930000 real, 75.84% usage, 583.55 MB
		----  Encoding  layer #1 ----
			**** DenseLayer.__init__ ****
			tag =  enc1
			inp =  inp
			n_inp =  5000
			n_out =  1000
			act =  tanh
			noise =  binomial_NLP
			out =  outenc1
			params (gradients) =  [Wenc1, benc1]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc1
			allocW, allocb, allocmask =  False False False
		----  Encoding  layer #2 ----
			**** DenseLayer.__init__ ****
			tag =  enc2
			inp =  outenc1
			n_inp =  1000
			n_out =  1000
			act =  tanh
			noise =  binomial
			out =  outenc2
			params (gradients) =  [Wenc2, benc2]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc2
			allocW, allocb, allocmask =  False False False
	---- Auxiliary Layer ----
			**** DenseLayer.__init__ ****
			tag =  aux-1
			inp =  outenc2
			n_inp =  1000
			n_out =  1000
			act =  sigmoid
			noise =  None
			out =  outaux-1
			params (gradients) =  [Waux-1, baux-1]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  None
			allocW, allocb, allocmask =  False False ones
	**** SDAE ****
	depth =  3
	mode =  Aux
	depth_min, depth_max, update_type =  0 , 2 , special
	inp, n_inp =  inp , 5000
	n_hid =  [1000, 1000, 1000]
	layertype =  [<class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>]
	act =  ['tanh', 'tanh', 'rectifier']
	noise, noise_lvl =  ['binomial_NLP', 'binomial', 'binomial'] , None
	tie =  [True, True, True]
	maskbool =  [None, None, None]
	n_out, outtype =  5 , <class 'deepANN.Logistic_regression.LogisticRegression'>
	lr =  0.001
	sup_scaling, unsup_scaling, aux_scaling  =  None None 1.0
	regularization, wdreg  =  [0.0, 0.0, 0.0, 0.0] , l2
	sparsity, spreg =  [0.0, 0.0, 0.01] , l1
	params, wd, sp =  [Wenc2, benc2, Waux-1, baux-1] , [] , []
	bbbool, hessscal =  None , None
	aux, auxtarget, aux_one_sided, auxdepth, auxregularization =  True , auxtarget , True , -1 , False
	auxact, auxn_out, auxwdreg =  sigmoid , 1000 , l2
Creating libsvm file '/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm' (model=<deepANN.ANN.SDAE object at 0x30fcb50>, depth=1, datafiles=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_labels_1.pkl'))...
ceylon.iro.umontreal.ca 2010-08-11 14:12:21.844298: 0:33:10.810000 user+sys, 0:43:44.440000 real, 75.86% usage, 583.55 MB
...done creating libsvm files
ceylon.iro.umontreal.ca 2010-08-11 14:12:32.053122: 0:33:20.850000 user+sys, 0:43:54.650000 real, 75.94% usage, 583.55 MB
Creating libsvm file '/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm' (model=<deepANN.ANN.SDAE object at 0x30fcb50>, depth=1, datafiles=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_labels_1.pkl'))...
ceylon.iro.umontreal.ca 2010-08-11 14:12:32.053622: 0:33:20.850000 user+sys, 0:43:54.650000 real, 75.94% usage, 583.55 MB
...done creating libsvm files
ceylon.iro.umontreal.ca 2010-08-11 14:12:42.194301: 0:33:30.820000 user+sys, 0:44:04.790000 real, 76.03% usage, 583.55 MB
Starting SVM validation for 100 examples (numrums=20, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm, PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211, MAXSTEPS=20, STEPFACTOR=10.000000, INITIALC=0.010000)...
ceylon.iro.umontreal.ca 2010-08-11 14:12:42.194798: 0:33:30.820000 user+sys, 0:44:04.790000 real, 76.03% usage, 583.55 MB
		Training SVM with C=0.010000, nbinputs=100, numruns=20
		Training SVM with C=0.100000, nbinputs=100, numruns=20
	testerr[Cnew 0.100000] = 57.740000 > testerr[Ccurrent 0.010000] = 55.340000
	Cbest <= 0.010000, testerr[Cbest] = 55.340000
	REVERSE: Cstepfactor is now 0.316228, Ccurrent remains 0.010000, Cnew is now 0.003162
		Training SVM with C=0.003162, nbinputs=100, numruns=20
	testerr[Cnew 0.003162] = 54.520000 < testerr[Ccurrent 0.010000] = 55.340000
	NEW BEST: Cbest <= 0.003162, testerr[Cbest] = 54.520000
	PROCEED: Cstepfactor remains 0.316228, Ccurrent is now 0.003162, Cnew is now 0.001000
		Training SVM with C=0.001000, nbinputs=100, numruns=20
	testerr[Cnew 0.001000] = 55.765000 > testerr[Ccurrent 0.003162] = 54.520000
	REVERSE: Cstepfactor is now 1.778279, Ccurrent remains 0.003162, Cnew is now 0.005623
		Training SVM with C=0.005623, nbinputs=100, numruns=20
	testerr[Cnew 0.005623] = 55.540000 > testerr[Ccurrent 0.003162] = 54.520000
	REVERSE: Cstepfactor is now 0.749894, Ccurrent remains 0.003162, Cnew is now 0.002371
		Training SVM with C=0.002371, nbinputs=100, numruns=20
	testerr[Cnew 0.002371] = 54.670000 > testerr[Ccurrent 0.003162] = 54.520000
	REVERSE: Cstepfactor is now 1.154782, Ccurrent remains 0.003162, Cnew is now 0.003652
		Training SVM with C=0.003652, nbinputs=100, numruns=20
	testerr[Cnew 0.003652] = 54.970000 > testerr[Ccurrent 0.003162] = 54.520000
	REVERSE: Cstepfactor is now 0.930572, Ccurrent remains 0.003162, Cnew is now 0.002943
		Training SVM with C=0.002943, nbinputs=100, numruns=20
	testerr[Cnew 0.002943] = 55.905000 > testerr[Ccurrent 0.003162] = 54.520000
	REVERSE: Cstepfactor is now 1.036633, Ccurrent remains 0.003162, Cnew is now 0.003278
		Training SVM with C=0.003278, nbinputs=100, numruns=20
	testerr[Cnew 0.003278] = 54.665000 > testerr[Ccurrent 0.003162] = 54.520000
	REVERSE: Cstepfactor is now 0.982172, Ccurrent remains 0.003162, Cnew is now 0.003106
		Training SVM with C=0.003106, nbinputs=100, numruns=20
	testerr[Cnew 0.003106] = 54.555000 > testerr[Ccurrent 0.003162] = 54.520000
	REVERSE: Cstepfactor is now 1.009035, Ccurrent remains 0.003162, Cnew is now 0.003191
		Training SVM with C=0.003191, nbinputs=100, numruns=20
	testerr[Cnew 0.003191] = 54.785000 > testerr[Ccurrent 0.003162] = 54.520000
	REVERSE: Cstepfactor is now 0.995513, Ccurrent remains 0.003162, Cnew is now 0.003148
		Training SVM with C=0.003148, nbinputs=100, numruns=20
	testerr[Cnew 0.003148] = 56.175000 > testerr[Ccurrent 0.003162] = 54.520000
	REVERSE: Cstepfactor is now 1.002251, Ccurrent remains 0.003162, Cnew is now 0.003169
		Training SVM with C=0.003169, nbinputs=100, numruns=20
	testerr[Cnew 0.003169] = 54.370000 < testerr[Ccurrent 0.003162] = 54.520000
	NEW BEST: Cbest <= 0.003169, testerr[Cbest] = 54.370000
	PROCEED: Cstepfactor remains 1.002251, Ccurrent is now 0.003169, Cnew is now 0.003177
		Training SVM with C=0.003177, nbinputs=100, numruns=20
	testerr[Cnew 0.003177] = 55.315000 > testerr[Ccurrent 0.003169] = 54.370000
	REVERSE: Cstepfactor is now 0.998876, Ccurrent remains 0.003169, Cnew is now 0.003166
		Training SVM with C=0.003166, nbinputs=100, numruns=20
	testerr[Cnew 0.003166] = 54.980000 > testerr[Ccurrent 0.003169] = 54.370000
	REVERSE: Cstepfactor is now 1.000562, Ccurrent remains 0.003169, Cnew is now 0.003171
		Training SVM with C=0.003171, nbinputs=100, numruns=20
	testerr[Cnew 0.003171] = 54.620000 > testerr[Ccurrent 0.003169] = 54.370000
	REVERSE: Cstepfactor is now 0.999719, Ccurrent remains 0.003169, Cnew is now 0.003169
		Training SVM with C=0.003169, nbinputs=100, numruns=20
	testerr[Cnew 0.003169] = 56.050000 > testerr[Ccurrent 0.003169] = 54.370000
	REVERSE: Cstepfactor is now 1.000141, Ccurrent remains 0.003169, Cnew is now 0.003170
		Training SVM with C=0.003170, nbinputs=100, numruns=20
	testerr[Cnew 0.003170] = 54.370000 > testerr[Ccurrent 0.003169] = 54.370000
	REVERSE: Cstepfactor is now 0.999930, Ccurrent remains 0.003169, Cnew is now 0.003169
		Training SVM with C=0.003169, nbinputs=100, numruns=20
	testerr[Cnew 0.003169] = 54.190000 < testerr[Ccurrent 0.003169] = 54.370000
	NEW BEST: Cbest <= 0.003169, testerr[Cbest] = 54.190000
	PROCEED: Cstepfactor remains 0.999930, Ccurrent is now 0.003169, Cnew is now 0.003169
		Training SVM with C=0.003169, nbinputs=100, numruns=20
	testerr[Cnew 0.003169] = 54.190000 > testerr[Ccurrent 0.003169] = 54.190000
	REVERSE: Cstepfactor is now 1.000035, Ccurrent remains 0.003169, Cnew is now 0.003169
	testerr[C 0.001000] = 55.765000 
	testerr[C 0.002371] = 54.670000 
	testerr[C 0.002943] = 55.905000 
	testerr[C 0.003106] = 54.555000 
	testerr[C 0.003148] = 56.175000 
	testerr[C 0.003162] = 54.520000 
	testerr[C 0.003166] = 54.980000 
	testerr[C 0.003169] = 56.050000 
	testerr[C 0.003169] = 54.190000 
	testerr[C 0.003169] = 54.190000  *best* (testerr = 54.190000, testerrdev = 3.106750, trainerr = 8.750000, trainerrdev = 2.094640)
	testerr[C 0.003169] = 54.370000 
	testerr[C 0.003170] = 54.370000 
	testerr[C 0.003171] = 54.620000 
	testerr[C 0.003177] = 55.315000 
	testerr[C 0.003191] = 54.785000 
	testerr[C 0.003278] = 54.665000 
	testerr[C 0.003652] = 54.970000 
	testerr[C 0.005623] = 55.540000 
	testerr[C 0.010000] = 55.340000 
	testerr[C 0.100000] = 57.740000 
...done with SVM validation for 100 examples (numrums=20, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm)...
ceylon.iro.umontreal.ca 2010-08-11 14:13:11.996438: 0:33:30.910000 user+sys, 0:44:34.590000 real, 75.19% usage, 583.55 MB
Starting SVM validation for 1000 examples (numrums=10, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm, PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211, MAXSTEPS=20, STEPFACTOR=10.000000, INITIALC=0.010000)...
ceylon.iro.umontreal.ca 2010-08-11 14:13:11.996814: 0:33:30.910000 user+sys, 0:44:34.590000 real, 75.19% usage, 583.55 MB
		Training SVM with C=0.010000, nbinputs=1000, numruns=10
		Training SVM with C=0.100000, nbinputs=1000, numruns=10
	testerr[Cnew 0.100000] = 55.510000 > testerr[Ccurrent 0.010000] = 49.600000
	Cbest <= 0.010000, testerr[Cbest] = 49.600000
	REVERSE: Cstepfactor is now 0.316228, Ccurrent remains 0.010000, Cnew is now 0.003162
		Training SVM with C=0.003162, nbinputs=1000, numruns=10
	testerr[Cnew 0.003162] = 46.810000 < testerr[Ccurrent 0.010000] = 49.600000
	NEW BEST: Cbest <= 0.003162, testerr[Cbest] = 46.810000
	PROCEED: Cstepfactor remains 0.316228, Ccurrent is now 0.003162, Cnew is now 0.001000
		Training SVM with C=0.001000, nbinputs=1000, numruns=10
	testerr[Cnew 0.001000] = 47.700000 > testerr[Ccurrent 0.003162] = 46.810000
	REVERSE: Cstepfactor is now 1.778279, Ccurrent remains 0.003162, Cnew is now 0.005623
		Training SVM with C=0.005623, nbinputs=1000, numruns=10
	testerr[Cnew 0.005623] = 47.530000 > testerr[Ccurrent 0.003162] = 46.810000
	REVERSE: Cstepfactor is now 0.749894, Ccurrent remains 0.003162, Cnew is now 0.002371
		Training SVM with C=0.002371, nbinputs=1000, numruns=10
	testerr[Cnew 0.002371] = 47.130000 > testerr[Ccurrent 0.003162] = 46.810000
	REVERSE: Cstepfactor is now 1.154782, Ccurrent remains 0.003162, Cnew is now 0.003652
		Training SVM with C=0.003652, nbinputs=1000, numruns=10
	testerr[Cnew 0.003652] = 46.410000 < testerr[Ccurrent 0.003162] = 46.810000
	NEW BEST: Cbest <= 0.003652, testerr[Cbest] = 46.410000
	PROCEED: Cstepfactor remains 1.154782, Ccurrent is now 0.003652, Cnew is now 0.004217
		Training SVM with C=0.004217, nbinputs=1000, numruns=10
	testerr[Cnew 0.004217] = 46.680000 > testerr[Ccurrent 0.003652] = 46.410000
	REVERSE: Cstepfactor is now 0.930572, Ccurrent remains 0.003652, Cnew is now 0.003398
		Training SVM with C=0.003398, nbinputs=1000, numruns=10
	testerr[Cnew 0.003398] = 46.740000 > testerr[Ccurrent 0.003652] = 46.410000
	REVERSE: Cstepfactor is now 1.036633, Ccurrent remains 0.003652, Cnew is now 0.003786
		Training SVM with C=0.003786, nbinputs=1000, numruns=10
	testerr[Cnew 0.003786] = 46.380000 < testerr[Ccurrent 0.003652] = 46.410000
	NEW BEST: Cbest <= 0.003786, testerr[Cbest] = 46.380000
	PROCEED: Cstepfactor remains 1.036633, Ccurrent is now 0.003786, Cnew is now 0.003924
		Training SVM with C=0.003924, nbinputs=1000, numruns=10
	testerr[Cnew 0.003924] = 46.460000 > testerr[Ccurrent 0.003786] = 46.380000
	REVERSE: Cstepfactor is now 0.982172, Ccurrent remains 0.003786, Cnew is now 0.003718
		Training SVM with C=0.003718, nbinputs=1000, numruns=10
	testerr[Cnew 0.003718] = 46.300000 < testerr[Ccurrent 0.003786] = 46.380000
	NEW BEST: Cbest <= 0.003718, testerr[Cbest] = 46.300000
	PROCEED: Cstepfactor remains 0.982172, Ccurrent is now 0.003718, Cnew is now 0.003652
	testerr[Cnew 0.003652] = 46.410000 > testerr[Ccurrent 0.003718] = 46.300000
	REVERSE: Cstepfactor is now 1.009035, Ccurrent remains 0.003718, Cnew is now 0.003752
		Training SVM with C=0.003752, nbinputs=1000, numruns=10
	testerr[Cnew 0.003752] = 46.290000 < testerr[Ccurrent 0.003718] = 46.300000
	NEW BEST: Cbest <= 0.003752, testerr[Cbest] = 46.290000
	PROCEED: Cstepfactor remains 1.009035, Ccurrent is now 0.003752, Cnew is now 0.003786
		Training SVM with C=0.003786, nbinputs=1000, numruns=10
	testerr[Cnew 0.003786] = 46.380000 > testerr[Ccurrent 0.003752] = 46.290000
	REVERSE: Cstepfactor is now 0.995513, Ccurrent remains 0.003752, Cnew is now 0.003735
		Training SVM with C=0.003735, nbinputs=1000, numruns=10
	testerr[Cnew 0.003735] = 46.380000 > testerr[Ccurrent 0.003752] = 46.290000
	REVERSE: Cstepfactor is now 1.002251, Ccurrent remains 0.003752, Cnew is now 0.003760
		Training SVM with C=0.003760, nbinputs=1000, numruns=10
	testerr[Cnew 0.003760] = 46.330000 > testerr[Ccurrent 0.003752] = 46.290000
	REVERSE: Cstepfactor is now 0.998876, Ccurrent remains 0.003752, Cnew is now 0.003747
		Training SVM with C=0.003747, nbinputs=1000, numruns=10
	testerr[Cnew 0.003747] = 46.430000 > testerr[Ccurrent 0.003752] = 46.290000
	REVERSE: Cstepfactor is now 1.000562, Ccurrent remains 0.003752, Cnew is now 0.003754
		Training SVM with C=0.003754, nbinputs=1000, numruns=10
	testerr[Cnew 0.003754] = 46.380000 > testerr[Ccurrent 0.003752] = 46.290000
	REVERSE: Cstepfactor is now 0.999719, Ccurrent remains 0.003752, Cnew is now 0.003751
		Training SVM with C=0.003751, nbinputs=1000, numruns=10
	testerr[Cnew 0.003751] = 46.350000 > testerr[Ccurrent 0.003752] = 46.290000
	REVERSE: Cstepfactor is now 1.000141, Ccurrent remains 0.003752, Cnew is now 0.003752
		Training SVM with C=0.003752, nbinputs=1000, numruns=10
	testerr[Cnew 0.003752] = 46.330000 > testerr[Ccurrent 0.003752] = 46.290000
	REVERSE: Cstepfactor is now 0.999930, Ccurrent remains 0.003752, Cnew is now 0.003751
	testerr[C 0.001000] = 47.700000 
	testerr[C 0.002371] = 47.130000 
	testerr[C 0.003162] = 46.810000 
	testerr[C 0.003398] = 46.740000 
	testerr[C 0.003652] = 46.410000 
	testerr[C 0.003718] = 46.300000 
	testerr[C 0.003735] = 46.380000 
	testerr[C 0.003747] = 46.430000 
	testerr[C 0.003751] = 46.350000 
	testerr[C 0.003752] = 46.290000  *best* (testerr = 46.290000, testerrdev = 0.186815, trainerr = 24.640000, trainerrdev = 0.190788)
	testerr[C 0.003752] = 46.330000 
	testerr[C 0.003754] = 46.380000 
	testerr[C 0.003760] = 46.330000 
	testerr[C 0.003786] = 46.380000 
	testerr[C 0.003786] = 46.380000 
	testerr[C 0.003924] = 46.460000 
	testerr[C 0.004217] = 46.680000 
	testerr[C 0.005623] = 47.530000 
	testerr[C 0.010000] = 49.600000 
	testerr[C 0.100000] = 55.510000 
...done with SVM validation for 1000 examples (numrums=10, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm)...
ceylon.iro.umontreal.ca 2010-08-11 14:14:58.710422: 0:33:30.990000 user+sys, 0:46:21.290000 real, 72.30% usage, 583.55 MB
Starting SVM validation for 10000 examples (numrums=1, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm, PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211, MAXSTEPS=20, STEPFACTOR=10.000000, INITIALC=0.010000)...
ceylon.iro.umontreal.ca 2010-08-11 14:14:58.710787: 0:33:30.990000 user+sys, 0:46:21.290000 real, 72.30% usage, 583.55 MB
		Training SVM with C=0.010000, nbinputs=10000, numruns=1
		Training SVM with C=0.100000, nbinputs=10000, numruns=1
	testerr[Cnew 0.100000] = 55.700000 > testerr[Ccurrent 0.010000] = 49.700000
	Cbest <= 0.010000, testerr[Cbest] = 49.700000
	REVERSE: Cstepfactor is now 0.316228, Ccurrent remains 0.010000, Cnew is now 0.003162
		Training SVM with C=0.003162, nbinputs=10000, numruns=1
	testerr[Cnew 0.003162] = 46.500000 < testerr[Ccurrent 0.010000] = 49.700000
	NEW BEST: Cbest <= 0.003162, testerr[Cbest] = 46.500000
	PROCEED: Cstepfactor remains 0.316228, Ccurrent is now 0.003162, Cnew is now 0.001000
		Training SVM with C=0.001000, nbinputs=10000, numruns=1
	testerr[Cnew 0.001000] = 47.900000 > testerr[Ccurrent 0.003162] = 46.500000
	REVERSE: Cstepfactor is now 1.778279, Ccurrent remains 0.003162, Cnew is now 0.005623
		Training SVM with C=0.005623, nbinputs=10000, numruns=1
	testerr[Cnew 0.005623] = 47.400000 > testerr[Ccurrent 0.003162] = 46.500000
	REVERSE: Cstepfactor is now 0.749894, Ccurrent remains 0.003162, Cnew is now 0.002371
		Training SVM with C=0.002371, nbinputs=10000, numruns=1
	testerr[Cnew 0.002371] = 47.000000 > testerr[Ccurrent 0.003162] = 46.500000
	REVERSE: Cstepfactor is now 1.154782, Ccurrent remains 0.003162, Cnew is now 0.003652
		Training SVM with C=0.003652, nbinputs=10000, numruns=1
	testerr[Cnew 0.003652] = 46.300000 < testerr[Ccurrent 0.003162] = 46.500000
	NEW BEST: Cbest <= 0.003652, testerr[Cbest] = 46.300000
	PROCEED: Cstepfactor remains 1.154782, Ccurrent is now 0.003652, Cnew is now 0.004217
		Training SVM with C=0.004217, nbinputs=10000, numruns=1
	testerr[Cnew 0.004217] = 47.100000 > testerr[Ccurrent 0.003652] = 46.300000
	REVERSE: Cstepfactor is now 0.930572, Ccurrent remains 0.003652, Cnew is now 0.003398
		Training SVM with C=0.003398, nbinputs=10000, numruns=1
	testerr[Cnew 0.003398] = 46.500000 > testerr[Ccurrent 0.003652] = 46.300000
	REVERSE: Cstepfactor is now 1.036633, Ccurrent remains 0.003652, Cnew is now 0.003786
		Training SVM with C=0.003786, nbinputs=10000, numruns=1
	testerr[Cnew 0.003786] = 46.600000 > testerr[Ccurrent 0.003652] = 46.300000
	REVERSE: Cstepfactor is now 0.982172, Ccurrent remains 0.003652, Cnew is now 0.003587
		Training SVM with C=0.003587, nbinputs=10000, numruns=1
	testerr[Cnew 0.003587] = 46.500000 > testerr[Ccurrent 0.003652] = 46.300000
	REVERSE: Cstepfactor is now 1.009035, Ccurrent remains 0.003652, Cnew is now 0.003685
		Training SVM with C=0.003685, nbinputs=10000, numruns=1
	testerr[Cnew 0.003685] = 46.500000 > testerr[Ccurrent 0.003652] = 46.300000
	REVERSE: Cstepfactor is now 0.995513, Ccurrent remains 0.003652, Cnew is now 0.003635
		Training SVM with C=0.003635, nbinputs=10000, numruns=1
	testerr[Cnew 0.003635] = 46.400000 > testerr[Ccurrent 0.003652] = 46.300000
	REVERSE: Cstepfactor is now 1.002251, Ccurrent remains 0.003652, Cnew is now 0.003660
		Training SVM with C=0.003660, nbinputs=10000, numruns=1
	testerr[Cnew 0.003660] = 46.600000 > testerr[Ccurrent 0.003652] = 46.300000
	REVERSE: Cstepfactor is now 0.998876, Ccurrent remains 0.003652, Cnew is now 0.003648
		Training SVM with C=0.003648, nbinputs=10000, numruns=1
	testerr[Cnew 0.003648] = 46.500000 > testerr[Ccurrent 0.003652] = 46.300000
	REVERSE: Cstepfactor is now 1.000562, Ccurrent remains 0.003652, Cnew is now 0.003654
		Training SVM with C=0.003654, nbinputs=10000, numruns=1
	testerr[Cnew 0.003654] = 46.300000 > testerr[Ccurrent 0.003652] = 46.300000
	REVERSE: Cstepfactor is now 0.999719, Ccurrent remains 0.003652, Cnew is now 0.003651
		Training SVM with C=0.003651, nbinputs=10000, numruns=1
	testerr[Cnew 0.003651] = 46.600000 > testerr[Ccurrent 0.003652] = 46.300000
	REVERSE: Cstepfactor is now 1.000141, Ccurrent remains 0.003652, Cnew is now 0.003652
		Training SVM with C=0.003652, nbinputs=10000, numruns=1
	testerr[Cnew 0.003652] = 46.300000 > testerr[Ccurrent 0.003652] = 46.300000
	REVERSE: Cstepfactor is now 0.999930, Ccurrent remains 0.003652, Cnew is now 0.003651
		Training SVM with C=0.003651, nbinputs=10000, numruns=1
	testerr[Cnew 0.003651] = 46.300000 > testerr[Ccurrent 0.003652] = 46.300000
	REVERSE: Cstepfactor is now 1.000035, Ccurrent remains 0.003652, Cnew is now 0.003652
		Training SVM with C=0.003652, nbinputs=10000, numruns=1
	testerr[Cnew 0.003652] = 46.300000 > testerr[Ccurrent 0.003652] = 46.300000
	REVERSE: Cstepfactor is now 0.999982, Ccurrent remains 0.003652, Cnew is now 0.003652
	testerr[C 0.001000] = 47.900000 
	testerr[C 0.002371] = 47.000000 
	testerr[C 0.003162] = 46.500000 
	testerr[C 0.003398] = 46.500000 
	testerr[C 0.003587] = 46.500000 
	testerr[C 0.003635] = 46.400000 
	testerr[C 0.003648] = 46.500000 
	testerr[C 0.003651] = 46.600000 
	testerr[C 0.003651] = 46.300000 
	testerr[C 0.003652] = 46.300000  *best* (testerr = 46.300000, testerrdev = 0.000000, trainerr = 25.100000, trainerrdev = 0.000000)
	testerr[C 0.003652] = 46.300000 
	testerr[C 0.003652] = 46.300000 
	testerr[C 0.003654] = 46.300000 
	testerr[C 0.003660] = 46.600000 
	testerr[C 0.003685] = 46.500000 
	testerr[C 0.003786] = 46.600000 
	testerr[C 0.004217] = 47.100000 
	testerr[C 0.005623] = 47.400000 
	testerr[C 0.010000] = 49.700000 
	testerr[C 0.100000] = 55.700000 
...done with SVM validation for 10000 examples (numrums=1, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm)...
ceylon.iro.umontreal.ca 2010-08-11 14:15:22.529219: 0:33:31.070000 user+sys, 0:46:45.100000 real, 71.69% usage, 583.55 MB
		----  Encoding  layer #1 ----
			**** DenseLayer.__init__ ****
			tag =  enc1
			inp =  inp
			n_inp =  5000
			n_out =  1000
			act =  tanh
			noise =  binomial_NLP
			out =  outenc1
			params (gradients) =  [Wenc1, benc1]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc1
			allocW, allocb, allocmask =  False False False
		----  Encoding  layer #2 ----
			**** DenseLayer.__init__ ****
			tag =  enc2
			inp =  outenc1
			n_inp =  1000
			n_out =  1000
			act =  tanh
			noise =  binomial
			out =  outenc2
			params (gradients) =  [Wenc2, benc2]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc2
			allocW, allocb, allocmask =  False False False
MRG_RandomStreams Can't determine #streams from size (Shape.0), guessing 30*256
	---- Auxiliary Layer ----
			**** DenseLayer.__init__ ****
			tag =  aux-1
			inp =  outenc2
			n_inp =  1000
			n_out =  1000
			act =  sigmoid
			noise =  None
			out =  outaux-1
			params (gradients) =  [Waux-1, baux-1]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  None
			allocW, allocb, allocmask =  False False ones
	**** SDAE ****
	depth =  3
	mode =  Aux
	depth_min, depth_max, update_type =  0 , 2 , special
	inp, n_inp =  inp , 5000
	n_hid =  [1000, 1000, 1000]
	layertype =  [<class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>]
	act =  ['tanh', 'tanh', 'rectifier']
	noise, noise_lvl =  ['binomial_NLP', 'binomial', 'binomial'] , 0.5
	tie =  [True, True, True]
	maskbool =  [None, None, None]
	n_out, outtype =  5 , <class 'deepANN.Logistic_regression.LogisticRegression'>
	lr =  0.001
	sup_scaling, unsup_scaling, aux_scaling  =  None None 1.0
	regularization, wdreg  =  [0.0, 0.0, 0.0, 0.0] , l2
	sparsity, spreg =  [0.0, 0.0, 0.01] , l1
	params, wd, sp =  [Wenc2, benc2, Waux-1, baux-1] , [] , []
	bbbool, hessscal =  None , None
	aux, auxtarget, aux_one_sided, auxdepth, auxregularization =  True , auxtarget , True , -1 , False
	auxact, auxn_out, auxwdreg =  sigmoid , 1000 , l2
##########  TEST ############ EPOCH :  2
CURRENT RECONSTRUCTION ERROR (is this on test or train?):  598.24505542
CURRENT 100 SVM ERROR:  (0.0031691737126170426, 54.189999999999998, 3.1067499999999999, 8.75, 2.0946400000000001)
CURRENT 1000 SVM ERROR:  (0.0037516192015446394, 46.289999999999999, 0.18681500000000001, 24.640000000000001, 0.19078800000000001)
CURRENT 10000 SVM ERROR:  (0.0036517412725483775, 46.299999999999997, 0.0, 25.100000000000001, 0.0)
ceylon.iro.umontreal.ca 2010-08-11 14:15:29.140010: 0:33:37.590000 user+sys, 0:46:51.710000 real, 71.76% usage, 583.55 MB
params.pkl saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth2pre2
Wenc1 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth2pre2/Layer1_W.pkl
benc1 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth2pre2/Layer1_b.pkl
maskenc1 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth2pre2/Layer1_mask.pkl
Wenc2 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth2pre2/Layer2_W.pkl
benc2 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth2pre2/Layer2_b.pkl
maskenc2 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth2pre2/Layer2_mask.pkl
Wenc3 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth2pre2/Layer3_W.pkl
benc3 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth2pre2/Layer3_b.pkl
maskenc3 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth2pre2/Layer3_mask.pkl
Waux-1 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth2pre2/Layeraux_W.pkl
baux-1 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth2pre2/Layeraux_b.pkl
maskaux-1 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth2pre2/Layeraux_mask.pkl
W saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth2pre2/Layerout_W.pkl
b saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth2pre2/Layerout_b.pkl
saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth2pre2
...done validating (err={1000: {0: (0.0052329911468149467, 47.100000000000001, 0.21908900000000001, 26.260000000000002, 0.233238), 1: (0.0014855080171727755, 46.75, 0.276586, 30.82, 0.15362300000000001), 2: (0.0037516192015446394, 46.289999999999999, 0.18681500000000001, 24.640000000000001, 0.19078800000000001)}, 10000: {0: (0.0052329911468149467, 46.899999999999999, 0.0, 26.100000000000001, 0.0), 1: (0.0010022511482929129, 46.700000000000003, 0.0, 33.399999999999999, 0.0), 2: (0.0036517412725483775, 46.299999999999997, 0.0, 25.100000000000001, 0.0)}, 100: {0: (1.0, 57.0, 3.1551499999999999, 0.0, 0.0), 1: (0.10000000000000001, 55.914999999999999, 2.85242, 0.0, 0.0), 2: (0.0031691737126170426, 54.189999999999998, 3.1067499999999999, 8.75, 2.0946400000000001)}},epoch=2,model=<deepANN.ANN.SDAE object at 0x30fcb50>,depth=1,ACT=['tanh', 'tanh', 'rectifier'],LR=0.001,NOISE_LVL=0.5,BATCHSIZE=10,train=<CudaNdarrayType(float32, matrix)>,datatrain=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_labels_1.pkl'),datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm,datatest=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_labels_1.pkl'),datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm,VALIDATION_TRAININGSIZE=[100, 1000, 10000],VALIDATION_RUNS_FOR_EACH_TRAININGSIZE={'100': 20, '10000': 1, '1000': 10},PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211)
ceylon.iro.umontreal.ca 2010-08-11 14:15:29.640512: 0:33:37.660000 user+sys, 0:46:52.210000 real, 71.75% usage, 585.66 MB
File: 1 16.7567329407 ----
ceylon.iro.umontreal.ca 2010-08-11 14:15:46.397640: 0:33:54.410000 user+sys, 0:47:08.970000 real, 71.91% usage, 585.66 MB
File: 2 16.7504501343 ----
ceylon.iro.umontreal.ca 2010-08-11 14:16:03.148895: 0:34:11.150000 user+sys, 0:47:25.710000 real, 72.08% usage, 585.66 MB
File: 3 16.7697541714 ----
ceylon.iro.umontreal.ca 2010-08-11 14:16:19.919540: 0:34:27.910000 user+sys, 0:47:42.480000 real, 72.24% usage, 585.66 MB
File: 4 16.7461419106 ----
ceylon.iro.umontreal.ca 2010-08-11 14:16:36.666558: 0:34:44.650000 user+sys, 0:47:59.230000 real, 72.40% usage, 585.66 MB
File: 5 16.759442091 ----
ceylon.iro.umontreal.ca 2010-08-11 14:16:53.426806: 0:35:01.390000 user+sys, 0:48:15.990000 real, 72.56% usage, 585.66 MB
File: 6 16.7562189102 ----
ceylon.iro.umontreal.ca 2010-08-11 14:17:10.183822: 0:35:18.120000 user+sys, 0:48:32.740000 real, 72.72% usage, 585.66 MB
File: 7 16.7939100266 ----
ceylon.iro.umontreal.ca 2010-08-11 14:17:26.978558: 0:35:34.890000 user+sys, 0:48:49.530000 real, 72.87% usage, 585.66 MB
File: 8 16.6312189102 ----
ceylon.iro.umontreal.ca 2010-08-11 14:17:43.611351: 0:35:51.500000 user+sys, 0:49:06.160000 real, 73.03% usage, 585.66 MB
File: 9 16.6585600376 ----
ceylon.iro.umontreal.ca 2010-08-11 14:18:00.270684: 0:36:08.130000 user+sys, 0:49:22.820000 real, 73.18% usage, 585.66 MB
File: 10 16.6377830505 ----
ceylon.iro.umontreal.ca 2010-08-11 14:18:16.909300: 0:36:24.740000 user+sys, 0:49:39.450000 real, 73.33% usage, 585.66 MB
File: 11 16.6354150772 ----
ceylon.iro.umontreal.ca 2010-08-11 14:18:33.545503: 0:36:41.350000 user+sys, 0:49:56.090000 real, 73.47% usage, 585.66 MB
File: 12 16.6405041218 ----
ceylon.iro.umontreal.ca 2010-08-11 14:18:50.186799: 0:36:57.990000 user+sys, 0:50:12.730000 real, 73.62% usage, 585.66 MB
File: 13 16.6316730976 ----
ceylon.iro.umontreal.ca 2010-08-11 14:19:06.819248: 0:37:14.610000 user+sys, 0:50:29.360000 real, 73.77% usage, 585.66 MB
File: 14 16.6551811695 ----
ceylon.iro.umontreal.ca 2010-08-11 14:19:23.475205: 0:37:31.240000 user+sys, 0:50:46.010000 real, 73.91% usage, 585.66 MB
File: 15 16.0219650269 ----
ceylon.iro.umontreal.ca 2010-08-11 14:19:39.497949: 0:37:47.170000 user+sys, 0:51:02.030000 real, 74.04% usage, 585.66 MB
...finished training epoch #3 of 3 (100.00%)
ceylon.iro.umontreal.ca 2010-08-11 14:19:39.498617: 0:37:47.180000 user+sys, 0:51:02.030000 real, 74.04% usage, 585.66 MB
...DONE DEPTH 2 of 3 (66.67%)
ceylon.iro.umontreal.ca 2010-08-11 14:19:39.499076: 0:37:47.180000 user+sys, 0:51:02.030000 real, 74.04% usage, 585.66 MB
BEGIN DEPTH 3 of 3 (100.00%)...
ceylon.iro.umontreal.ca 2010-08-11 14:19:39.499432: 0:37:47.180000 user+sys, 0:51:02.030000 real, 74.04% usage, 585.66 MB
	---- Auxiliary Layer ----
			**** DenseLayer.__init__ ****
			tag =  aux0
			inp =  outenc3
			n_inp =  1000
			n_out =  1000
			act =  sigmoid
			noise =  None
			out =  outaux0
			params (gradients) =  [Waux0, baux0]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  None
			allocW, allocb, allocmask =  True True ones
	**** SDAE ****
	depth =  3
	mode =  Aux
	depth_min, depth_max, update_type =  0 , 3 , special
	inp, n_inp =  inp , 5000
	n_hid =  [1000, 1000, 1000]
	layertype =  [<class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>]
	act =  ['tanh', 'tanh', 'rectifier']
	noise, noise_lvl =  ['binomial_NLP', 'binomial', 'binomial'] , 0.5
	tie =  [True, True, True]
	maskbool =  [None, None, None]
	n_out, outtype =  5 , <class 'deepANN.Logistic_regression.LogisticRegression'>
	lr =  0.001
	sup_scaling, unsup_scaling, aux_scaling  =  None None 1.0
	regularization, wdreg  =  [0.0, 0.0, 0.0, 0.0] , l2
	sparsity, spreg =  [0.0, 0.0, 0.01] , l1
	params, wd, sp =  [Wenc2, benc2, Waux0, baux0] , [] , []
	bbbool, hessscal =  None , None
	aux, auxtarget, aux_one_sided, auxdepth, auxregularization =  True , auxtarget , True , 0 , False
	auxact, auxn_out, auxwdreg =  sigmoid , 1000 , l2
		----  Encoding  layer #1 ----
			**** DenseLayer.__init__ ****
			tag =  enc1
			inp =  inp
			n_inp =  5000
			n_out =  1000
			act =  tanh
			noise =  binomial_NLP
			out =  outenc1
			params (gradients) =  [Wenc1, benc1]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc1
			allocW, allocb, allocmask =  False False False
		----  Encoding  layer #2 ----
			**** DenseLayer.__init__ ****
			tag =  enc2
			inp =  outenc1
			n_inp =  1000
			n_out =  1000
			act =  tanh
			noise =  binomial
			out =  outenc2
			params (gradients) =  [Wenc2, benc2]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc2
			allocW, allocb, allocmask =  False False False
		----  Encoding  layer #3 ----
			**** DenseLayer.__init__ ****
			tag =  enc3
			inp =  outenc2
			n_inp =  1000
			n_out =  1000
			act =  rectifier
			noise =  binomial
			out =  outenc3
			params (gradients) =  [Wenc3, benc3]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc3
			allocW, allocb, allocmask =  False False False
MRG_RandomStreams Can't determine #streams from size (Shape.0), guessing 30*256
	---- Auxiliary Layer ----
			**** DenseLayer.__init__ ****
			tag =  aux0
			inp =  outenc3
			n_inp =  1000
			n_out =  1000
			act =  sigmoid
			noise =  None
			out =  outaux0
			params (gradients) =  [Waux0, baux0]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  None
			allocW, allocb, allocmask =  False False ones
	**** SDAE ****
	depth =  3
	mode =  Aux
	depth_min, depth_max, update_type =  0 , 3 , special
	inp, n_inp =  inp , 5000
	n_hid =  [1000, 1000, 1000]
	layertype =  [<class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>]
	act =  ['tanh', 'tanh', 'rectifier']
	noise, noise_lvl =  ['binomial_NLP', 'binomial', 'binomial'] , 0.3
	tie =  [True, True, True]
	maskbool =  [None, None, None]
	n_out, outtype =  5 , <class 'deepANN.Logistic_regression.LogisticRegression'>
	lr =  0.0001
	sup_scaling, unsup_scaling, aux_scaling  =  None None 1.0
	regularization, wdreg  =  [0.0, 0.0, 0.0, 0.0] , l2
	sparsity, spreg =  [0.0, 0.0, 0.01] , l1
	params, wd, sp =  [Wenc3, benc3, Waux0, baux0] , [] , [Elemwise{mul,no_inplace}.0]
	bbbool, hessscal =  None , None
	aux, auxtarget, aux_one_sided, auxdepth, auxregularization =  True , auxtarget , True , 0 , False
	auxact, auxn_out, auxwdreg =  sigmoid , 1000 , l2
Validating (err={1000: {}, 10000: {}, 100: {}},epoch=0,model=<deepANN.ANN.SDAE object at 0x30fcb50>,depth=2,ACT=['tanh', 'tanh', 'rectifier'],LR=0.0001,NOISE_LVL=0.3,BATCHSIZE=10,train=<CudaNdarrayType(float32, matrix)>,datatrain=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_labels_1.pkl'),datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm,datatest=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_labels_1.pkl'),datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm,VALIDATION_TRAININGSIZE=[100, 1000, 10000],VALIDATION_RUNS_FOR_EACH_TRAININGSIZE={'100': 20, '10000': 1, '1000': 10},PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211)...
ceylon.iro.umontreal.ca 2010-08-11 14:19:45.116186: 0:37:52.570000 user+sys, 0:51:07.650000 real, 74.08% usage, 610.18 MB
		----  Encoding  layer #1 ----
			**** DenseLayer.__init__ ****
			tag =  enc1
			inp =  inp
			n_inp =  5000
			n_out =  1000
			act =  tanh
			noise =  binomial_NLP
			out =  outenc1
			params (gradients) =  [Wenc1, benc1]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc1
			allocW, allocb, allocmask =  False False False
		----  Encoding  layer #2 ----
			**** DenseLayer.__init__ ****
			tag =  enc2
			inp =  outenc1
			n_inp =  1000
			n_out =  1000
			act =  tanh
			noise =  binomial
			out =  outenc2
			params (gradients) =  [Wenc2, benc2]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc2
			allocW, allocb, allocmask =  False False False
		----  Encoding  layer #3 ----
			**** DenseLayer.__init__ ****
			tag =  enc3
			inp =  outenc2
			n_inp =  1000
			n_out =  1000
			act =  rectifier
			noise =  binomial
			out =  outenc3
			params (gradients) =  [Wenc3, benc3]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc3
			allocW, allocb, allocmask =  False False False
	---- Auxiliary Layer ----
			**** DenseLayer.__init__ ****
			tag =  aux0
			inp =  outenc3
			n_inp =  1000
			n_out =  1000
			act =  sigmoid
			noise =  None
			out =  outaux0
			params (gradients) =  [Waux0, baux0]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  None
			allocW, allocb, allocmask =  False False ones
	**** SDAE ****
	depth =  3
	mode =  Aux
	depth_min, depth_max, update_type =  0 , 3 , special
	inp, n_inp =  inp , 5000
	n_hid =  [1000, 1000, 1000]
	layertype =  [<class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>]
	act =  ['tanh', 'tanh', 'rectifier']
	noise, noise_lvl =  ['binomial_NLP', 'binomial', 'binomial'] , None
	tie =  [True, True, True]
	maskbool =  [None, None, None]
	n_out, outtype =  5 , <class 'deepANN.Logistic_regression.LogisticRegression'>
	lr =  0.0001
	sup_scaling, unsup_scaling, aux_scaling  =  None None 1.0
	regularization, wdreg  =  [0.0, 0.0, 0.0, 0.0] , l2
	sparsity, spreg =  [0.0, 0.0, 0.01] , l1
	params, wd, sp =  [Wenc3, benc3, Waux0, baux0] , [] , [Elemwise{mul,no_inplace}.0]
	bbbool, hessscal =  None , None
	aux, auxtarget, aux_one_sided, auxdepth, auxregularization =  True , auxtarget , True , 0 , False
	auxact, auxn_out, auxwdreg =  sigmoid , 1000 , l2
Creating libsvm file '/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm' (model=<deepANN.ANN.SDAE object at 0x30fcb50>, depth=2, datafiles=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_labels_1.pkl'))...
ceylon.iro.umontreal.ca 2010-08-11 14:19:48.480097: 0:37:55.850000 user+sys, 0:51:11.010000 real, 74.11% usage, 618.39 MB
...done creating libsvm files
ceylon.iro.umontreal.ca 2010-08-11 14:19:54.085649: 0:38:01.320000 user+sys, 0:51:16.620000 real, 74.15% usage, 618.39 MB
Creating libsvm file '/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm' (model=<deepANN.ANN.SDAE object at 0x30fcb50>, depth=2, datafiles=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_labels_1.pkl'))...
ceylon.iro.umontreal.ca 2010-08-11 14:19:54.086149: 0:38:01.320000 user+sys, 0:51:16.620000 real, 74.15% usage, 618.39 MB
...done creating libsvm files
ceylon.iro.umontreal.ca 2010-08-11 14:19:59.769152: 0:38:06.910000 user+sys, 0:51:22.300000 real, 74.19% usage, 618.39 MB
Starting SVM validation for 100 examples (numrums=20, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm, PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211, MAXSTEPS=20, STEPFACTOR=10.000000, INITIALC=0.010000)...
ceylon.iro.umontreal.ca 2010-08-11 14:19:59.769754: 0:38:06.910000 user+sys, 0:51:22.300000 real, 74.19% usage, 618.39 MB
		Training SVM with C=0.010000, nbinputs=100, numruns=20
		Training SVM with C=0.100000, nbinputs=100, numruns=20
	testerr[Cnew 0.100000] = 59.360000 > testerr[Ccurrent 0.010000] = 57.225000
	Cbest <= 0.010000, testerr[Cbest] = 57.225000
	REVERSE: Cstepfactor is now 0.316228, Ccurrent remains 0.010000, Cnew is now 0.003162
		Training SVM with C=0.003162, nbinputs=100, numruns=20
	testerr[Cnew 0.003162] = 57.705000 > testerr[Ccurrent 0.010000] = 57.225000
	REVERSE: Cstepfactor is now 1.778279, Ccurrent remains 0.010000, Cnew is now 0.017783
		Training SVM with C=0.017783, nbinputs=100, numruns=20
	testerr[Cnew 0.017783] = 55.565000 < testerr[Ccurrent 0.010000] = 57.225000
	NEW BEST: Cbest <= 0.017783, testerr[Cbest] = 55.565000
	PROCEED: Cstepfactor remains 1.778279, Ccurrent is now 0.017783, Cnew is now 0.031623
		Training SVM with C=0.031623, nbinputs=100, numruns=20
	testerr[Cnew 0.031623] = 57.375000 > testerr[Ccurrent 0.017783] = 55.565000
	REVERSE: Cstepfactor is now 0.749894, Ccurrent remains 0.017783, Cnew is now 0.013335
		Training SVM with C=0.013335, nbinputs=100, numruns=20
	testerr[Cnew 0.013335] = 55.725000 > testerr[Ccurrent 0.017783] = 55.565000
	REVERSE: Cstepfactor is now 1.154782, Ccurrent remains 0.017783, Cnew is now 0.020535
		Training SVM with C=0.020535, nbinputs=100, numruns=20
	testerr[Cnew 0.020535] = 55.340000 < testerr[Ccurrent 0.017783] = 55.565000
	NEW BEST: Cbest <= 0.020535, testerr[Cbest] = 55.340000
	PROCEED: Cstepfactor remains 1.154782, Ccurrent is now 0.020535, Cnew is now 0.023714
		Training SVM with C=0.023714, nbinputs=100, numruns=20
	testerr[Cnew 0.023714] = 56.605000 > testerr[Ccurrent 0.020535] = 55.340000
	REVERSE: Cstepfactor is now 0.930572, Ccurrent remains 0.020535, Cnew is now 0.019110
		Training SVM with C=0.019110, nbinputs=100, numruns=20
	testerr[Cnew 0.019110] = 55.825000 > testerr[Ccurrent 0.020535] = 55.340000
	REVERSE: Cstepfactor is now 1.036633, Ccurrent remains 0.020535, Cnew is now 0.021288
		Training SVM with C=0.021288, nbinputs=100, numruns=20
	testerr[Cnew 0.021288] = 55.605000 > testerr[Ccurrent 0.020535] = 55.340000
	REVERSE: Cstepfactor is now 0.982172, Ccurrent remains 0.020535, Cnew is now 0.020169
		Training SVM with C=0.020169, nbinputs=100, numruns=20
	testerr[Cnew 0.020169] = 58.465000 > testerr[Ccurrent 0.020535] = 55.340000
	REVERSE: Cstepfactor is now 1.009035, Ccurrent remains 0.020535, Cnew is now 0.020721
		Training SVM with C=0.020721, nbinputs=100, numruns=20
	testerr[Cnew 0.020721] = 55.725000 > testerr[Ccurrent 0.020535] = 55.340000
	REVERSE: Cstepfactor is now 0.995513, Ccurrent remains 0.020535, Cnew is now 0.020443
		Training SVM with C=0.020443, nbinputs=100, numruns=20
	testerr[Cnew 0.020443] = 56.385000 > testerr[Ccurrent 0.020535] = 55.340000
	REVERSE: Cstepfactor is now 1.002251, Ccurrent remains 0.020535, Cnew is now 0.020581
		Training SVM with C=0.020581, nbinputs=100, numruns=20
	testerr[Cnew 0.020581] = 57.630000 > testerr[Ccurrent 0.020535] = 55.340000
	REVERSE: Cstepfactor is now 0.998876, Ccurrent remains 0.020535, Cnew is now 0.020512
		Training SVM with C=0.020512, nbinputs=100, numruns=20
	testerr[Cnew 0.020512] = 56.795000 > testerr[Ccurrent 0.020535] = 55.340000
	REVERSE: Cstepfactor is now 1.000562, Ccurrent remains 0.020535, Cnew is now 0.020547
		Training SVM with C=0.020547, nbinputs=100, numruns=20
	testerr[Cnew 0.020547] = 56.265000 > testerr[Ccurrent 0.020535] = 55.340000
	REVERSE: Cstepfactor is now 0.999719, Ccurrent remains 0.020535, Cnew is now 0.020529
		Training SVM with C=0.020529, nbinputs=100, numruns=20
	testerr[Cnew 0.020529] = 57.085000 > testerr[Ccurrent 0.020535] = 55.340000
	REVERSE: Cstepfactor is now 1.000141, Ccurrent remains 0.020535, Cnew is now 0.020538
		Training SVM with C=0.020538, nbinputs=100, numruns=20
	testerr[Cnew 0.020538] = 56.870000 > testerr[Ccurrent 0.020535] = 55.340000
	REVERSE: Cstepfactor is now 0.999930, Ccurrent remains 0.020535, Cnew is now 0.020534
		Training SVM with C=0.020534, nbinputs=100, numruns=20
	testerr[Cnew 0.020534] = 57.075000 > testerr[Ccurrent 0.020535] = 55.340000
	REVERSE: Cstepfactor is now 1.000035, Ccurrent remains 0.020535, Cnew is now 0.020536
		Training SVM with C=0.020536, nbinputs=100, numruns=20
	testerr[Cnew 0.020536] = 55.860000 > testerr[Ccurrent 0.020535] = 55.340000
	REVERSE: Cstepfactor is now 0.999982, Ccurrent remains 0.020535, Cnew is now 0.020535
	testerr[C 0.003162] = 57.705000 
	testerr[C 0.010000] = 57.225000 
	testerr[C 0.013335] = 55.725000 
	testerr[C 0.017783] = 55.565000 
	testerr[C 0.019110] = 55.825000 
	testerr[C 0.020169] = 58.465000 
	testerr[C 0.020443] = 56.385000 
	testerr[C 0.020512] = 56.795000 
	testerr[C 0.020529] = 57.085000 
	testerr[C 0.020534] = 57.075000 
	testerr[C 0.020535] = 55.340000  *best* (testerr = 55.340000, testerrdev = 3.158230, trainerr = 2.900000, trainerrdev = 1.609350)
	testerr[C 0.020536] = 55.860000 
	testerr[C 0.020538] = 56.870000 
	testerr[C 0.020547] = 56.265000 
	testerr[C 0.020581] = 57.630000 
	testerr[C 0.020721] = 55.725000 
	testerr[C 0.021288] = 55.605000 
	testerr[C 0.023714] = 56.605000 
	testerr[C 0.031623] = 57.375000 
	testerr[C 0.100000] = 59.360000 
...done with SVM validation for 100 examples (numrums=20, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm)...
ceylon.iro.umontreal.ca 2010-08-11 14:20:24.272067: 0:38:07 user+sys, 0:51:46.800000 real, 73.61% usage, 618.39 MB
Starting SVM validation for 1000 examples (numrums=10, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm, PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211, MAXSTEPS=20, STEPFACTOR=10.000000, INITIALC=0.010000)...
ceylon.iro.umontreal.ca 2010-08-11 14:20:24.272486: 0:38:07 user+sys, 0:51:46.800000 real, 73.61% usage, 618.39 MB
		Training SVM with C=0.010000, nbinputs=1000, numruns=10
		Training SVM with C=0.100000, nbinputs=1000, numruns=10
	testerr[Cnew 0.100000] = 53.200000 > testerr[Ccurrent 0.010000] = 49.350000
	Cbest <= 0.010000, testerr[Cbest] = 49.350000
	REVERSE: Cstepfactor is now 0.316228, Ccurrent remains 0.010000, Cnew is now 0.003162
		Training SVM with C=0.003162, nbinputs=1000, numruns=10
	testerr[Cnew 0.003162] = 48.280000 < testerr[Ccurrent 0.010000] = 49.350000
	NEW BEST: Cbest <= 0.003162, testerr[Cbest] = 48.280000
	PROCEED: Cstepfactor remains 0.316228, Ccurrent is now 0.003162, Cnew is now 0.001000
		Training SVM with C=0.001000, nbinputs=1000, numruns=10
	testerr[Cnew 0.001000] = 49.760000 > testerr[Ccurrent 0.003162] = 48.280000
	REVERSE: Cstepfactor is now 1.778279, Ccurrent remains 0.003162, Cnew is now 0.005623
		Training SVM with C=0.005623, nbinputs=1000, numruns=10
	testerr[Cnew 0.005623] = 48.750000 > testerr[Ccurrent 0.003162] = 48.280000
	REVERSE: Cstepfactor is now 0.749894, Ccurrent remains 0.003162, Cnew is now 0.002371
		Training SVM with C=0.002371, nbinputs=1000, numruns=10
	testerr[Cnew 0.002371] = 48.340000 > testerr[Ccurrent 0.003162] = 48.280000
	REVERSE: Cstepfactor is now 1.154782, Ccurrent remains 0.003162, Cnew is now 0.003652
		Training SVM with C=0.003652, nbinputs=1000, numruns=10
	testerr[Cnew 0.003652] = 48.380000 > testerr[Ccurrent 0.003162] = 48.280000
	REVERSE: Cstepfactor is now 0.930572, Ccurrent remains 0.003162, Cnew is now 0.002943
		Training SVM with C=0.002943, nbinputs=1000, numruns=10
	testerr[Cnew 0.002943] = 48.300000 > testerr[Ccurrent 0.003162] = 48.280000
	REVERSE: Cstepfactor is now 1.036633, Ccurrent remains 0.003162, Cnew is now 0.003278
		Training SVM with C=0.003278, nbinputs=1000, numruns=10
	testerr[Cnew 0.003278] = 48.220000 < testerr[Ccurrent 0.003162] = 48.280000
	NEW BEST: Cbest <= 0.003278, testerr[Cbest] = 48.220000
	PROCEED: Cstepfactor remains 1.036633, Ccurrent is now 0.003278, Cnew is now 0.003398
		Training SVM with C=0.003398, nbinputs=1000, numruns=10
	testerr[Cnew 0.003398] = 48.100000 < testerr[Ccurrent 0.003278] = 48.220000
	NEW BEST: Cbest <= 0.003398, testerr[Cbest] = 48.100000
	PROCEED: Cstepfactor remains 1.036633, Ccurrent is now 0.003398, Cnew is now 0.003523
		Training SVM with C=0.003523, nbinputs=1000, numruns=10
	testerr[Cnew 0.003523] = 48.190000 > testerr[Ccurrent 0.003398] = 48.100000
	REVERSE: Cstepfactor is now 0.982172, Ccurrent remains 0.003398, Cnew is now 0.003338
		Training SVM with C=0.003338, nbinputs=1000, numruns=10
	testerr[Cnew 0.003338] = 48.220000 > testerr[Ccurrent 0.003398] = 48.100000
	REVERSE: Cstepfactor is now 1.009035, Ccurrent remains 0.003398, Cnew is now 0.003429
		Training SVM with C=0.003429, nbinputs=1000, numruns=10
	testerr[Cnew 0.003429] = 48.160000 > testerr[Ccurrent 0.003398] = 48.100000
	REVERSE: Cstepfactor is now 0.995513, Ccurrent remains 0.003398, Cnew is now 0.003383
		Training SVM with C=0.003383, nbinputs=1000, numruns=10
	testerr[Cnew 0.003383] = 48.220000 > testerr[Ccurrent 0.003398] = 48.100000
	REVERSE: Cstepfactor is now 1.002251, Ccurrent remains 0.003398, Cnew is now 0.003406
		Training SVM with C=0.003406, nbinputs=1000, numruns=10
	testerr[Cnew 0.003406] = 47.990000 < testerr[Ccurrent 0.003398] = 48.100000
	NEW BEST: Cbest <= 0.003406, testerr[Cbest] = 47.990000
	PROCEED: Cstepfactor remains 1.002251, Ccurrent is now 0.003406, Cnew is now 0.003414
		Training SVM with C=0.003414, nbinputs=1000, numruns=10
	testerr[Cnew 0.003414] = 48.190000 > testerr[Ccurrent 0.003406] = 47.990000
	REVERSE: Cstepfactor is now 0.998876, Ccurrent remains 0.003406, Cnew is now 0.003402
		Training SVM with C=0.003402, nbinputs=1000, numruns=10
	testerr[Cnew 0.003402] = 48.180000 > testerr[Ccurrent 0.003406] = 47.990000
	REVERSE: Cstepfactor is now 1.000562, Ccurrent remains 0.003406, Cnew is now 0.003408
		Training SVM with C=0.003408, nbinputs=1000, numruns=10
	testerr[Cnew 0.003408] = 48.170000 > testerr[Ccurrent 0.003406] = 47.990000
	REVERSE: Cstepfactor is now 0.999719, Ccurrent remains 0.003406, Cnew is now 0.003405
		Training SVM with C=0.003405, nbinputs=1000, numruns=10
	testerr[Cnew 0.003405] = 48.230000 > testerr[Ccurrent 0.003406] = 47.990000
	REVERSE: Cstepfactor is now 1.000141, Ccurrent remains 0.003406, Cnew is now 0.003406
		Training SVM with C=0.003406, nbinputs=1000, numruns=10
	testerr[Cnew 0.003406] = 48.190000 > testerr[Ccurrent 0.003406] = 47.990000
	REVERSE: Cstepfactor is now 0.999930, Ccurrent remains 0.003406, Cnew is now 0.003406
	testerr[C 0.001000] = 49.760000 
	testerr[C 0.002371] = 48.340000 
	testerr[C 0.002943] = 48.300000 
	testerr[C 0.003162] = 48.280000 
	testerr[C 0.003278] = 48.220000 
	testerr[C 0.003338] = 48.220000 
	testerr[C 0.003383] = 48.220000 
	testerr[C 0.003398] = 48.100000 
	testerr[C 0.003402] = 48.180000 
	testerr[C 0.003405] = 48.230000 
	testerr[C 0.003406] = 47.990000  *best* (testerr = 47.990000, testerrdev = 0.280891, trainerr = 28.100000, trainerrdev = 0.184391)
	testerr[C 0.003406] = 48.190000 
	testerr[C 0.003408] = 48.170000 
	testerr[C 0.003414] = 48.190000 
	testerr[C 0.003429] = 48.160000 
	testerr[C 0.003523] = 48.190000 
	testerr[C 0.003652] = 48.380000 
	testerr[C 0.005623] = 48.750000 
	testerr[C 0.010000] = 49.350000 
	testerr[C 0.100000] = 53.200000 
...done with SVM validation for 1000 examples (numrums=10, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm)...
ceylon.iro.umontreal.ca 2010-08-11 14:21:13.561530: 0:38:07.080000 user+sys, 0:52:36.080000 real, 72.47% usage, 618.39 MB
Starting SVM validation for 10000 examples (numrums=1, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm, PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211, MAXSTEPS=20, STEPFACTOR=10.000000, INITIALC=0.010000)...
ceylon.iro.umontreal.ca 2010-08-11 14:21:13.561944: 0:38:07.080000 user+sys, 0:52:36.080000 real, 72.47% usage, 618.39 MB
		Training SVM with C=0.010000, nbinputs=10000, numruns=1
		Training SVM with C=0.100000, nbinputs=10000, numruns=1
	testerr[Cnew 0.100000] = 53.100000 > testerr[Ccurrent 0.010000] = 49.300000
	Cbest <= 0.010000, testerr[Cbest] = 49.300000
	REVERSE: Cstepfactor is now 0.316228, Ccurrent remains 0.010000, Cnew is now 0.003162
		Training SVM with C=0.003162, nbinputs=10000, numruns=1
	testerr[Cnew 0.003162] = 48.300000 < testerr[Ccurrent 0.010000] = 49.300000
	NEW BEST: Cbest <= 0.003162, testerr[Cbest] = 48.300000
	PROCEED: Cstepfactor remains 0.316228, Ccurrent is now 0.003162, Cnew is now 0.001000
		Training SVM with C=0.001000, nbinputs=10000, numruns=1
	testerr[Cnew 0.001000] = 49.700000 > testerr[Ccurrent 0.003162] = 48.300000
	REVERSE: Cstepfactor is now 1.778279, Ccurrent remains 0.003162, Cnew is now 0.005623
		Training SVM with C=0.005623, nbinputs=10000, numruns=1
	testerr[Cnew 0.005623] = 48.500000 > testerr[Ccurrent 0.003162] = 48.300000
	REVERSE: Cstepfactor is now 0.749894, Ccurrent remains 0.003162, Cnew is now 0.002371
		Training SVM with C=0.002371, nbinputs=10000, numruns=1
	testerr[Cnew 0.002371] = 48.600000 > testerr[Ccurrent 0.003162] = 48.300000
	REVERSE: Cstepfactor is now 1.154782, Ccurrent remains 0.003162, Cnew is now 0.003652
		Training SVM with C=0.003652, nbinputs=10000, numruns=1
	testerr[Cnew 0.003652] = 48.400000 > testerr[Ccurrent 0.003162] = 48.300000
	REVERSE: Cstepfactor is now 0.930572, Ccurrent remains 0.003162, Cnew is now 0.002943
		Training SVM with C=0.002943, nbinputs=10000, numruns=1
	testerr[Cnew 0.002943] = 48.200000 < testerr[Ccurrent 0.003162] = 48.300000
	NEW BEST: Cbest <= 0.002943, testerr[Cbest] = 48.200000
	PROCEED: Cstepfactor remains 0.930572, Ccurrent is now 0.002943, Cnew is now 0.002738
		Training SVM with C=0.002738, nbinputs=10000, numruns=1
	testerr[Cnew 0.002738] = 48.600000 > testerr[Ccurrent 0.002943] = 48.200000
	REVERSE: Cstepfactor is now 1.036633, Ccurrent remains 0.002943, Cnew is now 0.003051
		Training SVM with C=0.003051, nbinputs=10000, numruns=1
	testerr[Cnew 0.003051] = 48.300000 > testerr[Ccurrent 0.002943] = 48.200000
	REVERSE: Cstepfactor is now 0.982172, Ccurrent remains 0.002943, Cnew is now 0.002890
		Training SVM with C=0.002890, nbinputs=10000, numruns=1
	testerr[Cnew 0.002890] = 48.400000 > testerr[Ccurrent 0.002943] = 48.200000
	REVERSE: Cstepfactor is now 1.009035, Ccurrent remains 0.002943, Cnew is now 0.002969
		Training SVM with C=0.002969, nbinputs=10000, numruns=1
	testerr[Cnew 0.002969] = 47.700000 < testerr[Ccurrent 0.002943] = 48.200000
	NEW BEST: Cbest <= 0.002969, testerr[Cbest] = 47.700000
	PROCEED: Cstepfactor remains 1.009035, Ccurrent is now 0.002969, Cnew is now 0.002996
		Training SVM with C=0.002996, nbinputs=10000, numruns=1
	testerr[Cnew 0.002996] = 48.500000 > testerr[Ccurrent 0.002969] = 47.700000
	REVERSE: Cstepfactor is now 0.995513, Ccurrent remains 0.002969, Cnew is now 0.002956
		Training SVM with C=0.002956, nbinputs=10000, numruns=1
	testerr[Cnew 0.002956] = 48.500000 > testerr[Ccurrent 0.002969] = 47.700000
	REVERSE: Cstepfactor is now 1.002251, Ccurrent remains 0.002969, Cnew is now 0.002976
		Training SVM with C=0.002976, nbinputs=10000, numruns=1
	testerr[Cnew 0.002976] = 47.900000 > testerr[Ccurrent 0.002969] = 47.700000
	REVERSE: Cstepfactor is now 0.998876, Ccurrent remains 0.002969, Cnew is now 0.002966
		Training SVM with C=0.002966, nbinputs=10000, numruns=1
	testerr[Cnew 0.002966] = 48.000000 > testerr[Ccurrent 0.002969] = 47.700000
	REVERSE: Cstepfactor is now 1.000562, Ccurrent remains 0.002969, Cnew is now 0.002971
		Training SVM with C=0.002971, nbinputs=10000, numruns=1
	testerr[Cnew 0.002971] = 48.100000 > testerr[Ccurrent 0.002969] = 47.700000
	REVERSE: Cstepfactor is now 0.999719, Ccurrent remains 0.002969, Cnew is now 0.002968
		Training SVM with C=0.002968, nbinputs=10000, numruns=1
	testerr[Cnew 0.002968] = 48.400000 > testerr[Ccurrent 0.002969] = 47.700000
	REVERSE: Cstepfactor is now 1.000141, Ccurrent remains 0.002969, Cnew is now 0.002970
		Training SVM with C=0.002970, nbinputs=10000, numruns=1
	testerr[Cnew 0.002970] = 48.100000 > testerr[Ccurrent 0.002969] = 47.700000
	REVERSE: Cstepfactor is now 0.999930, Ccurrent remains 0.002969, Cnew is now 0.002969
		Training SVM with C=0.002969, nbinputs=10000, numruns=1
	testerr[Cnew 0.002969] = 47.700000 > testerr[Ccurrent 0.002969] = 47.700000
	REVERSE: Cstepfactor is now 1.000035, Ccurrent remains 0.002969, Cnew is now 0.002969
	testerr[C 0.001000] = 49.700000 
	testerr[C 0.002371] = 48.600000 
	testerr[C 0.002738] = 48.600000 
	testerr[C 0.002890] = 48.400000 
	testerr[C 0.002943] = 48.200000 
	testerr[C 0.002956] = 48.500000 
	testerr[C 0.002966] = 48.000000 
	testerr[C 0.002968] = 48.400000 
	testerr[C 0.002969] = 47.700000 
	testerr[C 0.002969] = 47.700000  *best* (testerr = 47.700000, testerrdev = 0.000000, trainerr = 29.300000, trainerrdev = 0.000000)
	testerr[C 0.002970] = 48.100000 
	testerr[C 0.002971] = 48.100000 
	testerr[C 0.002976] = 47.900000 
	testerr[C 0.002996] = 48.500000 
	testerr[C 0.003051] = 48.300000 
	testerr[C 0.003162] = 48.300000 
	testerr[C 0.003652] = 48.400000 
	testerr[C 0.005623] = 48.500000 
	testerr[C 0.010000] = 49.300000 
	testerr[C 0.100000] = 53.100000 
...done with SVM validation for 10000 examples (numrums=1, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm)...
ceylon.iro.umontreal.ca 2010-08-11 14:21:24.871374: 0:38:07.170000 user+sys, 0:52:47.390000 real, 72.21% usage, 618.39 MB
		----  Encoding  layer #1 ----
			**** DenseLayer.__init__ ****
			tag =  enc1
			inp =  inp
			n_inp =  5000
			n_out =  1000
			act =  tanh
			noise =  binomial_NLP
			out =  outenc1
			params (gradients) =  [Wenc1, benc1]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc1
			allocW, allocb, allocmask =  False False False
		----  Encoding  layer #2 ----
			**** DenseLayer.__init__ ****
			tag =  enc2
			inp =  outenc1
			n_inp =  1000
			n_out =  1000
			act =  tanh
			noise =  binomial
			out =  outenc2
			params (gradients) =  [Wenc2, benc2]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc2
			allocW, allocb, allocmask =  False False False
		----  Encoding  layer #3 ----
			**** DenseLayer.__init__ ****
			tag =  enc3
			inp =  outenc2
			n_inp =  1000
			n_out =  1000
			act =  rectifier
			noise =  binomial
			out =  outenc3
			params (gradients) =  [Wenc3, benc3]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc3
			allocW, allocb, allocmask =  False False False
MRG_RandomStreams Can't determine #streams from size (Shape.0), guessing 30*256
	---- Auxiliary Layer ----
			**** DenseLayer.__init__ ****
			tag =  aux0
			inp =  outenc3
			n_inp =  1000
			n_out =  1000
			act =  sigmoid
			noise =  None
			out =  outaux0
			params (gradients) =  [Waux0, baux0]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  None
			allocW, allocb, allocmask =  False False ones
	**** SDAE ****
	depth =  3
	mode =  Aux
	depth_min, depth_max, update_type =  0 , 3 , special
	inp, n_inp =  inp , 5000
	n_hid =  [1000, 1000, 1000]
	layertype =  [<class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>]
	act =  ['tanh', 'tanh', 'rectifier']
	noise, noise_lvl =  ['binomial_NLP', 'binomial', 'binomial'] , 0.3
	tie =  [True, True, True]
	maskbool =  [None, None, None]
	n_out, outtype =  5 , <class 'deepANN.Logistic_regression.LogisticRegression'>
	lr =  0.0001
	sup_scaling, unsup_scaling, aux_scaling  =  None None 1.0
	regularization, wdreg  =  [0.0, 0.0, 0.0, 0.0] , l2
	sparsity, spreg =  [0.0, 0.0, 0.01] , l1
	params, wd, sp =  [Wenc3, benc3, Waux0, baux0] , [] , [Elemwise{mul,no_inplace}.0]
	bbbool, hessscal =  None , None
	aux, auxtarget, aux_one_sided, auxdepth, auxregularization =  True , auxtarget , True , 0 , False
	auxact, auxn_out, auxwdreg =  sigmoid , 1000 , l2
##########  TEST ############ EPOCH :  0
CURRENT RECONSTRUCTION ERROR (is this on test or train?):  714.656567627
CURRENT 100 SVM ERROR:  (0.020535250264571463, 55.340000000000003, 3.1582300000000001, 2.8999999999999999, 1.6093500000000001)
CURRENT 1000 SVM ERROR:  (0.0034058581998212207, 47.990000000000002, 0.280891, 28.100000000000001, 0.184391)
CURRENT 10000 SVM ERROR:  (0.0029693148482024781, 47.700000000000003, 0.0, 29.300000000000001, 0.0)
ceylon.iro.umontreal.ca 2010-08-11 14:21:31.993039: 0:38:14.180000 user+sys, 0:52:54.510000 real, 72.27% usage, 618.39 MB
...done validating (err={1000: {0: (0.0034058581998212207, 47.990000000000002, 0.280891, 28.100000000000001, 0.184391)}, 10000: {0: (0.0029693148482024781, 47.700000000000003, 0.0, 29.300000000000001, 0.0)}, 100: {0: (0.020535250264571463, 55.340000000000003, 3.1582300000000001, 2.8999999999999999, 1.6093500000000001)}},epoch=0,model=<deepANN.ANN.SDAE object at 0x30fcb50>,depth=2,ACT=['tanh', 'tanh', 'rectifier'],LR=0.0001,NOISE_LVL=0.3,BATCHSIZE=10,train=<CudaNdarrayType(float32, matrix)>,datatrain=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_labels_1.pkl'),datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm,datatest=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_labels_1.pkl'),datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm,VALIDATION_TRAININGSIZE=[100, 1000, 10000],VALIDATION_RUNS_FOR_EACH_TRAININGSIZE={'100': 20, '10000': 1, '1000': 10},PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211)
ceylon.iro.umontreal.ca 2010-08-11 14:21:31.993515: 0:38:14.180000 user+sys, 0:52:54.510000 real, 72.27% usage, 618.39 MB
File: 1 22.0721879005 ----
ceylon.iro.umontreal.ca 2010-08-11 14:21:54.066108: 0:38:36.210000 user+sys, 0:53:16.580000 real, 72.46% usage, 618.39 MB
File: 2 22.0603339672 ----
ceylon.iro.umontreal.ca 2010-08-11 14:22:16.126876: 0:38:58.250000 user+sys, 0:53:38.640000 real, 72.65% usage, 618.39 MB
File: 3 22.0915579796 ----
ceylon.iro.umontreal.ca 2010-08-11 14:22:38.218870: 0:39:20.290000 user+sys, 0:54:00.720000 real, 72.83% usage, 618.39 MB
File: 4 22.0624599457 ----
ceylon.iro.umontreal.ca 2010-08-11 14:23:00.281773: 0:39:42.320000 user+sys, 0:54:22.780000 real, 73.02% usage, 618.39 MB
File: 5 22.1165299416 ----
ceylon.iro.umontreal.ca 2010-08-11 14:23:22.398736: 0:40:04.420000 user+sys, 0:54:44.900000 real, 73.20% usage, 618.39 MB
File: 6 21.9304769039 ----
ceylon.iro.umontreal.ca 2010-08-11 14:23:44.329664: 0:40:26.320000 user+sys, 0:55:06.830000 real, 73.37% usage, 618.39 MB
File: 7 21.9335949421 ----
ceylon.iro.umontreal.ca 2010-08-11 14:24:06.263695: 0:40:48.210000 user+sys, 0:55:28.760000 real, 73.55% usage, 618.39 MB
File: 8 22.0341072083 ----
ceylon.iro.umontreal.ca 2010-08-11 14:24:28.298227: 0:41:10.140000 user+sys, 0:55:50.790000 real, 73.72% usage, 618.39 MB
File: 9 21.9398281574 ----
ceylon.iro.umontreal.ca 2010-08-11 14:24:50.238515: 0:41:32.060000 user+sys, 0:56:12.720000 real, 73.89% usage, 618.39 MB
File: 10 21.9331548214 ----
ceylon.iro.umontreal.ca 2010-08-11 14:25:12.172114: 0:41:53.970000 user+sys, 0:56:34.650000 real, 74.06% usage, 618.39 MB
File: 11 21.9277501106 ----
ceylon.iro.umontreal.ca 2010-08-11 14:25:34.100314: 0:42:15.890000 user+sys, 0:56:56.580000 real, 74.22% usage, 618.39 MB
File: 12 21.9452419281 ----
ceylon.iro.umontreal.ca 2010-08-11 14:25:56.046005: 0:42:37.810000 user+sys, 0:57:18.520000 real, 74.39% usage, 618.39 MB
File: 13 21.9317409992 ----
ceylon.iro.umontreal.ca 2010-08-11 14:26:17.978187: 0:42:59.720000 user+sys, 0:57:40.450000 real, 74.55% usage, 618.39 MB
File: 14 21.9342691898 ----
ceylon.iro.umontreal.ca 2010-08-11 14:26:39.912908: 0:43:21.640000 user+sys, 0:58:02.380000 real, 74.71% usage, 618.39 MB
File: 15 20.9867298603 ----
ceylon.iro.umontreal.ca 2010-08-11 14:27:00.900087: 0:43:42.590000 user+sys, 0:58:23.370000 real, 74.86% usage, 618.39 MB
...finished training epoch #1 of 3 (33.33%)
ceylon.iro.umontreal.ca 2010-08-11 14:27:00.900416: 0:43:42.590000 user+sys, 0:58:23.370000 real, 74.86% usage, 618.39 MB
Validating (err={1000: {0: (0.0034058581998212207, 47.990000000000002, 0.280891, 28.100000000000001, 0.184391)}, 10000: {0: (0.0029693148482024781, 47.700000000000003, 0.0, 29.300000000000001, 0.0)}, 100: {0: (0.020535250264571463, 55.340000000000003, 3.1582300000000001, 2.8999999999999999, 1.6093500000000001)}},epoch=1,model=<deepANN.ANN.SDAE object at 0x30fcb50>,depth=2,ACT=['tanh', 'tanh', 'rectifier'],LR=0.0001,NOISE_LVL=0.3,BATCHSIZE=10,train=<CudaNdarrayType(float32, matrix)>,datatrain=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_labels_1.pkl'),datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm,datatest=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_labels_1.pkl'),datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm,VALIDATION_TRAININGSIZE=[100, 1000, 10000],VALIDATION_RUNS_FOR_EACH_TRAININGSIZE={'100': 20, '10000': 1, '1000': 10},PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211)...
ceylon.iro.umontreal.ca 2010-08-11 14:27:00.900821: 0:43:42.590000 user+sys, 0:58:23.370000 real, 74.86% usage, 618.39 MB
		----  Encoding  layer #1 ----
			**** DenseLayer.__init__ ****
			tag =  enc1
			inp =  inp
			n_inp =  5000
			n_out =  1000
			act =  tanh
			noise =  binomial_NLP
			out =  outenc1
			params (gradients) =  [Wenc1, benc1]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc1
			allocW, allocb, allocmask =  False False False
		----  Encoding  layer #2 ----
			**** DenseLayer.__init__ ****
			tag =  enc2
			inp =  outenc1
			n_inp =  1000
			n_out =  1000
			act =  tanh
			noise =  binomial
			out =  outenc2
			params (gradients) =  [Wenc2, benc2]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc2
			allocW, allocb, allocmask =  False False False
		----  Encoding  layer #3 ----
			**** DenseLayer.__init__ ****
			tag =  enc3
			inp =  outenc2
			n_inp =  1000
			n_out =  1000
			act =  rectifier
			noise =  binomial
			out =  outenc3
			params (gradients) =  [Wenc3, benc3]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc3
			allocW, allocb, allocmask =  False False False
	---- Auxiliary Layer ----
			**** DenseLayer.__init__ ****
			tag =  aux0
			inp =  outenc3
			n_inp =  1000
			n_out =  1000
			act =  sigmoid
			noise =  None
			out =  outaux0
			params (gradients) =  [Waux0, baux0]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  None
			allocW, allocb, allocmask =  False False ones
	**** SDAE ****
	depth =  3
	mode =  Aux
	depth_min, depth_max, update_type =  0 , 3 , special
	inp, n_inp =  inp , 5000
	n_hid =  [1000, 1000, 1000]
	layertype =  [<class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>]
	act =  ['tanh', 'tanh', 'rectifier']
	noise, noise_lvl =  ['binomial_NLP', 'binomial', 'binomial'] , None
	tie =  [True, True, True]
	maskbool =  [None, None, None]
	n_out, outtype =  5 , <class 'deepANN.Logistic_regression.LogisticRegression'>
	lr =  0.0001
	sup_scaling, unsup_scaling, aux_scaling  =  None None 1.0
	regularization, wdreg  =  [0.0, 0.0, 0.0, 0.0] , l2
	sparsity, spreg =  [0.0, 0.0, 0.01] , l1
	params, wd, sp =  [Wenc3, benc3, Waux0, baux0] , [] , [Elemwise{mul,no_inplace}.0]
	bbbool, hessscal =  None , None
	aux, auxtarget, aux_one_sided, auxdepth, auxregularization =  True , auxtarget , True , 0 , False
	auxact, auxn_out, auxwdreg =  sigmoid , 1000 , l2
Creating libsvm file '/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm' (model=<deepANN.ANN.SDAE object at 0x30fcb50>, depth=2, datafiles=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_labels_1.pkl'))...
ceylon.iro.umontreal.ca 2010-08-11 14:27:04.314182: 0:43:45.830000 user+sys, 0:58:26.780000 real, 74.88% usage, 618.39 MB
...done creating libsvm files
ceylon.iro.umontreal.ca 2010-08-11 14:27:10.122176: 0:43:51.520000 user+sys, 0:58:32.590000 real, 74.92% usage, 618.39 MB
Creating libsvm file '/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm' (model=<deepANN.ANN.SDAE object at 0x30fcb50>, depth=2, datafiles=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_labels_1.pkl'))...
ceylon.iro.umontreal.ca 2010-08-11 14:27:10.122718: 0:43:51.520000 user+sys, 0:58:32.590000 real, 74.92% usage, 618.39 MB
...done creating libsvm files
ceylon.iro.umontreal.ca 2010-08-11 14:27:15.901094: 0:43:57.200000 user+sys, 0:58:38.360000 real, 74.96% usage, 618.39 MB
Starting SVM validation for 100 examples (numrums=20, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm, PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211, MAXSTEPS=20, STEPFACTOR=10.000000, INITIALC=0.010000)...
ceylon.iro.umontreal.ca 2010-08-11 14:27:15.901634: 0:43:57.200000 user+sys, 0:58:38.370000 real, 74.96% usage, 618.39 MB
		Training SVM with C=0.010000, nbinputs=100, numruns=20
		Training SVM with C=0.100000, nbinputs=100, numruns=20
	testerr[Cnew 0.100000] = 56.020000 > testerr[Ccurrent 0.010000] = 54.760000
	Cbest <= 0.010000, testerr[Cbest] = 54.760000
	REVERSE: Cstepfactor is now 0.316228, Ccurrent remains 0.010000, Cnew is now 0.003162
		Training SVM with C=0.003162, nbinputs=100, numruns=20
	testerr[Cnew 0.003162] = 55.020000 > testerr[Ccurrent 0.010000] = 54.760000
	REVERSE: Cstepfactor is now 1.778279, Ccurrent remains 0.010000, Cnew is now 0.017783
		Training SVM with C=0.017783, nbinputs=100, numruns=20
	testerr[Cnew 0.017783] = 55.050000 > testerr[Ccurrent 0.010000] = 54.760000
	REVERSE: Cstepfactor is now 0.749894, Ccurrent remains 0.010000, Cnew is now 0.007499
		Training SVM with C=0.007499, nbinputs=100, numruns=20
	testerr[Cnew 0.007499] = 55.965000 > testerr[Ccurrent 0.010000] = 54.760000
	REVERSE: Cstepfactor is now 1.154782, Ccurrent remains 0.010000, Cnew is now 0.011548
		Training SVM with C=0.011548, nbinputs=100, numruns=20
	testerr[Cnew 0.011548] = 56.150000 > testerr[Ccurrent 0.010000] = 54.760000
	REVERSE: Cstepfactor is now 0.930572, Ccurrent remains 0.010000, Cnew is now 0.009306
		Training SVM with C=0.009306, nbinputs=100, numruns=20
	testerr[Cnew 0.009306] = 55.490000 > testerr[Ccurrent 0.010000] = 54.760000
	REVERSE: Cstepfactor is now 1.036633, Ccurrent remains 0.010000, Cnew is now 0.010366
		Training SVM with C=0.010366, nbinputs=100, numruns=20
	testerr[Cnew 0.010366] = 54.365000 < testerr[Ccurrent 0.010000] = 54.760000
	NEW BEST: Cbest <= 0.010366, testerr[Cbest] = 54.365000
	PROCEED: Cstepfactor remains 1.036633, Ccurrent is now 0.010366, Cnew is now 0.010746
		Training SVM with C=0.010746, nbinputs=100, numruns=20
	testerr[Cnew 0.010746] = 55.550000 > testerr[Ccurrent 0.010366] = 54.365000
	REVERSE: Cstepfactor is now 0.982172, Ccurrent remains 0.010366, Cnew is now 0.010182
		Training SVM with C=0.010182, nbinputs=100, numruns=20
	testerr[Cnew 0.010182] = 55.480000 > testerr[Ccurrent 0.010366] = 54.365000
	REVERSE: Cstepfactor is now 1.009035, Ccurrent remains 0.010366, Cnew is now 0.010460
		Training SVM with C=0.010460, nbinputs=100, numruns=20
	testerr[Cnew 0.010460] = 54.540000 > testerr[Ccurrent 0.010366] = 54.365000
	REVERSE: Cstepfactor is now 0.995513, Ccurrent remains 0.010366, Cnew is now 0.010320
		Training SVM with C=0.010320, nbinputs=100, numruns=20
	testerr[Cnew 0.010320] = 54.600000 > testerr[Ccurrent 0.010366] = 54.365000
	REVERSE: Cstepfactor is now 1.002251, Ccurrent remains 0.010366, Cnew is now 0.010390
		Training SVM with C=0.010390, nbinputs=100, numruns=20
	testerr[Cnew 0.010390] = 53.740000 < testerr[Ccurrent 0.010366] = 54.365000
	NEW BEST: Cbest <= 0.010390, testerr[Cbest] = 53.740000
	PROCEED: Cstepfactor remains 1.002251, Ccurrent is now 0.010390, Cnew is now 0.010413
		Training SVM with C=0.010413, nbinputs=100, numruns=20
	testerr[Cnew 0.010413] = 54.290000 > testerr[Ccurrent 0.010390] = 53.740000
	REVERSE: Cstepfactor is now 0.998876, Ccurrent remains 0.010390, Cnew is now 0.010378
		Training SVM with C=0.010378, nbinputs=100, numruns=20
	testerr[Cnew 0.010378] = 55.185000 > testerr[Ccurrent 0.010390] = 53.740000
	REVERSE: Cstepfactor is now 1.000562, Ccurrent remains 0.010390, Cnew is now 0.010396
		Training SVM with C=0.010396, nbinputs=100, numruns=20
	testerr[Cnew 0.010396] = 54.165000 > testerr[Ccurrent 0.010390] = 53.740000
	REVERSE: Cstepfactor is now 0.999719, Ccurrent remains 0.010390, Cnew is now 0.010387
		Training SVM with C=0.010387, nbinputs=100, numruns=20
	testerr[Cnew 0.010387] = 55.065000 > testerr[Ccurrent 0.010390] = 53.740000
	REVERSE: Cstepfactor is now 1.000141, Ccurrent remains 0.010390, Cnew is now 0.010391
		Training SVM with C=0.010391, nbinputs=100, numruns=20
	testerr[Cnew 0.010391] = 54.615000 > testerr[Ccurrent 0.010390] = 53.740000
	REVERSE: Cstepfactor is now 0.999930, Ccurrent remains 0.010390, Cnew is now 0.010389
		Training SVM with C=0.010389, nbinputs=100, numruns=20
	testerr[Cnew 0.010389] = 55.560000 > testerr[Ccurrent 0.010390] = 53.740000
	REVERSE: Cstepfactor is now 1.000035, Ccurrent remains 0.010390, Cnew is now 0.010390
		Training SVM with C=0.010390, nbinputs=100, numruns=20
	testerr[Cnew 0.010390] = 53.500000 < testerr[Ccurrent 0.010390] = 53.740000
	NEW BEST: Cbest <= 0.010390, testerr[Cbest] = 53.500000
	PROCEED: Cstepfactor remains 1.000035, Ccurrent is now 0.010390, Cnew is now 0.010390
	testerr[C 0.003162] = 55.020000 
	testerr[C 0.007499] = 55.965000 
	testerr[C 0.009306] = 55.490000 
	testerr[C 0.010000] = 54.760000 
	testerr[C 0.010182] = 55.480000 
	testerr[C 0.010320] = 54.600000 
	testerr[C 0.010366] = 54.365000 
	testerr[C 0.010378] = 55.185000 
	testerr[C 0.010387] = 55.065000 
	testerr[C 0.010389] = 55.560000 
	testerr[C 0.010390] = 53.740000 
	testerr[C 0.010390] = 53.500000  *best* (testerr = 53.500000, testerrdev = 2.621450, trainerr = 5.600000, trainerrdev = 2.034700)
	testerr[C 0.010391] = 54.615000 
	testerr[C 0.010396] = 54.165000 
	testerr[C 0.010413] = 54.290000 
	testerr[C 0.010460] = 54.540000 
	testerr[C 0.010746] = 55.550000 
	testerr[C 0.011548] = 56.150000 
	testerr[C 0.017783] = 55.050000 
	testerr[C 0.100000] = 56.020000 
...done with SVM validation for 100 examples (numrums=20, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm)...
ceylon.iro.umontreal.ca 2010-08-11 14:27:51.590325: 0:43:57.290000 user+sys, 0:59:14.050000 real, 74.21% usage, 618.39 MB
Starting SVM validation for 1000 examples (numrums=10, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm, PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211, MAXSTEPS=20, STEPFACTOR=10.000000, INITIALC=0.010000)...
ceylon.iro.umontreal.ca 2010-08-11 14:27:51.590690: 0:43:57.290000 user+sys, 0:59:14.050000 real, 74.21% usage, 618.39 MB
		Training SVM with C=0.010000, nbinputs=1000, numruns=10
		Training SVM with C=0.100000, nbinputs=1000, numruns=10
	testerr[Cnew 0.100000] = 52.950000 > testerr[Ccurrent 0.010000] = 50.630000
	Cbest <= 0.010000, testerr[Cbest] = 50.630000
	REVERSE: Cstepfactor is now 0.316228, Ccurrent remains 0.010000, Cnew is now 0.003162
		Training SVM with C=0.003162, nbinputs=1000, numruns=10
	testerr[Cnew 0.003162] = 46.560000 < testerr[Ccurrent 0.010000] = 50.630000
	NEW BEST: Cbest <= 0.003162, testerr[Cbest] = 46.560000
	PROCEED: Cstepfactor remains 0.316228, Ccurrent is now 0.003162, Cnew is now 0.001000
		Training SVM with C=0.001000, nbinputs=1000, numruns=10
	testerr[Cnew 0.001000] = 47.390000 > testerr[Ccurrent 0.003162] = 46.560000
	REVERSE: Cstepfactor is now 1.778279, Ccurrent remains 0.003162, Cnew is now 0.005623
		Training SVM with C=0.005623, nbinputs=1000, numruns=10
	testerr[Cnew 0.005623] = 48.270000 > testerr[Ccurrent 0.003162] = 46.560000
	REVERSE: Cstepfactor is now 0.749894, Ccurrent remains 0.003162, Cnew is now 0.002371
		Training SVM with C=0.002371, nbinputs=1000, numruns=10
	testerr[Cnew 0.002371] = 46.180000 < testerr[Ccurrent 0.003162] = 46.560000
	NEW BEST: Cbest <= 0.002371, testerr[Cbest] = 46.180000
	PROCEED: Cstepfactor remains 0.749894, Ccurrent is now 0.002371, Cnew is now 0.001778
		Training SVM with C=0.001778, nbinputs=1000, numruns=10
	testerr[Cnew 0.001778] = 46.870000 > testerr[Ccurrent 0.002371] = 46.180000
	REVERSE: Cstepfactor is now 1.154782, Ccurrent remains 0.002371, Cnew is now 0.002738
		Training SVM with C=0.002738, nbinputs=1000, numruns=10
	testerr[Cnew 0.002738] = 46.350000 > testerr[Ccurrent 0.002371] = 46.180000
	REVERSE: Cstepfactor is now 0.930572, Ccurrent remains 0.002371, Cnew is now 0.002207
		Training SVM with C=0.002207, nbinputs=1000, numruns=10
	testerr[Cnew 0.002207] = 46.540000 > testerr[Ccurrent 0.002371] = 46.180000
	REVERSE: Cstepfactor is now 1.036633, Ccurrent remains 0.002371, Cnew is now 0.002458
		Training SVM with C=0.002458, nbinputs=1000, numruns=10
	testerr[Cnew 0.002458] = 46.260000 > testerr[Ccurrent 0.002371] = 46.180000
	REVERSE: Cstepfactor is now 0.982172, Ccurrent remains 0.002371, Cnew is now 0.002329
		Training SVM with C=0.002329, nbinputs=1000, numruns=10
	testerr[Cnew 0.002329] = 46.360000 > testerr[Ccurrent 0.002371] = 46.180000
	REVERSE: Cstepfactor is now 1.009035, Ccurrent remains 0.002371, Cnew is now 0.002393
		Training SVM with C=0.002393, nbinputs=1000, numruns=10
	testerr[Cnew 0.002393] = 46.150000 < testerr[Ccurrent 0.002371] = 46.180000
	NEW BEST: Cbest <= 0.002393, testerr[Cbest] = 46.150000
	PROCEED: Cstepfactor remains 1.009035, Ccurrent is now 0.002393, Cnew is now 0.002414
		Training SVM with C=0.002414, nbinputs=1000, numruns=10
	testerr[Cnew 0.002414] = 46.200000 > testerr[Ccurrent 0.002393] = 46.150000
	REVERSE: Cstepfactor is now 0.995513, Ccurrent remains 0.002393, Cnew is now 0.002382
		Training SVM with C=0.002382, nbinputs=1000, numruns=10
	testerr[Cnew 0.002382] = 46.150000 > testerr[Ccurrent 0.002393] = 46.150000
	REVERSE: Cstepfactor is now 1.002251, Ccurrent remains 0.002393, Cnew is now 0.002398
		Training SVM with C=0.002398, nbinputs=1000, numruns=10
	testerr[Cnew 0.002398] = 46.260000 > testerr[Ccurrent 0.002393] = 46.150000
	REVERSE: Cstepfactor is now 0.998876, Ccurrent remains 0.002393, Cnew is now 0.002390
		Training SVM with C=0.002390, nbinputs=1000, numruns=10
	testerr[Cnew 0.002390] = 46.350000 > testerr[Ccurrent 0.002393] = 46.150000
	REVERSE: Cstepfactor is now 1.000562, Ccurrent remains 0.002393, Cnew is now 0.002394
		Training SVM with C=0.002394, nbinputs=1000, numruns=10
	testerr[Cnew 0.002394] = 46.150000 > testerr[Ccurrent 0.002393] = 46.150000
	REVERSE: Cstepfactor is now 0.999719, Ccurrent remains 0.002393, Cnew is now 0.002392
		Training SVM with C=0.002392, nbinputs=1000, numruns=10
	testerr[Cnew 0.002392] = 46.290000 > testerr[Ccurrent 0.002393] = 46.150000
	REVERSE: Cstepfactor is now 1.000141, Ccurrent remains 0.002393, Cnew is now 0.002393
		Training SVM with C=0.002393, nbinputs=1000, numruns=10
	testerr[Cnew 0.002393] = 46.300000 > testerr[Ccurrent 0.002393] = 46.150000
	REVERSE: Cstepfactor is now 0.999930, Ccurrent remains 0.002393, Cnew is now 0.002393
		Training SVM with C=0.002393, nbinputs=1000, numruns=10
	testerr[Cnew 0.002393] = 46.260000 > testerr[Ccurrent 0.002393] = 46.150000
	REVERSE: Cstepfactor is now 1.000035, Ccurrent remains 0.002393, Cnew is now 0.002393
	testerr[C 0.001000] = 47.390000 
	testerr[C 0.001778] = 46.870000 
	testerr[C 0.002207] = 46.540000 
	testerr[C 0.002329] = 46.360000 
	testerr[C 0.002371] = 46.180000 
	testerr[C 0.002382] = 46.150000 
	testerr[C 0.002390] = 46.350000 
	testerr[C 0.002392] = 46.290000 
	testerr[C 0.002393] = 46.260000 
	testerr[C 0.002393] = 46.150000  *best* (testerr = 46.150000, testerrdev = 0.304138, trainerr = 31.060000, trainerrdev = 0.185472)
	testerr[C 0.002393] = 46.300000 
	testerr[C 0.002394] = 46.150000 
	testerr[C 0.002398] = 46.260000 
	testerr[C 0.002414] = 46.200000 
	testerr[C 0.002458] = 46.260000 
	testerr[C 0.002738] = 46.350000 
	testerr[C 0.003162] = 46.560000 
	testerr[C 0.005623] = 48.270000 
	testerr[C 0.010000] = 50.630000 
	testerr[C 0.100000] = 52.950000 
...done with SVM validation for 1000 examples (numrums=10, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm)...
ceylon.iro.umontreal.ca 2010-08-11 14:29:42.804316: 0:43:57.370000 user+sys, 1:01:05.250000 real, 71.96% usage, 618.39 MB
Starting SVM validation for 10000 examples (numrums=1, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm, PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211, MAXSTEPS=20, STEPFACTOR=10.000000, INITIALC=0.010000)...
ceylon.iro.umontreal.ca 2010-08-11 14:29:42.804674: 0:43:57.370000 user+sys, 1:01:05.250000 real, 71.96% usage, 618.39 MB
		Training SVM with C=0.010000, nbinputs=10000, numruns=1
		Training SVM with C=0.100000, nbinputs=10000, numruns=1
	testerr[Cnew 0.100000] = 53.100000 > testerr[Ccurrent 0.010000] = 50.400000
	Cbest <= 0.010000, testerr[Cbest] = 50.400000
	REVERSE: Cstepfactor is now 0.316228, Ccurrent remains 0.010000, Cnew is now 0.003162
		Training SVM with C=0.003162, nbinputs=10000, numruns=1
	testerr[Cnew 0.003162] = 46.600000 < testerr[Ccurrent 0.010000] = 50.400000
	NEW BEST: Cbest <= 0.003162, testerr[Cbest] = 46.600000
	PROCEED: Cstepfactor remains 0.316228, Ccurrent is now 0.003162, Cnew is now 0.001000
		Training SVM with C=0.001000, nbinputs=10000, numruns=1
	testerr[Cnew 0.001000] = 47.300000 > testerr[Ccurrent 0.003162] = 46.600000
	REVERSE: Cstepfactor is now 1.778279, Ccurrent remains 0.003162, Cnew is now 0.005623
		Training SVM with C=0.005623, nbinputs=10000, numruns=1
	testerr[Cnew 0.005623] = 48.200000 > testerr[Ccurrent 0.003162] = 46.600000
	REVERSE: Cstepfactor is now 0.749894, Ccurrent remains 0.003162, Cnew is now 0.002371
		Training SVM with C=0.002371, nbinputs=10000, numruns=1
	testerr[Cnew 0.002371] = 46.300000 < testerr[Ccurrent 0.003162] = 46.600000
	NEW BEST: Cbest <= 0.002371, testerr[Cbest] = 46.300000
	PROCEED: Cstepfactor remains 0.749894, Ccurrent is now 0.002371, Cnew is now 0.001778
		Training SVM with C=0.001778, nbinputs=10000, numruns=1
	testerr[Cnew 0.001778] = 47.000000 > testerr[Ccurrent 0.002371] = 46.300000
	REVERSE: Cstepfactor is now 1.154782, Ccurrent remains 0.002371, Cnew is now 0.002738
		Training SVM with C=0.002738, nbinputs=10000, numruns=1
	testerr[Cnew 0.002738] = 46.600000 > testerr[Ccurrent 0.002371] = 46.300000
	REVERSE: Cstepfactor is now 0.930572, Ccurrent remains 0.002371, Cnew is now 0.002207
		Training SVM with C=0.002207, nbinputs=10000, numruns=1
	testerr[Cnew 0.002207] = 47.100000 > testerr[Ccurrent 0.002371] = 46.300000
	REVERSE: Cstepfactor is now 1.036633, Ccurrent remains 0.002371, Cnew is now 0.002458
		Training SVM with C=0.002458, nbinputs=10000, numruns=1
	testerr[Cnew 0.002458] = 46.300000 > testerr[Ccurrent 0.002371] = 46.300000
	REVERSE: Cstepfactor is now 0.982172, Ccurrent remains 0.002371, Cnew is now 0.002329
		Training SVM with C=0.002329, nbinputs=10000, numruns=1
	testerr[Cnew 0.002329] = 46.200000 < testerr[Ccurrent 0.002371] = 46.300000
	NEW BEST: Cbest <= 0.002329, testerr[Cbest] = 46.200000
	PROCEED: Cstepfactor remains 0.982172, Ccurrent is now 0.002329, Cnew is now 0.002288
		Training SVM with C=0.002288, nbinputs=10000, numruns=1
	testerr[Cnew 0.002288] = 46.400000 > testerr[Ccurrent 0.002329] = 46.200000
	REVERSE: Cstepfactor is now 1.009035, Ccurrent remains 0.002329, Cnew is now 0.002350
		Training SVM with C=0.002350, nbinputs=10000, numruns=1
	testerr[Cnew 0.002350] = 46.000000 < testerr[Ccurrent 0.002329] = 46.200000
	NEW BEST: Cbest <= 0.002350, testerr[Cbest] = 46.000000
	PROCEED: Cstepfactor remains 1.009035, Ccurrent is now 0.002350, Cnew is now 0.002371
		Training SVM with C=0.002371, nbinputs=10000, numruns=1
	testerr[Cnew 0.002371] = 46.300000 > testerr[Ccurrent 0.002350] = 46.000000
	REVERSE: Cstepfactor is now 0.995513, Ccurrent remains 0.002350, Cnew is now 0.002340
		Training SVM with C=0.002340, nbinputs=10000, numruns=1
	testerr[Cnew 0.002340] = 46.100000 > testerr[Ccurrent 0.002350] = 46.000000
	REVERSE: Cstepfactor is now 1.002251, Ccurrent remains 0.002350, Cnew is now 0.002355
		Training SVM with C=0.002355, nbinputs=10000, numruns=1
	testerr[Cnew 0.002355] = 46.400000 > testerr[Ccurrent 0.002350] = 46.000000
	REVERSE: Cstepfactor is now 0.998876, Ccurrent remains 0.002350, Cnew is now 0.002347
		Training SVM with C=0.002347, nbinputs=10000, numruns=1
	testerr[Cnew 0.002347] = 46.100000 > testerr[Ccurrent 0.002350] = 46.000000
	REVERSE: Cstepfactor is now 1.000562, Ccurrent remains 0.002350, Cnew is now 0.002351
		Training SVM with C=0.002351, nbinputs=10000, numruns=1
	testerr[Cnew 0.002351] = 46.300000 > testerr[Ccurrent 0.002350] = 46.000000
	REVERSE: Cstepfactor is now 0.999719, Ccurrent remains 0.002350, Cnew is now 0.002349
		Training SVM with C=0.002349, nbinputs=10000, numruns=1
	testerr[Cnew 0.002349] = 46.000000 > testerr[Ccurrent 0.002350] = 46.000000
	REVERSE: Cstepfactor is now 1.000141, Ccurrent remains 0.002350, Cnew is now 0.002350
		Training SVM with C=0.002350, nbinputs=10000, numruns=1
	testerr[Cnew 0.002350] = 46.300000 > testerr[Ccurrent 0.002350] = 46.000000
	REVERSE: Cstepfactor is now 0.999930, Ccurrent remains 0.002350, Cnew is now 0.002350
	testerr[C 0.001000] = 47.300000 
	testerr[C 0.001778] = 47.000000 
	testerr[C 0.002207] = 47.100000 
	testerr[C 0.002288] = 46.400000 
	testerr[C 0.002329] = 46.200000 
	testerr[C 0.002340] = 46.100000 
	testerr[C 0.002347] = 46.100000 
	testerr[C 0.002349] = 46.000000 
	testerr[C 0.002350] = 46.000000  *best* (testerr = 46.000000, testerrdev = 0.000000, trainerr = 31.200000, trainerrdev = 0.000000)
	testerr[C 0.002350] = 46.300000 
	testerr[C 0.002351] = 46.300000 
	testerr[C 0.002355] = 46.400000 
	testerr[C 0.002371] = 46.300000 
	testerr[C 0.002371] = 46.300000 
	testerr[C 0.002458] = 46.300000 
	testerr[C 0.002738] = 46.600000 
	testerr[C 0.003162] = 46.600000 
	testerr[C 0.005623] = 48.200000 
	testerr[C 0.010000] = 50.400000 
	testerr[C 0.100000] = 53.100000 
...done with SVM validation for 10000 examples (numrums=1, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm)...
ceylon.iro.umontreal.ca 2010-08-11 14:30:01.198957: 0:43:57.460000 user+sys, 1:01:23.640000 real, 71.60% usage, 618.39 MB
		----  Encoding  layer #1 ----
			**** DenseLayer.__init__ ****
			tag =  enc1
			inp =  inp
			n_inp =  5000
			n_out =  1000
			act =  tanh
			noise =  binomial_NLP
			out =  outenc1
			params (gradients) =  [Wenc1, benc1]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc1
			allocW, allocb, allocmask =  False False False
		----  Encoding  layer #2 ----
			**** DenseLayer.__init__ ****
			tag =  enc2
			inp =  outenc1
			n_inp =  1000
			n_out =  1000
			act =  tanh
			noise =  binomial
			out =  outenc2
			params (gradients) =  [Wenc2, benc2]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc2
			allocW, allocb, allocmask =  False False False
		----  Encoding  layer #3 ----
			**** DenseLayer.__init__ ****
			tag =  enc3
			inp =  outenc2
			n_inp =  1000
			n_out =  1000
			act =  rectifier
			noise =  binomial
			out =  outenc3
			params (gradients) =  [Wenc3, benc3]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc3
			allocW, allocb, allocmask =  False False False
MRG_RandomStreams Can't determine #streams from size (Shape.0), guessing 30*256
	---- Auxiliary Layer ----
			**** DenseLayer.__init__ ****
			tag =  aux0
			inp =  outenc3
			n_inp =  1000
			n_out =  1000
			act =  sigmoid
			noise =  None
			out =  outaux0
			params (gradients) =  [Waux0, baux0]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  None
			allocW, allocb, allocmask =  False False ones
	**** SDAE ****
	depth =  3
	mode =  Aux
	depth_min, depth_max, update_type =  0 , 3 , special
	inp, n_inp =  inp , 5000
	n_hid =  [1000, 1000, 1000]
	layertype =  [<class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>]
	act =  ['tanh', 'tanh', 'rectifier']
	noise, noise_lvl =  ['binomial_NLP', 'binomial', 'binomial'] , 0.3
	tie =  [True, True, True]
	maskbool =  [None, None, None]
	n_out, outtype =  5 , <class 'deepANN.Logistic_regression.LogisticRegression'>
	lr =  0.0001
	sup_scaling, unsup_scaling, aux_scaling  =  None None 1.0
	regularization, wdreg  =  [0.0, 0.0, 0.0, 0.0] , l2
	sparsity, spreg =  [0.0, 0.0, 0.01] , l1
	params, wd, sp =  [Wenc3, benc3, Waux0, baux0] , [] , [Elemwise{mul,no_inplace}.0]
	bbbool, hessscal =  None , None
	aux, auxtarget, aux_one_sided, auxdepth, auxregularization =  True , auxtarget , True , 0 , False
	auxact, auxn_out, auxwdreg =  sigmoid , 1000 , l2
##########  TEST ############ EPOCH :  1
CURRENT RECONSTRUCTION ERROR (is this on test or train?):  550.240707764
CURRENT 100 SVM ERROR:  (0.010390030472626858, 53.5, 2.6214499999999998, 5.5999999999999996, 2.0347)
CURRENT 1000 SVM ERROR:  (0.0023927991734281374, 46.149999999999999, 0.30413800000000002, 31.059999999999999, 0.185472)
CURRENT 10000 SVM ERROR:  (0.0023501400846134891, 46.0, 0.0, 31.199999999999999, 0.0)
ceylon.iro.umontreal.ca 2010-08-11 14:30:09.229993: 0:44:05.370000 user+sys, 1:01:31.670000 real, 71.66% usage, 618.39 MB
params.pkl saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth3pre1
Wenc1 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth3pre1/Layer1_W.pkl
benc1 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth3pre1/Layer1_b.pkl
maskenc1 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth3pre1/Layer1_mask.pkl
Wenc2 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth3pre1/Layer2_W.pkl
benc2 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth3pre1/Layer2_b.pkl
maskenc2 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth3pre1/Layer2_mask.pkl
Wenc3 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth3pre1/Layer3_W.pkl
benc3 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth3pre1/Layer3_b.pkl
maskenc3 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth3pre1/Layer3_mask.pkl
Waux0 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth3pre1/Layeraux_W.pkl
baux0 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth3pre1/Layeraux_b.pkl
maskaux0 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth3pre1/Layeraux_mask.pkl
W saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth3pre1/Layerout_W.pkl
b saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth3pre1/Layerout_b.pkl
saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth3pre1
...done validating (err={1000: {0: (0.0034058581998212207, 47.990000000000002, 0.280891, 28.100000000000001, 0.184391), 1: (0.0023927991734281374, 46.149999999999999, 0.30413800000000002, 31.059999999999999, 0.185472)}, 10000: {0: (0.0029693148482024781, 47.700000000000003, 0.0, 29.300000000000001, 0.0), 1: (0.0023501400846134891, 46.0, 0.0, 31.199999999999999, 0.0)}, 100: {0: (0.020535250264571463, 55.340000000000003, 3.1582300000000001, 2.8999999999999999, 1.6093500000000001), 1: (0.010390030472626858, 53.5, 2.6214499999999998, 5.5999999999999996, 2.0347)}},epoch=1,model=<deepANN.ANN.SDAE object at 0x30fcb50>,depth=2,ACT=['tanh', 'tanh', 'rectifier'],LR=0.0001,NOISE_LVL=0.3,BATCHSIZE=10,train=<CudaNdarrayType(float32, matrix)>,datatrain=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_labels_1.pkl'),datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm,datatest=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_labels_1.pkl'),datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm,VALIDATION_TRAININGSIZE=[100, 1000, 10000],VALIDATION_RUNS_FOR_EACH_TRAININGSIZE={'100': 20, '10000': 1, '1000': 10},PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211)
ceylon.iro.umontreal.ca 2010-08-11 14:30:09.745112: 0:44:05.450000 user+sys, 1:01:32.180000 real, 71.65% usage, 625.49 MB
File: 1 22.0372889042 ----
ceylon.iro.umontreal.ca 2010-08-11 14:30:31.782820: 0:44:27.460000 user+sys, 1:01:54.220000 real, 71.82% usage, 625.49 MB
File: 2 22.0078699589 ----
ceylon.iro.umontreal.ca 2010-08-11 14:30:53.791127: 0:44:49.430000 user+sys, 1:02:16.220000 real, 71.98% usage, 625.49 MB
File: 3 22.0072829723 ----
ceylon.iro.umontreal.ca 2010-08-11 14:31:15.798859: 0:45:11.410000 user+sys, 1:02:38.230000 real, 72.15% usage, 625.49 MB
File: 4 22.0084428787 ----
ceylon.iro.umontreal.ca 2010-08-11 14:31:37.807727: 0:45:33.390000 user+sys, 1:03:00.230000 real, 72.31% usage, 625.49 MB
File: 5 22.0642089844 ----
ceylon.iro.umontreal.ca 2010-08-11 14:31:59.872378: 0:45:55.420000 user+sys, 1:03:22.290000 real, 72.47% usage, 625.49 MB
File: 6 22.3436598778 ----
ceylon.iro.umontreal.ca 2010-08-11 14:32:22.216498: 0:46:17.640000 user+sys, 1:03:44.630000 real, 72.63% usage, 625.49 MB
File: 7 22.2773730755 ----
ceylon.iro.umontreal.ca 2010-08-11 14:32:44.494389: 0:46:39.810000 user+sys, 1:04:06.910000 real, 72.78% usage, 625.49 MB
File: 8 22.3420641422 ----
ceylon.iro.umontreal.ca 2010-08-11 14:33:06.837036: 0:47:01.940000 user+sys, 1:04:29.250000 real, 72.93% usage, 625.49 MB
File: 9 22.5481898785 ----
ceylon.iro.umontreal.ca 2010-08-11 14:33:29.385658: 0:47:24.100000 user+sys, 1:04:51.790000 real, 73.08% usage, 625.49 MB
File: 10 22.2419369221 ----
ceylon.iro.umontreal.ca 2010-08-11 14:33:51.628022: 0:47:46.190000 user+sys, 1:05:14.030000 real, 73.23% usage, 625.49 MB
File: 11 22.2351119518 ----
ceylon.iro.umontreal.ca 2010-08-11 14:34:13.863581: 0:48:08.280000 user+sys, 1:05:36.260000 real, 73.38% usage, 625.49 MB
File: 12 22.2036180496 ----
ceylon.iro.umontreal.ca 2010-08-11 14:34:36.067616: 0:48:30.350000 user+sys, 1:05:58.460000 real, 73.52% usage, 625.49 MB
File: 13 22.305410862 ----
ceylon.iro.umontreal.ca 2010-08-11 14:34:58.373475: 0:48:52.390000 user+sys, 1:06:20.770000 real, 73.66% usage, 625.49 MB
File: 14 21.8780519962 ----
ceylon.iro.umontreal.ca 2010-08-11 14:35:20.251976: 0:49:14.250000 user+sys, 1:06:42.640000 real, 73.81% usage, 625.49 MB
File: 15 20.8903090954 ----
ceylon.iro.umontreal.ca 2010-08-11 14:35:41.142722: 0:49:35.110000 user+sys, 1:07:03.530000 real, 73.94% usage, 625.49 MB
...finished training epoch #2 of 3 (66.67%)
ceylon.iro.umontreal.ca 2010-08-11 14:35:41.143045: 0:49:35.110000 user+sys, 1:07:03.530000 real, 73.94% usage, 625.49 MB
Validating (err={1000: {0: (0.0034058581998212207, 47.990000000000002, 0.280891, 28.100000000000001, 0.184391), 1: (0.0023927991734281374, 46.149999999999999, 0.30413800000000002, 31.059999999999999, 0.185472)}, 10000: {0: (0.0029693148482024781, 47.700000000000003, 0.0, 29.300000000000001, 0.0), 1: (0.0023501400846134891, 46.0, 0.0, 31.199999999999999, 0.0)}, 100: {0: (0.020535250264571463, 55.340000000000003, 3.1582300000000001, 2.8999999999999999, 1.6093500000000001), 1: (0.010390030472626858, 53.5, 2.6214499999999998, 5.5999999999999996, 2.0347)}},epoch=2,model=<deepANN.ANN.SDAE object at 0x30fcb50>,depth=2,ACT=['tanh', 'tanh', 'rectifier'],LR=0.0001,NOISE_LVL=0.3,BATCHSIZE=10,train=<CudaNdarrayType(float32, matrix)>,datatrain=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_labels_1.pkl'),datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm,datatest=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_labels_1.pkl'),datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm,VALIDATION_TRAININGSIZE=[100, 1000, 10000],VALIDATION_RUNS_FOR_EACH_TRAININGSIZE={'100': 20, '10000': 1, '1000': 10},PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211)...
ceylon.iro.umontreal.ca 2010-08-11 14:35:41.143490: 0:49:35.110000 user+sys, 1:07:03.530000 real, 73.94% usage, 625.49 MB
		----  Encoding  layer #1 ----
			**** DenseLayer.__init__ ****
			tag =  enc1
			inp =  inp
			n_inp =  5000
			n_out =  1000
			act =  tanh
			noise =  binomial_NLP
			out =  outenc1
			params (gradients) =  [Wenc1, benc1]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc1
			allocW, allocb, allocmask =  False False False
		----  Encoding  layer #2 ----
			**** DenseLayer.__init__ ****
			tag =  enc2
			inp =  outenc1
			n_inp =  1000
			n_out =  1000
			act =  tanh
			noise =  binomial
			out =  outenc2
			params (gradients) =  [Wenc2, benc2]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc2
			allocW, allocb, allocmask =  False False False
		----  Encoding  layer #3 ----
			**** DenseLayer.__init__ ****
			tag =  enc3
			inp =  outenc2
			n_inp =  1000
			n_out =  1000
			act =  rectifier
			noise =  binomial
			out =  outenc3
			params (gradients) =  [Wenc3, benc3]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc3
			allocW, allocb, allocmask =  False False False
	---- Auxiliary Layer ----
			**** DenseLayer.__init__ ****
			tag =  aux0
			inp =  outenc3
			n_inp =  1000
			n_out =  1000
			act =  sigmoid
			noise =  None
			out =  outaux0
			params (gradients) =  [Waux0, baux0]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  None
			allocW, allocb, allocmask =  False False ones
	**** SDAE ****
	depth =  3
	mode =  Aux
	depth_min, depth_max, update_type =  0 , 3 , special
	inp, n_inp =  inp , 5000
	n_hid =  [1000, 1000, 1000]
	layertype =  [<class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>]
	act =  ['tanh', 'tanh', 'rectifier']
	noise, noise_lvl =  ['binomial_NLP', 'binomial', 'binomial'] , None
	tie =  [True, True, True]
	maskbool =  [None, None, None]
	n_out, outtype =  5 , <class 'deepANN.Logistic_regression.LogisticRegression'>
	lr =  0.0001
	sup_scaling, unsup_scaling, aux_scaling  =  None None 1.0
	regularization, wdreg  =  [0.0, 0.0, 0.0, 0.0] , l2
	sparsity, spreg =  [0.0, 0.0, 0.01] , l1
	params, wd, sp =  [Wenc3, benc3, Waux0, baux0] , [] , [Elemwise{mul,no_inplace}.0]
	bbbool, hessscal =  None , None
	aux, auxtarget, aux_one_sided, auxdepth, auxregularization =  True , auxtarget , True , 0 , False
	auxact, auxn_out, auxwdreg =  sigmoid , 1000 , l2
Creating libsvm file '/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm' (model=<deepANN.ANN.SDAE object at 0x30fcb50>, depth=2, datafiles=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_labels_1.pkl'))...
ceylon.iro.umontreal.ca 2010-08-11 14:35:44.545869: 0:49:38.400000 user+sys, 1:07:06.930000 real, 73.96% usage, 625.49 MB
...done creating libsvm files
ceylon.iro.umontreal.ca 2010-08-11 14:35:51.001402: 0:49:44.750000 user+sys, 1:07:13.390000 real, 74.00% usage, 625.49 MB
Creating libsvm file '/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm' (model=<deepANN.ANN.SDAE object at 0x30fcb50>, depth=2, datafiles=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_labels_1.pkl'))...
ceylon.iro.umontreal.ca 2010-08-11 14:35:51.001978: 0:49:44.750000 user+sys, 1:07:13.390000 real, 74.00% usage, 625.49 MB
...done creating libsvm files
ceylon.iro.umontreal.ca 2010-08-11 14:35:57.456628: 0:49:51.080000 user+sys, 1:07:19.840000 real, 74.04% usage, 625.49 MB
Starting SVM validation for 100 examples (numrums=20, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm, PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211, MAXSTEPS=20, STEPFACTOR=10.000000, INITIALC=0.010000)...
ceylon.iro.umontreal.ca 2010-08-11 14:35:57.457208: 0:49:51.080000 user+sys, 1:07:19.840000 real, 74.04% usage, 625.49 MB
		Training SVM with C=0.010000, nbinputs=100, numruns=20
		Training SVM with C=0.100000, nbinputs=100, numruns=20
	testerr[Cnew 0.100000] = 57.965000 > testerr[Ccurrent 0.010000] = 56.335000
	Cbest <= 0.010000, testerr[Cbest] = 56.335000
	REVERSE: Cstepfactor is now 0.316228, Ccurrent remains 0.010000, Cnew is now 0.003162
		Training SVM with C=0.003162, nbinputs=100, numruns=20
	testerr[Cnew 0.003162] = 54.790000 < testerr[Ccurrent 0.010000] = 56.335000
	NEW BEST: Cbest <= 0.003162, testerr[Cbest] = 54.790000
	PROCEED: Cstepfactor remains 0.316228, Ccurrent is now 0.003162, Cnew is now 0.001000
		Training SVM with C=0.001000, nbinputs=100, numruns=20
	testerr[Cnew 0.001000] = 54.915000 > testerr[Ccurrent 0.003162] = 54.790000
	REVERSE: Cstepfactor is now 1.778279, Ccurrent remains 0.003162, Cnew is now 0.005623
		Training SVM with C=0.005623, nbinputs=100, numruns=20
	testerr[Cnew 0.005623] = 55.765000 > testerr[Ccurrent 0.003162] = 54.790000
	REVERSE: Cstepfactor is now 0.749894, Ccurrent remains 0.003162, Cnew is now 0.002371
		Training SVM with C=0.002371, nbinputs=100, numruns=20
	testerr[Cnew 0.002371] = 54.255000 < testerr[Ccurrent 0.003162] = 54.790000
	NEW BEST: Cbest <= 0.002371, testerr[Cbest] = 54.255000
	PROCEED: Cstepfactor remains 0.749894, Ccurrent is now 0.002371, Cnew is now 0.001778
		Training SVM with C=0.001778, nbinputs=100, numruns=20
	testerr[Cnew 0.001778] = 54.815000 > testerr[Ccurrent 0.002371] = 54.255000
	REVERSE: Cstepfactor is now 1.154782, Ccurrent remains 0.002371, Cnew is now 0.002738
		Training SVM with C=0.002738, nbinputs=100, numruns=20
	testerr[Cnew 0.002738] = 55.500000 > testerr[Ccurrent 0.002371] = 54.255000
	REVERSE: Cstepfactor is now 0.930572, Ccurrent remains 0.002371, Cnew is now 0.002207
		Training SVM with C=0.002207, nbinputs=100, numruns=20
	testerr[Cnew 0.002207] = 55.730000 > testerr[Ccurrent 0.002371] = 54.255000
	REVERSE: Cstepfactor is now 1.036633, Ccurrent remains 0.002371, Cnew is now 0.002458
		Training SVM with C=0.002458, nbinputs=100, numruns=20
	testerr[Cnew 0.002458] = 54.590000 > testerr[Ccurrent 0.002371] = 54.255000
	REVERSE: Cstepfactor is now 0.982172, Ccurrent remains 0.002371, Cnew is now 0.002329
		Training SVM with C=0.002329, nbinputs=100, numruns=20
	testerr[Cnew 0.002329] = 53.715000 < testerr[Ccurrent 0.002371] = 54.255000
	NEW BEST: Cbest <= 0.002329, testerr[Cbest] = 53.715000
	PROCEED: Cstepfactor remains 0.982172, Ccurrent is now 0.002329, Cnew is now 0.002288
		Training SVM with C=0.002288, nbinputs=100, numruns=20
	testerr[Cnew 0.002288] = 56.340000 > testerr[Ccurrent 0.002329] = 53.715000
	REVERSE: Cstepfactor is now 1.009035, Ccurrent remains 0.002329, Cnew is now 0.002350
		Training SVM with C=0.002350, nbinputs=100, numruns=20
	testerr[Cnew 0.002350] = 54.775000 > testerr[Ccurrent 0.002329] = 53.715000
	REVERSE: Cstepfactor is now 0.995513, Ccurrent remains 0.002329, Cnew is now 0.002319
		Training SVM with C=0.002319, nbinputs=100, numruns=20
	testerr[Cnew 0.002319] = 56.345000 > testerr[Ccurrent 0.002329] = 53.715000
	REVERSE: Cstepfactor is now 1.002251, Ccurrent remains 0.002329, Cnew is now 0.002334
		Training SVM with C=0.002334, nbinputs=100, numruns=20
	testerr[Cnew 0.002334] = 54.685000 > testerr[Ccurrent 0.002329] = 53.715000
	REVERSE: Cstepfactor is now 0.998876, Ccurrent remains 0.002329, Cnew is now 0.002326
		Training SVM with C=0.002326, nbinputs=100, numruns=20
	testerr[Cnew 0.002326] = 55.600000 > testerr[Ccurrent 0.002329] = 53.715000
	REVERSE: Cstepfactor is now 1.000562, Ccurrent remains 0.002329, Cnew is now 0.002330
		Training SVM with C=0.002330, nbinputs=100, numruns=20
	testerr[Cnew 0.002330] = 55.920000 > testerr[Ccurrent 0.002329] = 53.715000
	REVERSE: Cstepfactor is now 0.999719, Ccurrent remains 0.002329, Cnew is now 0.002328
		Training SVM with C=0.002328, nbinputs=100, numruns=20
	testerr[Cnew 0.002328] = 52.610000 < testerr[Ccurrent 0.002329] = 53.715000
	NEW BEST: Cbest <= 0.002328, testerr[Cbest] = 52.610000
	PROCEED: Cstepfactor remains 0.999719, Ccurrent is now 0.002328, Cnew is now 0.002328
		Training SVM with C=0.002328, nbinputs=100, numruns=20
	testerr[Cnew 0.002328] = 54.880000 > testerr[Ccurrent 0.002328] = 52.610000
	REVERSE: Cstepfactor is now 1.000141, Ccurrent remains 0.002328, Cnew is now 0.002329
		Training SVM with C=0.002329, nbinputs=100, numruns=20
	testerr[Cnew 0.002329] = 53.785000 > testerr[Ccurrent 0.002328] = 52.610000
	REVERSE: Cstepfactor is now 0.999930, Ccurrent remains 0.002328, Cnew is now 0.002328
	testerr[C 0.001000] = 54.915000 
	testerr[C 0.001778] = 54.815000 
	testerr[C 0.002207] = 55.730000 
	testerr[C 0.002288] = 56.340000 
	testerr[C 0.002319] = 56.345000 
	testerr[C 0.002326] = 55.600000 
	testerr[C 0.002328] = 54.880000 
	testerr[C 0.002328] = 52.610000  *best* (testerr = 52.610000, testerrdev = 1.814910, trainerr = 12.200000, trainerrdev = 3.828840)
	testerr[C 0.002329] = 53.785000 
	testerr[C 0.002329] = 53.715000 
	testerr[C 0.002330] = 55.920000 
	testerr[C 0.002334] = 54.685000 
	testerr[C 0.002350] = 54.775000 
	testerr[C 0.002371] = 54.255000 
	testerr[C 0.002458] = 54.590000 
	testerr[C 0.002738] = 55.500000 
	testerr[C 0.003162] = 54.790000 
	testerr[C 0.005623] = 55.765000 
	testerr[C 0.010000] = 56.335000 
	testerr[C 0.100000] = 57.965000 
...done with SVM validation for 100 examples (numrums=20, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm)...
ceylon.iro.umontreal.ca 2010-08-11 14:36:21.233307: 0:49:51.170000 user+sys, 1:07:43.610000 real, 73.61% usage, 625.49 MB
Starting SVM validation for 1000 examples (numrums=10, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm, PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211, MAXSTEPS=20, STEPFACTOR=10.000000, INITIALC=0.010000)...
ceylon.iro.umontreal.ca 2010-08-11 14:36:21.233692: 0:49:51.170000 user+sys, 1:07:43.610000 real, 73.61% usage, 625.49 MB
		Training SVM with C=0.010000, nbinputs=1000, numruns=10
		Training SVM with C=0.100000, nbinputs=1000, numruns=10
	testerr[Cnew 0.100000] = 54.140000 > testerr[Ccurrent 0.010000] = 49.950000
	Cbest <= 0.010000, testerr[Cbest] = 49.950000
	REVERSE: Cstepfactor is now 0.316228, Ccurrent remains 0.010000, Cnew is now 0.003162
		Training SVM with C=0.003162, nbinputs=1000, numruns=10
	testerr[Cnew 0.003162] = 47.140000 < testerr[Ccurrent 0.010000] = 49.950000
	NEW BEST: Cbest <= 0.003162, testerr[Cbest] = 47.140000
	PROCEED: Cstepfactor remains 0.316228, Ccurrent is now 0.003162, Cnew is now 0.001000
		Training SVM with C=0.001000, nbinputs=1000, numruns=10
	testerr[Cnew 0.001000] = 47.230000 > testerr[Ccurrent 0.003162] = 47.140000
	REVERSE: Cstepfactor is now 1.778279, Ccurrent remains 0.003162, Cnew is now 0.005623
		Training SVM with C=0.005623, nbinputs=1000, numruns=10
	testerr[Cnew 0.005623] = 48.900000 > testerr[Ccurrent 0.003162] = 47.140000
	REVERSE: Cstepfactor is now 0.749894, Ccurrent remains 0.003162, Cnew is now 0.002371
		Training SVM with C=0.002371, nbinputs=1000, numruns=10
	testerr[Cnew 0.002371] = 46.960000 < testerr[Ccurrent 0.003162] = 47.140000
	NEW BEST: Cbest <= 0.002371, testerr[Cbest] = 46.960000
	PROCEED: Cstepfactor remains 0.749894, Ccurrent is now 0.002371, Cnew is now 0.001778
		Training SVM with C=0.001778, nbinputs=1000, numruns=10
	testerr[Cnew 0.001778] = 46.620000 < testerr[Ccurrent 0.002371] = 46.960000
	NEW BEST: Cbest <= 0.001778, testerr[Cbest] = 46.620000
	PROCEED: Cstepfactor remains 0.749894, Ccurrent is now 0.001778, Cnew is now 0.001334
		Training SVM with C=0.001334, nbinputs=1000, numruns=10
	testerr[Cnew 0.001334] = 46.660000 > testerr[Ccurrent 0.001778] = 46.620000
	REVERSE: Cstepfactor is now 1.154782, Ccurrent remains 0.001778, Cnew is now 0.002054
		Training SVM with C=0.002054, nbinputs=1000, numruns=10
	testerr[Cnew 0.002054] = 46.960000 > testerr[Ccurrent 0.001778] = 46.620000
	REVERSE: Cstepfactor is now 0.930572, Ccurrent remains 0.001778, Cnew is now 0.001655
		Training SVM with C=0.001655, nbinputs=1000, numruns=10
	testerr[Cnew 0.001655] = 46.500000 < testerr[Ccurrent 0.001778] = 46.620000
	NEW BEST: Cbest <= 0.001655, testerr[Cbest] = 46.500000
	PROCEED: Cstepfactor remains 0.930572, Ccurrent is now 0.001655, Cnew is now 0.001540
		Training SVM with C=0.001540, nbinputs=1000, numruns=10
	testerr[Cnew 0.001540] = 46.660000 > testerr[Ccurrent 0.001655] = 46.500000
	REVERSE: Cstepfactor is now 1.036633, Ccurrent remains 0.001655, Cnew is now 0.001715
		Training SVM with C=0.001715, nbinputs=1000, numruns=10
	testerr[Cnew 0.001715] = 46.400000 < testerr[Ccurrent 0.001655] = 46.500000
	NEW BEST: Cbest <= 0.001715, testerr[Cbest] = 46.400000
	PROCEED: Cstepfactor remains 1.036633, Ccurrent is now 0.001715, Cnew is now 0.001778
	testerr[Cnew 0.001778] = 46.620000 > testerr[Ccurrent 0.001715] = 46.400000
	REVERSE: Cstepfactor is now 0.982172, Ccurrent remains 0.001715, Cnew is now 0.001685
		Training SVM with C=0.001685, nbinputs=1000, numruns=10
	testerr[Cnew 0.001685] = 46.540000 > testerr[Ccurrent 0.001715] = 46.400000
	REVERSE: Cstepfactor is now 1.009035, Ccurrent remains 0.001715, Cnew is now 0.001731
		Training SVM with C=0.001731, nbinputs=1000, numruns=10
	testerr[Cnew 0.001731] = 46.690000 > testerr[Ccurrent 0.001715] = 46.400000
	REVERSE: Cstepfactor is now 0.995513, Ccurrent remains 0.001715, Cnew is now 0.001708
		Training SVM with C=0.001708, nbinputs=1000, numruns=10
	testerr[Cnew 0.001708] = 46.610000 > testerr[Ccurrent 0.001715] = 46.400000
	REVERSE: Cstepfactor is now 1.002251, Ccurrent remains 0.001715, Cnew is now 0.001719
		Training SVM with C=0.001719, nbinputs=1000, numruns=10
	testerr[Cnew 0.001719] = 46.570000 > testerr[Ccurrent 0.001715] = 46.400000
	REVERSE: Cstepfactor is now 0.998876, Ccurrent remains 0.001715, Cnew is now 0.001714
		Training SVM with C=0.001714, nbinputs=1000, numruns=10
	testerr[Cnew 0.001714] = 46.450000 > testerr[Ccurrent 0.001715] = 46.400000
	REVERSE: Cstepfactor is now 1.000562, Ccurrent remains 0.001715, Cnew is now 0.001716
		Training SVM with C=0.001716, nbinputs=1000, numruns=10
	testerr[Cnew 0.001716] = 46.590000 > testerr[Ccurrent 0.001715] = 46.400000
	REVERSE: Cstepfactor is now 0.999719, Ccurrent remains 0.001715, Cnew is now 0.001715
		Training SVM with C=0.001715, nbinputs=1000, numruns=10
	testerr[Cnew 0.001715] = 46.690000 > testerr[Ccurrent 0.001715] = 46.400000
	REVERSE: Cstepfactor is now 1.000141, Ccurrent remains 0.001715, Cnew is now 0.001716
		Training SVM with C=0.001716, nbinputs=1000, numruns=10
	testerr[Cnew 0.001716] = 46.460000 > testerr[Ccurrent 0.001715] = 46.400000
	REVERSE: Cstepfactor is now 0.999930, Ccurrent remains 0.001715, Cnew is now 0.001715
	testerr[C 0.001000] = 47.230000 
	testerr[C 0.001334] = 46.660000 
	testerr[C 0.001540] = 46.660000 
	testerr[C 0.001655] = 46.500000 
	testerr[C 0.001685] = 46.540000 
	testerr[C 0.001708] = 46.610000 
	testerr[C 0.001714] = 46.450000 
	testerr[C 0.001715] = 46.690000 
	testerr[C 0.001715] = 46.400000  *best* (testerr = 46.400000, testerrdev = 0.204939, trainerr = 32.240000, trainerrdev = 0.210713)
	testerr[C 0.001716] = 46.460000 
	testerr[C 0.001716] = 46.590000 
	testerr[C 0.001719] = 46.570000 
	testerr[C 0.001731] = 46.690000 
	testerr[C 0.001778] = 46.620000 
	testerr[C 0.002054] = 46.960000 
	testerr[C 0.002371] = 46.960000 
	testerr[C 0.003162] = 47.140000 
	testerr[C 0.005623] = 48.900000 
	testerr[C 0.010000] = 49.950000 
	testerr[C 0.100000] = 54.140000 
...done with SVM validation for 1000 examples (numrums=10, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm)...
ceylon.iro.umontreal.ca 2010-08-11 14:38:03.721360: 0:49:51.260000 user+sys, 1:09:26.090000 real, 71.80% usage, 625.49 MB
Starting SVM validation for 10000 examples (numrums=1, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm, PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211, MAXSTEPS=20, STEPFACTOR=10.000000, INITIALC=0.010000)...
ceylon.iro.umontreal.ca 2010-08-11 14:38:03.721746: 0:49:51.260000 user+sys, 1:09:26.090000 real, 71.80% usage, 625.49 MB
		Training SVM with C=0.010000, nbinputs=10000, numruns=1
		Training SVM with C=0.100000, nbinputs=10000, numruns=1
	testerr[Cnew 0.100000] = 54.000000 > testerr[Ccurrent 0.010000] = 49.400000
	Cbest <= 0.010000, testerr[Cbest] = 49.400000
	REVERSE: Cstepfactor is now 0.316228, Ccurrent remains 0.010000, Cnew is now 0.003162
		Training SVM with C=0.003162, nbinputs=10000, numruns=1
	testerr[Cnew 0.003162] = 47.200000 < testerr[Ccurrent 0.010000] = 49.400000
	NEW BEST: Cbest <= 0.003162, testerr[Cbest] = 47.200000
	PROCEED: Cstepfactor remains 0.316228, Ccurrent is now 0.003162, Cnew is now 0.001000
		Training SVM with C=0.001000, nbinputs=10000, numruns=1
	testerr[Cnew 0.001000] = 47.400000 > testerr[Ccurrent 0.003162] = 47.200000
	REVERSE: Cstepfactor is now 1.778279, Ccurrent remains 0.003162, Cnew is now 0.005623
		Training SVM with C=0.005623, nbinputs=10000, numruns=1
	testerr[Cnew 0.005623] = 48.700000 > testerr[Ccurrent 0.003162] = 47.200000
	REVERSE: Cstepfactor is now 0.749894, Ccurrent remains 0.003162, Cnew is now 0.002371
		Training SVM with C=0.002371, nbinputs=10000, numruns=1
	testerr[Cnew 0.002371] = 46.500000 < testerr[Ccurrent 0.003162] = 47.200000
	NEW BEST: Cbest <= 0.002371, testerr[Cbest] = 46.500000
	PROCEED: Cstepfactor remains 0.749894, Ccurrent is now 0.002371, Cnew is now 0.001778
		Training SVM with C=0.001778, nbinputs=10000, numruns=1
	testerr[Cnew 0.001778] = 47.000000 > testerr[Ccurrent 0.002371] = 46.500000
	REVERSE: Cstepfactor is now 1.154782, Ccurrent remains 0.002371, Cnew is now 0.002738
		Training SVM with C=0.002738, nbinputs=10000, numruns=1
	testerr[Cnew 0.002738] = 46.800000 > testerr[Ccurrent 0.002371] = 46.500000
	REVERSE: Cstepfactor is now 0.930572, Ccurrent remains 0.002371, Cnew is now 0.002207
		Training SVM with C=0.002207, nbinputs=10000, numruns=1
	testerr[Cnew 0.002207] = 46.500000 > testerr[Ccurrent 0.002371] = 46.500000
	REVERSE: Cstepfactor is now 1.036633, Ccurrent remains 0.002371, Cnew is now 0.002458
		Training SVM with C=0.002458, nbinputs=10000, numruns=1
	testerr[Cnew 0.002458] = 46.700000 > testerr[Ccurrent 0.002371] = 46.500000
	REVERSE: Cstepfactor is now 0.982172, Ccurrent remains 0.002371, Cnew is now 0.002329
		Training SVM with C=0.002329, nbinputs=10000, numruns=1
	testerr[Cnew 0.002329] = 46.600000 > testerr[Ccurrent 0.002371] = 46.500000
	REVERSE: Cstepfactor is now 1.009035, Ccurrent remains 0.002371, Cnew is now 0.002393
		Training SVM with C=0.002393, nbinputs=10000, numruns=1
	testerr[Cnew 0.002393] = 46.500000 > testerr[Ccurrent 0.002371] = 46.500000
	REVERSE: Cstepfactor is now 0.995513, Ccurrent remains 0.002371, Cnew is now 0.002361
		Training SVM with C=0.002361, nbinputs=10000, numruns=1
	testerr[Cnew 0.002361] = 46.800000 > testerr[Ccurrent 0.002371] = 46.500000
	REVERSE: Cstepfactor is now 1.002251, Ccurrent remains 0.002371, Cnew is now 0.002377
		Training SVM with C=0.002377, nbinputs=10000, numruns=1
	testerr[Cnew 0.002377] = 47.000000 > testerr[Ccurrent 0.002371] = 46.500000
	REVERSE: Cstepfactor is now 0.998876, Ccurrent remains 0.002371, Cnew is now 0.002369
		Training SVM with C=0.002369, nbinputs=10000, numruns=1
	testerr[Cnew 0.002369] = 46.600000 > testerr[Ccurrent 0.002371] = 46.500000
	REVERSE: Cstepfactor is now 1.000562, Ccurrent remains 0.002371, Cnew is now 0.002373
		Training SVM with C=0.002373, nbinputs=10000, numruns=1
	testerr[Cnew 0.002373] = 46.700000 > testerr[Ccurrent 0.002371] = 46.500000
	REVERSE: Cstepfactor is now 0.999719, Ccurrent remains 0.002371, Cnew is now 0.002371
		Training SVM with C=0.002371, nbinputs=10000, numruns=1
	testerr[Cnew 0.002371] = 46.500000 > testerr[Ccurrent 0.002371] = 46.500000
	REVERSE: Cstepfactor is now 1.000141, Ccurrent remains 0.002371, Cnew is now 0.002372
		Training SVM with C=0.002372, nbinputs=10000, numruns=1
	testerr[Cnew 0.002372] = 46.500000 > testerr[Ccurrent 0.002371] = 46.500000
	REVERSE: Cstepfactor is now 0.999930, Ccurrent remains 0.002371, Cnew is now 0.002371
		Training SVM with C=0.002371, nbinputs=10000, numruns=1
	testerr[Cnew 0.002371] = 46.500000 > testerr[Ccurrent 0.002371] = 46.500000
	REVERSE: Cstepfactor is now 1.000035, Ccurrent remains 0.002371, Cnew is now 0.002371
		Training SVM with C=0.002371, nbinputs=10000, numruns=1
	testerr[Cnew 0.002371] = 46.500000 > testerr[Ccurrent 0.002371] = 46.500000
	REVERSE: Cstepfactor is now 0.999982, Ccurrent remains 0.002371, Cnew is now 0.002371
	testerr[C 0.001000] = 47.400000 
	testerr[C 0.001778] = 47.000000 
	testerr[C 0.002207] = 46.500000 
	testerr[C 0.002329] = 46.600000 
	testerr[C 0.002361] = 46.800000 
	testerr[C 0.002369] = 46.600000 
	testerr[C 0.002371] = 46.500000 
	testerr[C 0.002371] = 46.500000 
	testerr[C 0.002371] = 46.500000  *best* (testerr = 46.500000, testerrdev = 0.000000, trainerr = 30.300000, trainerrdev = 0.000000)
	testerr[C 0.002371] = 46.500000 
	testerr[C 0.002372] = 46.500000 
	testerr[C 0.002373] = 46.700000 
	testerr[C 0.002377] = 47.000000 
	testerr[C 0.002393] = 46.500000 
	testerr[C 0.002458] = 46.700000 
	testerr[C 0.002738] = 46.800000 
	testerr[C 0.003162] = 47.200000 
	testerr[C 0.005623] = 48.700000 
	testerr[C 0.010000] = 49.400000 
	testerr[C 0.100000] = 54.000000 
...done with SVM validation for 10000 examples (numrums=1, datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm, datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm)...
ceylon.iro.umontreal.ca 2010-08-11 14:38:27.520813: 0:49:51.350000 user+sys, 1:09:49.880000 real, 71.39% usage, 625.49 MB
		----  Encoding  layer #1 ----
			**** DenseLayer.__init__ ****
			tag =  enc1
			inp =  inp
			n_inp =  5000
			n_out =  1000
			act =  tanh
			noise =  binomial_NLP
			out =  outenc1
			params (gradients) =  [Wenc1, benc1]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc1
			allocW, allocb, allocmask =  False False False
		----  Encoding  layer #2 ----
			**** DenseLayer.__init__ ****
			tag =  enc2
			inp =  outenc1
			n_inp =  1000
			n_out =  1000
			act =  tanh
			noise =  binomial
			out =  outenc2
			params (gradients) =  [Wenc2, benc2]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc2
			allocW, allocb, allocmask =  False False False
		----  Encoding  layer #3 ----
			**** DenseLayer.__init__ ****
			tag =  enc3
			inp =  outenc2
			n_inp =  1000
			n_out =  1000
			act =  rectifier
			noise =  binomial
			out =  outenc3
			params (gradients) =  [Wenc3, benc3]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  maskenc3
			allocW, allocb, allocmask =  False False False
MRG_RandomStreams Can't determine #streams from size (Shape.0), guessing 30*256
	---- Auxiliary Layer ----
			**** DenseLayer.__init__ ****
			tag =  aux0
			inp =  outenc3
			n_inp =  1000
			n_out =  1000
			act =  sigmoid
			noise =  None
			out =  outaux0
			params (gradients) =  [Waux0, baux0]
			wdreg (weigth decay) =  l2
			spreg (sparsity) =  l1
			upmaskbool =  None
			maskinit =  None
			allocW, allocb, allocmask =  False False ones
	**** SDAE ****
	depth =  3
	mode =  Aux
	depth_min, depth_max, update_type =  0 , 3 , special
	inp, n_inp =  inp , 5000
	n_hid =  [1000, 1000, 1000]
	layertype =  [<class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>, <class 'deepANN.ANN.DenseLayer'>]
	act =  ['tanh', 'tanh', 'rectifier']
	noise, noise_lvl =  ['binomial_NLP', 'binomial', 'binomial'] , 0.3
	tie =  [True, True, True]
	maskbool =  [None, None, None]
	n_out, outtype =  5 , <class 'deepANN.Logistic_regression.LogisticRegression'>
	lr =  0.0001
	sup_scaling, unsup_scaling, aux_scaling  =  None None 1.0
	regularization, wdreg  =  [0.0, 0.0, 0.0, 0.0] , l2
	sparsity, spreg =  [0.0, 0.0, 0.01] , l1
	params, wd, sp =  [Wenc3, benc3, Waux0, baux0] , [] , [Elemwise{mul,no_inplace}.0]
	bbbool, hessscal =  None , None
	aux, auxtarget, aux_one_sided, auxdepth, auxregularization =  True , auxtarget , True , 0 , False
	auxact, auxn_out, auxwdreg =  sigmoid , 1000 , l2
##########  TEST ############ EPOCH :  2
CURRENT RECONSTRUCTION ERROR (is this on test or train?):  532.309258911
CURRENT 100 SVM ERROR:  (0.0023284420283170132, 52.609999999999999, 1.81491, 12.199999999999999, 3.82884)
CURRENT 1000 SVM ERROR:  (0.001715437896342879, 46.399999999999999, 0.20493900000000001, 32.240000000000002, 0.21071300000000001)
CURRENT 10000 SVM ERROR:  (0.0023713737056616554, 46.5, 0.0, 30.300000000000001, 0.0)
ceylon.iro.umontreal.ca 2010-08-11 14:39:36.698992: 0:49:59.970000 user+sys, 1:10:59.050000 real, 70.44% usage, 625.49 MB
params.pkl saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth3pre2
Wenc1 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth3pre2/Layer1_W.pkl
benc1 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth3pre2/Layer1_b.pkl
maskenc1 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth3pre2/Layer1_mask.pkl
Wenc2 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth3pre2/Layer2_W.pkl
benc2 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth3pre2/Layer2_b.pkl
maskenc2 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth3pre2/Layer2_mask.pkl
Wenc3 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth3pre2/Layer3_W.pkl
benc3 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth3pre2/Layer3_b.pkl
maskenc3 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth3pre2/Layer3_mask.pkl
Waux0 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth3pre2/Layeraux_W.pkl
baux0 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth3pre2/Layeraux_b.pkl
maskaux0 saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth3pre2/Layeraux_mask.pkl
W saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth3pre2/Layerout_W.pkl
b saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth3pre2/Layerout_b.pkl
saved in /data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/depth3pre2
...done validating (err={1000: {0: (0.0034058581998212207, 47.990000000000002, 0.280891, 28.100000000000001, 0.184391), 1: (0.0023927991734281374, 46.149999999999999, 0.30413800000000002, 31.059999999999999, 0.185472), 2: (0.001715437896342879, 46.399999999999999, 0.20493900000000001, 32.240000000000002, 0.21071300000000001)}, 10000: {0: (0.0029693148482024781, 47.700000000000003, 0.0, 29.300000000000001, 0.0), 1: (0.0023501400846134891, 46.0, 0.0, 31.199999999999999, 0.0), 2: (0.0023713737056616554, 46.5, 0.0, 30.300000000000001, 0.0)}, 100: {0: (0.020535250264571463, 55.340000000000003, 3.1582300000000001, 2.8999999999999999, 1.6093500000000001), 1: (0.010390030472626858, 53.5, 2.6214499999999998, 5.5999999999999996, 2.0347), 2: (0.0023284420283170132, 52.609999999999999, 1.81491, 12.199999999999999, 3.82884)}},epoch=2,model=<deepANN.ANN.SDAE object at 0x30fcb50>,depth=2,ACT=['tanh', 'tanh', 'rectifier'],LR=0.0001,NOISE_LVL=0.3,BATCHSIZE=10,train=<CudaNdarrayType(float32, matrix)>,datatrain=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_train_labels_1.pkl'),datatrainsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/train.libsvm,datatest=('/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_instances_1.pkl', '/u/glorotxa/work/NLP/DARPAproject/OpenTable_5000_test_labels_1.pkl'),datatestsave=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211/test.libsvm,VALIDATION_TRAININGSIZE=[100, 1000, 10000],VALIDATION_RUNS_FOR_EACH_TRAININGSIZE={'100': 20, '10000': 1, '1000': 10},PATH_SAVE=/data/lisa/exp/turian/dev/python/DeepANN/exp_scripts/jobman_20100811_132837_00486211)
ceylon.iro.umontreal.ca 2010-08-11 14:39:38.814578: 0:50:00.060000 user+sys, 1:11:01.170000 real, 70.40% usage, 625.49 MB
File: 1 25.6533219814 ----
ceylon.iro.umontreal.ca 2010-08-11 14:40:04.468281: 0:50:22.520000 user+sys, 1:11:26.810000 real, 70.51% usage, 625.49 MB
File: 2 24.8446598053 ----
ceylon.iro.umontreal.ca 2010-08-11 14:40:29.313383: 0:50:44.830000 user+sys, 1:11:51.660000 real, 70.62% usage, 625.49 MB
File: 3 24.919064045 ----
ceylon.iro.umontreal.ca 2010-08-11 14:40:54.232887: 0:51:07.240000 user+sys, 1:12:16.570000 real, 70.73% usage, 625.49 MB
File: 4 22.3044378757 ----
ceylon.iro.umontreal.ca 2010-08-11 14:41:16.537760: 0:51:29.350000 user+sys, 1:12:38.870000 real, 70.88% usage, 625.49 MB
